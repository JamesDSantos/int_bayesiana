[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introdução à Inferência Bayesiana",
    "section": "",
    "text": "Preface\nEste material foi criado para a disciplina Introdução à Inferência Bayesiana, do curso de bacharelado em Estatística, da Universidade Federal do Amazonas.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introdução",
    "section": "",
    "text": "2.1 Dados que serão utilizados nesse capítulo\nA amostra abaixo se refere ao número mensal de suicídios registrados no Amazonas nos anos 2021, 2022 e 2023.\nno_suicidios &lt;- c(19, 26, 30, 28, 25, 23,23, 21,\n22, 27, 31, 22, 23, 21, 29, 27, 26, 23,\n36, 27, 24, 21, 18, 22, 34, 27, 26, 26, 34,\n22, 27, 25, 32, 36, 28, 22 )\nDesta amostra, inferimos que a média mensal é de 25,9 registros e que a variância é 21,05.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#notação",
    "href": "intro.html#notação",
    "title": "2  Introdução",
    "section": "2.2 Notação",
    "text": "2.2 Notação\nVariáveis aleatórias cujos valores podem ser observados serão denotadas por letras maiúsculas. Exemplos:\n\n\\(X\\) é o número de acidentes diários na Avenida Torquato Tapajós\n\\(Y\\) é o nível máximo diário do Rio Negro\n\nValores observados de variáveis aleatórias serão denotados pela respectiva letra minúscula.\nParâmetros serão considerados aleatórios, mas serão representados por letras gregas minúsculas, como \\(\\theta\\), \\(\\lambda\\), etc.\nVetores aleatórios serão representados por letras em negrito. Exemplos:\n\n\\(\\mathbf{X} = \\{X_1 , \\ldots , X_n \\}\\) é um vetor de variáveis aleatórias.\n\\(\\mathbf{x} = \\{x_1 ,\\ldots , x_n \\}\\) é um vetor observado de variáveis aleatórias.\n\\(\\theta=\\{\\alpha,\\beta\\}\\) é um vetor de parâmetros.\n\n\nDefinition 2.1 O suporte de uma variável aleatória é o conjunto de todos os seus possíveis valores. Quando necessário, o suporte de variáveis aleatórias é representado pela versão caligráfica de sua letra correspondente.\nExemplos: o suporte de \\(X\\) é \\(\\mathcal{X}\\) ; o suporte de Y é \\(\\mathcal{Y}\\) ; o suporte de \\(Z\\) é \\(\\mathcal{Z}\\).\n\n\nDefinition 2.2 O espaço paramétrico é o conjunto de todos os possíveis valores do parâmetro. Ele é representado pela versão maiúscula da letra grega utilizada para seu respectivo parâmetro.\nExemplo: o espaço paramétrico do parâmetro \\(\\theta\\) é representado por \\(\\Theta\\).\n\nTanto a função de densidade quanto a de probabilidade serão denotadas por funções começando com letras minúsculas. Por exemplo,\n\\[f(x|\\lambda)=\\lambda e^{-\\lambda x}\\] onde \\(x,\\lambda&gt;0\\) é a densidade da distribuição exponencial, enquanto que\n\\[p(x|\\lambda)=\\frac{e^{-\\lambda}\\lambda^x}{x!}\\] com \\(x\\in\\mathbb{N}\\) e \\(\\lambda &gt;0\\) é a função de probabilidade da distribuição Poisson.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#fontes-de-informação",
    "href": "intro.html#fontes-de-informação",
    "title": "2  Introdução",
    "section": "2.3 Fontes de informação",
    "text": "2.3 Fontes de informação\n\n2.3.1 A função de verossimilhança\nSeja \\(\\mathbf{x} = \\{x_1 , \\ldots , x_n \\}\\) uma amostra observada. Supomos que \\(\\mathbf{x}\\) é uma das possíveis amostras das variáveis aleatórias \\(\\mathbf{X} = \\{X_1 , \\ldots , X_n \\}\\). Supomos ainda que \\(X\\sim F (.|\\theta)\\). Assim, condicionada ao conhecimento de \\(\\theta\\), a distribuição da amostra está completamente especificada.\n::: {#def-Funcao de verossimilhanca} Para \\(\\mathbf{x}\\) fixado, a função \\[L:\\Theta\\Rightarrow [0,\\infty)\\] é denominada verossimilhança. :::\nSua interpretação é a seguinte: para \\(\\theta_1,\\theta_2\\in\\Theta\\), se\n\\[L(\\theta_1)&gt;L(\\theta_2),\\] dizemos que \\(\\theta_1\\) é mais verossímil que \\(\\theta_2\\). Isto porque a probabilidade de observar uma amostra na vizinhança de \\(\\mathbf{x}\\) é maior se considerarmos que \\(\\theta_1\\) é o valor do parâmetro. A verossimilhança é uma das fontes de informação utilizada na inferência bayesiana (e a única fonte da inferência frequentista).\n\nExample 2.1 Seja \\(X_i\\) o número de suicídios no \\(i\\)-ésimo mês da amostra e suponha que \\(X_1,\\ldots,X_{36}\\) é uma amostra aleatória proveniente do modelo Poisson(\\(\\theta\\)). Como \\(\\sum_i x_i=933\\), a função de verossimilhança será \\[L(\\theta)=\\prod_{i=1}^{36}\\frac{e^{-\\theta}\\theta^{x_i}}{x_i!}\\propto e^{-36\\theta}\\theta^{933}.\\]\nA próxima figura mostra os valores da função de verossimilhança para diversos valores de \\(\\theta\\) para a amostra observada.\n\n# função de verossimilhança\nvero &lt;- function(q){\n  sapply ( q, function(q) prod(dpois(no_suicidios, q)) ) \n} \n\n# gráfico da função de verossimilhança\noo &lt;- par( cex = 1.2)\ncurve( vero(x),22,30, xlab = expression(theta), ylab = expression( L(theta)) , lwd = 2)\n\n\n\n\n\n\n\npar(oo)\n\nPodemos notar que o valores mais verossímeis para \\(\\theta\\) estão entre 24 e 28. Podemos ainda procurar o valor mais verossímil, denominado estimativa de máxima verossimilhança (emv). Pode-se mostrar, utilizando cálculo diferencial, que este valor é equivalente à média amostral. Contudo, com o objetivo de utilizar ao máximo o poder computacional que temos disponível, vamos encontrar esse valor utilizando a função optimize.\n\n# menos o logaritmo da função de verossimilhança\nlvero &lt;- function(q) -log( vero(q))\n\n# encontrando a emv:\noptimise(lvero, c(24,28))\n\n$minimum\n[1] 25.91666\n\n$objective\n[1] 105.4219\n\n\nO valor 25,9 é a estimativa de verossimilhança. Sob o ponto de vista frequentista, esta seria a nossa estimativa para o valor de \\(\\theta\\).\n\n\n\n2.3.2 A distribuição a priori\nSob o ponto de vista bayesiano, a informação existente sobre \\(\\theta\\) antes da observação da amostra deve ser levada em consideração. Isto é feito traduzindo tal informação em termos de probabilidades.\n\nDefinition 2.3 A distribuição de \\(\\theta\\) é denominada distribuição a priori.\n\n\nOs parâmetros da distribuição a priori são denominados hiperparâmetros.\n\nAs distribuições a priori agregam o conhecimento sobre parâmetro antes da observação da amostra (tal conhecimento pode pode vir da expertize dos envolvidos ou ter sido gerado de uma amostra prévia).\nAs prioris podem ser muito ou pouco informativas, dependendo do grau de crença sobre os valores particulares do espaço paramétrico. Em geral isto é feito alterando a variância da distribuição:\n\\[\\hbox{variância}=\\frac{1}{\\hbox{precisão}}\\]\n\nExample 2.2 Nosso objetivo é encontrar uma distribuição a priori para \\(\\theta\\), que representa o número médio de suicídios mensais no Amazonas. Primeiro, vamos obter algumas informações:\n\nEm 2024 foi noticiado que, no Brasil, ocorrem em média 38 suicídios por dia, algo em torno de 1.140 suicídios em um mês.\nPara 2024, a população brasileira estava estimada em 212.600.000, enquanto que a população do Amazonas estava estimada em 4.281.209. Portanto, o Amazonas representa, aproximadamente 2% da população brasileira.\nDeste modo, pode-se inferir (a priori) que, em média, ocorrem 22,8 suicídios mensais no Amazonas.\n\nPodemos então procurar alguma distribuição a priori que reflita essa informação. Por mera conveniência, vamos escolher \\(\\theta\\sim\\hbox{Gama}(a,b)\\), onde \\(E(\\theta)=\\frac{a}{b}=22,8.\\)\nUm especialista em saúde pública poderia argumentar melhor se há motivos para acreditar que essa média deveria ser maior ou não. Como não temos essa informação disponível, podemos refletir esse fato aumentando a variabilidade do modelo. O desvio padrão desta priori é\n\\[\\sqrt{Var(\\theta)}=\\frac{\\sqrt{a}}{b}=\\frac{E(\\theta)}{\\sqrt{a}}=\\frac{22,8}{\\sqrt{a}}.\\]\nVamos escolher esse desvio igual 5. Isto implica que \\[a=\\left(\\frac{22,8}{5}\\right)^2=20,8\\] e \\[b=\\frac{22,8}{20,8}=1,1.\\] Então, nossa informação a priori está traduzida no modelo Gama(20.8,1.1). Abaixo, apresentamos a função densidade desse modelo. Observe que esse modelo traz informações vagas sobre \\(\\theta\\), permitindo que ele assuma valores entre 10 e 30\n\ncurve(dgamma(x,20.8, 1.1), 10,35)\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Reunindo as fontes de informação - distribuição a posteriori\nSejam \\(f(\\boldsymbol{\\theta})\\) a densidade/função para \\(\\boldsymbol{\\theta}\\) e \\(L(\\boldsymbol{\\theta})\\) a função de verossimilhança.\nComo \\(\\boldsymbol{\\theta}\\) é considerado aleatório, podemos analisar sua distribuição após observar a amostra \\(\\boldsymbol{x}\\), ou seja \\[\\boldsymbol{\\theta}|\\boldsymbol{x}.\\]\nEsta distribuição é denominada \n::: {#thm-Teorema de Bayes}\nSeja \\(\\boldsymbol{x}\\) uma amostra observada. Considere a priori \\(\\theta\\sim f(\\theta)\\) e a verossimilhança \\(L(\\theta)\\). Então a função de densidade (ou probabilidade) de \\(\\theta|\\boldsymbol{x}\\) é dada por \\[f(\\theta|\\boldsymbol{x})=\\frac{L(\\theta)f(\\theta)}{f(\\boldsymbol{x})}.\\] O denominador é denominado distribuição preditiva, sendo igual a \\[f(\\boldsymbol{x})=\\sum_{\\theta\\in \\Theta}L(\\theta)f(\\theta),\\] se \\(\\theta\\) é v.a. discreta ou \\[f(\\boldsymbol{x})=\\int_{\\Theta}L(\\theta)f(\\theta)d\\theta\\] se \\(\\theta\\) é v.a. contínua. :::\n\nExample 2.3 Considerando os dados de suicídios do começo desse capítulo, temos as seguintes fontes de informação:\n\nVerossimilhança: \\[L(\\theta)\\propto e^{-36\\theta}\\theta^{933}\\]\nPriori \\[f(\\theta)\\propto \\theta^{19,8}e^{-1,1\\theta}\\]\n\nA distribuição a posteriori será\n\\[f(\\theta|x_1,\\ldots,x_{36})\\propto \\theta^{933+19,8}e^{-(36+1,1)\\theta}=\\theta^{952,8}e^{-37,1\\theta}.\\] Assim, verificamos que \\(\\theta|x_1,\\ldots,x_{36}\\sim\\hbox{Gama}(953.8,37.1)\\). Na figura abaixo, apresentamos no mesmo gráfico, a função de verossimilhança, priori e posteriori (fazendo as mudanças de escala necessárias). Observe que a priori é mais dispersa que a verossimilhança. Essa, por sua vez, restringe os valores de \\(\\theta\\) que eram prováveis a priori. O resutaldo é uma distribuição a posteriori próxima da função de verossimilhança.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#inferência-estatística",
    "href": "intro.html#inferência-estatística",
    "title": "2  Introdução",
    "section": "2.4 Inferência estatística",
    "text": "2.4 Inferência estatística\nDenominamos por estatística qualquer função da amostra. Utilizamos estatísticas para fazer as seguintes inferências:\n\nEstimação pontual: trata-se de uma estatística com o objetivo de inferir o valor de \\(\\theta\\). Tal estatística é denominada estimador.\nEstimação por região: trata-se de uma estatística, digamos \\(T(\\boldsymbol{X})\\), com o objetivo de cobrir o valor de \\(\\theta\\), ou seja, fazer a inferência \\(\\theta\\in T(\\boldsymbol{X})\\). As estimações intervalares são as mais comuns, nas quais \\(T(\\boldsymbol{X})=(L(\\boldsymbol{X}),U(\\boldsymbol{X}))\\).\nTestes de hipóteses: são estatísticas construídas para decidir se aceitamos a afirmação (hipótese) \\(H:\\theta\\in \\Theta_0\\), onde \\(\\Theta_0\\) é um subconjunto de \\(\\Theta\\) conhecido por hipótese.\n\nNote que a distribuição a posteriori é função da amostra. Assim, toda função desta distribuição é uma estatística. Assim:\n\nEstimação pontual: em geral é uma medida que representa a região de alta densidade (ou probabilidade) da posteriori. A média da posteriori, assim como a mediana ou a moda são escolhas comuns.\nEstimação por regiões: em geral procuramos por uma região \\(T\\) da posteriori que satisfaça \\(P(\\theta\\in T(\\boldsymbol{x})|\\boldsymbol{x})=\\gamma\\), onde \\(\\gamma\\) é denominado nível de credibilidade (não confundir com nível de confiança)\nTestes de hipóteses: em geral, aceitamos \\(H:\\theta\\in\\Theta_0\\) se \\(P(H|\\boldsymbol{x})\\) é elevada.\n\n\nExample 2.4 Para o nosso exemplo, obtivemos \\(\\theta|\\boldsymbol{x}\\sim\\hbox{Gama}(953.8,37.1)\\). Então, uma estimativa pontual para \\(\\theta\\) é\n\\[E(\\theta|\\boldsymbol{x})=\\frac{953,8}{37,1}=25,7\\] registros de suicídios mensais.\nPodemos obter os quantis de 2,5% e 97,5% para construir um intervalo com 95% de credibilidade:\n\nqgamma( c(.025,.975), 953.8, 37.1)\n\n[1] 24.10301 27.36583\n\n\nlogo, inferimos que \\(\\theta\\in(24.1,27.36)\\) com probabilidade 0,95.\nPor último, recorde-se que discutimos, utilizando apenas os dados nacionais, que \\(\\theta\\) deveria está próximo de 22,8. Após observa a amostra, existem evidências de que \\(H:\\theta&gt;22,8\\)? Para responder a esse questionamento, podemos calcular\n\\[P(H|\\boldsymbol{x})=P(\\theta&gt;22.8|\\boldsymbol{x})\\]\n\n1-pgamma(22.8, 953.8, 37.1)\n\n[1] 0.9998554\n\n\nlogo, com uma probabilidade maior que 99,9%, existem fortes evidências de que o número médio mensal de suicídios no Amazonas é maior do que 22,8 registros por mês.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#exercício",
    "href": "intro.html#exercício",
    "title": "2  Introdução",
    "section": "2.5 Exercício",
    "text": "2.5 Exercício\n\nÉ fato que a taxa de suicídio é maior entre os homens, embora a tentativa seja maior entre as mulheres. Uma das explicações está no fato de que os homens tendem a utilizar métodos mais letais para o suicídio, como armas de fogo, enquanto as mulheres são mais propensas a utilizar métodos menos letais, como overdose de medicamentos.\nDados históricos, entre 1996 e 2017, sugerem que 79% dos suicídios são cometidos por homens.\nSeja \\(\\rho\\) a probabilidade de que um suicídio seja cometido por alguém do sexo masculino no Estado do Amazonas. Considere a priori \\(\\rho\\sim\\hbox{Beta}(a,b)\\), onde sabemos que\n\\[f(\\rho)\\propto \\rho^{a-1}(1-\\rho)^{b-1},\\] \\[E(\\rho)=\\frac{a}{a+b},\\] e \\[Var(\\rho)=\\frac{E(\\rho)(1-E(\\rho))}{a+b+1}.\\]\n\nEncontre valores de \\(a\\) e \\(b\\) que reflitam a média de 0,79 mas que não restrinjam demais os valores possíveis para \\(\\rho\\)\nNo Amazonas, entre os anos 2021 e 2023, dos 933 registros de suicídios, 726 foram cometidos por homens. Considere então o modelo \\(X|\\rho\\sim\\hbox{Binomial}(933,\\rho)\\). Mostre que \\[f(\\theta|x)\\propto \\rho^{726+a-1}(1-\\rho)^{207+b-1}\\] e conclua que \\(\\rho|x\\sim\\hbox{Beta}(a+933,b+207)\\).\nEstime \\(\\theta\\) e construa um intervalo de 95% de credibilidade\nTeste a hipótese de que, para o Amazonas, a probabilidade de um indivíduo do sexo masculino cometer suicídio é maior do que 79%.\nPara problemas envolvendo proporções, é comum o uso a priori \\(\\rho\\sim\\hbox{Uniforme}(0,1)\\), que é equivalente à \\(\\rho\\sim\\hbox{Beta}(1,1)\\). Refaça este exercício com essa priori e discuta sobre as diferenças encontradas tanto nas estimações quanto no teste de hipóteses.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#resumo-da-aula-1",
    "href": "intro.html#resumo-da-aula-1",
    "title": "2  Introdução",
    "section": "2.6 Resumo da aula 1",
    "text": "2.6 Resumo da aula 1\n\nExistem duas fontes de informação na inferência bayesiana: os dados (verossimilhança) e a informação anterior (priori)\nA informação a priori é subjetiva: pessoas diferentes têm prioris diferentes\nO Teorema de Bayes combina as duas fontes em uma nova informação, dada pela distribuição \nOs objetivos da inferência (estimação e testes) são feitos a partir da distribuição a posteriori",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "conjugada.html",
    "href": "conjugada.html",
    "title": "3  Famílias conjugadas",
    "section": "",
    "text": "3.1 Dados que serão utilizados neste capítulo\nrequire(gsheet)\n\nCarregando pacotes exigidos: gsheet\n\nurl &lt;- 'https://docs.google.com/spreadsheets/d/1dLDCjA9a8UgXA9sJ1TNCVvRCDFITalewGkHlc__Eg20/edit?usp=sharing' \ndt &lt;- gsheet2tbl(url)\nhead(dt)\n\n# A tibble: 6 × 5\n  REGIAO              TIPO     SEXO  PERIODO   TOTAL\n  &lt;chr&gt;               &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n1 Região Norte        AGRESSAO Masc  2001-2003  7628\n2 Região Nordeste     AGRESSAO Masc  2001-2003 29652\n3 Região Sudeste      AGRESSAO Masc  2001-2003 63411\n4 Região Sul          AGRESSAO Masc  2001-2003 12428\n5 Região Centro-Oeste AGRESSAO Masc  2001-2003  9319\n6 Região Norte        AGRESSAO Fem   2001-2003   677",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Famílias conjugadas</span>"
    ]
  },
  {
    "objectID": "conjugada.html#família-de-distribuições-conjugadas",
    "href": "conjugada.html#família-de-distribuições-conjugadas",
    "title": "3  Famílias conjugadas",
    "section": "3.2 Família de distribuições conjugadas",
    "text": "3.2 Família de distribuições conjugadas\n::: {#def-Priori conjugada} Dizemos que a priori \\(f(\\boldsymbol{\\theta})\\) é conjugada para a verossimilhança \\(L(\\boldsymbol{\\theta})\\) se priori e posteriori pertencem à mesma família de distribuições. :::\n\nExample 3.1 Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias independentes com \\(X|\\theta\\sim \\hbox{Bernoulli}(\\theta)\\) e \\(\\theta\\sim\\hbox{Beta}(a,b)\\). Então\n\\[\\begin{align}\n    f(\\theta|\\boldsymbol{x})&\\varpropto L(\\theta)f(\\theta) = \\underbrace{\\theta^{\\sum_{i=1}^{n}x_i} (1-\\theta)^{n-\\sum_{i=1}^{n}x_i}}_{L(\\theta)}\\underbrace{\\theta^{a-1}(1-\\theta)^{b-1}}_{f(\\theta)}\\\\\n    &=\\theta^{a+\\sum_{i=1}^n x_i-1}(1-\\theta)^{b+n-\\sum_{i=1}^{n}x_i-1},\n    \\end{align}\\] logo \\(\\theta|\\boldsymbol{x}\\sim\\hbox{Beta}(a+\\sum_{i=1}^{n}x_i,b+n-\\sum_{i=1}^{n}x_i)\\) e a priori beta é conjugada para a verossimilhança Bernoulli.\n\nFamílias conjugadas são extremamente úteis tanto sob o ponto de vista algébrico quanto computacional. Entretanto, note que a definição de família conjugada é ampla. Por exemplo, priori e posteriori sempre pertencem à grande família de todas as distribuições de probabilidade, sendo esta a família conjugada trivial.\nFamílias conjugadas não triviais são raras, existindo principalmente quando a distribuição condicional dos dados pertence à família exponencial.\n::: {#def-Família exponencial} Definição Considere que \\(\\Theta\\) tem dimensão \\(k\\). Dizemos que \\(X|\\boldsymbol{\\theta}\\) pertence à família exponencial (natural) se \\[f(x|\\boldsymbol{\\theta})=h(x)a(\\boldsymbol{\\theta})\\exp\\left\\{\\sum_{j=1}^k t_j(x)\\theta_j\\right\\},\\] onde \\(\\mathcal{X}\\) não depende de \\(\\boldsymbol{\\theta}\\). Além disso, para a amostra (iid )\\(X_1,\\ldots,X_n|\\boldsymbol{\\theta}\\), \\[f(\\boldsymbol{x}|\\boldsymbol{\\theta})=h(\\boldsymbol{x})a(\\boldsymbol{\\theta})^n\\exp\\left\\{\\sum_{j=1}^k T_j\\theta_j\\right\\},\\] onde \\(T_j=\\sum_{i=1}^{n}t_j(x_i)\\) :::\n\nTheorem 3.1 Se \\(X|\\boldsymbol{\\theta}\\) pertence à família exponencial, então \\[f(\\boldsymbol{\\theta})=c(\\boldsymbol{r},s)a(\\boldsymbol{\\theta})^s\\exp\\left\\{\\sum_{j=1}^k r_j\\theta_j\\right\\}\\] é uma priori conjugada (ver O’Hagan (2005) para a existência dessa distribuição). A posteriori será dada por \\[f(\\boldsymbol{\\theta}|\\boldsymbol{x})=c\\left(\\sum_{j=1}^k r_j+T_j,s+n\\right)a(\\boldsymbol{\\theta})^{s+n}\\exp\\left\\{\\sum_{j=1}^k(r_j+T_j)\\theta_j\\right\\}\\]\n\n\nProva\n\\[\\begin{align}\nf(\\boldsymbol{\\theta}|\\boldsymbol{x})&\\varpropto \\underbrace{a(\\boldsymbol{\\theta})^ne^{\\sum_{j=1}^kT_j\\theta_k}}_{L(\\boldsymbol{\\theta})}\\underbrace{a(\\boldsymbol{\\theta})^s e^{\\sum_{j=1}^k r_j\\theta_k}}_{f(\\boldsymbol{\\theta})}\\\\\n&a(\\boldsymbol{\\theta})^{n+s}e^{(\\sum_{j=1}^{k}T_j+r_j)\\theta_j}\n\\end{align}\\]\n\nConsidere que \\(\\boldsymbol{\\theta}\\sim C(\\boldsymbol{r},s)\\) é a distribuição conjugada da verossimilhança. Isto implica em \\(\\boldsymbol{\\theta}|\\boldsymbol{x}\\sim\\hbox{C}(\\boldsymbol{T}+\\boldsymbol{r},s+n)\\). Note que a posteriori atualiza a informação de \\(s\\) para \\(s+n\\) e de \\(r_j\\) para \\(T_j+r_j\\). Logo, se imaginarmos que a priori é um experimento hipotético, \\(s\\) seria o tamanho da amostra e \\(\\boldsymbol{r}\\) seriam as estatísticas suficientes deste modelo.\nAbaixo, segue uma lista de algumas prioris conjugadas para modelos na família exponencial.\n\\[\\begin{array}{c|c|c}\\hline\n\\text{Modelo} & \\text{Priori} & \\text{Posteriori} \\\\ \\hline\n\\text{Bernoulli}(\\theta) & \\text{Beta}(a,b) & \\text{Beta}(a+\\sum_i x_i, b+n-\\sum_i x_i) \\\\ \\hline\n\\text{Poisson}(\\lambda) & \\text{Gama}(a,b) & \\text{Gama}(a+\\sum_i x_i, b+n) \\\\ \\hline\n\\text{Multinomial}(p_1,\\ldots,p_k) & \\text{Dirichlet}(a_1,\\ldots,a_k) & \\text{Dirichlet}(a_1+x_1,\\ldots,a_k+x_k) \\\\\n\\text{Exponencial}(\\lambda) & \\text{Gama}(a,b) & \\text{Gama}(a+n, b+x_i) \\\\\n\\text{Normal}(\\mu,\\phi^{-1})&\\text{Normal-Gama}(m_0,n_0,v_0,s_0^2)&\n\\text{Normal-Gama}(m_1,n_0+n,v_0+n,s_1^2)\\\\\n& & m_1= \\frac{n}{n_1}\\bar{x}+\\frac{n_0}{n_1}m_0\\\\\n& & s_1^2=\\frac{n_0n}{n_1^2}(\\bar{x}-m_0)^2 + \\frac{(n-1)s^2+n_0 s_0^2}{n_1} \\\\ \\hline\n\\end{array}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Famílias conjugadas</span>"
    ]
  },
  {
    "objectID": "conjugada.html#prioris-conjugadas-fora-da-família-exponencial",
    "href": "conjugada.html#prioris-conjugadas-fora-da-família-exponencial",
    "title": "3  Famílias conjugadas",
    "section": "3.3 Prioris conjugadas fora da família exponencial",
    "text": "3.3 Prioris conjugadas fora da família exponencial\nFamílias conjugadas fora da família exponencial são raras. Seja \\(X_1,\\ldots,X_n\\) variáveis aleatória independentes com \\(X_1|\\phi,\\psi\\sim\\hbox{Binomial Negativa}(\\psi,\\phi)\\), onde\n\\[f(x|\\phi,\\psi)=\\frac{\\Gamma(x+\\psi)}{\\Gamma(\\psi)x!}\\phi^\\psi (1-\\phi)^x,\\] com \\(\\psi&gt;0\\), \\(\\phi\\in(0,1)\\) e \\(x\\in\\mathbb{N}\\). Se \\(\\psi\\) é conhecido, então \\[L(\\boldsymbol{\\theta})=\\underbrace{\\left[\\frac{\\prod_{i=1}^n\\Gamma(x_i+\\psi)}{\\Gamma(\\psi)^n\\prod_{i=1}^n x_i!}\\right]}_{h(\\boldsymbol{x})}\\underbrace{\\phi^{n\\psi}}_{a(\\phi)}\\exp\\left\\{ \\underbrace{\\sum_{i=1}^n x_i}_{t(\\boldsymbol{x})} \\underbrace{\\log(1-\\phi)}_{w(\\phi)}\\right\\} \\]\nEntão, \\[\\begin{align}\nf(\\phi|\\psi)&=c(r,s)a(\\phi)^s e^{rw(\\phi)}\\\\\n&=c(r,s)\\phi^{s\\psi}(1-\\phi)^{r}\n\\end{align}\\] é uma \\(*priori*\\) conjugada. Da expressão acima segue que \\(\\phi|\\psi \\sim \\hbox{Beta}(s\\psi+1,r+1)\\). A \\(*posteriori*\\) (condicional) por sua vez é dada por \\[f(\\phi|\\boldsymbol{x},\\psi)\\varpropto \\phi^{\\psi(s+n)}(1-\\phi)^{r+\\sum_{i=1}^{n}x_i},\\] onde ainda \\(\\phi|\\psi,\\boldsymbol{x}\\sim\\hbox{Beta}(\\psi(s+n)+1,r+\\sum_{i=1}^{n}x_i+1)\\) Note que para fazer a inferência completa, ainda necessitamos de \\(\\psi|\\boldsymbol{x}\\), uma vez que \\[f(\\phi,\\psi|\\boldsymbol{x})=f(\\phi|\\psi,\\boldsymbol{x})f(\\psi|\\boldsymbol{x}).\\] Outro método de obter a conjunta \\((\\phi,\\psi|\\boldsymbol{x})\\), sem a necessidade de calcular \\(\\psi|\\boldsymbol{x}\\) será discutido na próxima aula.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Famílias conjugadas</span>"
    ]
  },
  {
    "objectID": "estimacao.html",
    "href": "estimacao.html",
    "title": "4  O estimador de bayes",
    "section": "",
    "text": "Considere o problema de tomar alguma decisão sobre \\(\\theta\\) utilizando uma estatística \\(T(\\mathbf{x})\\).\nPodemos determinar o quão ruim é a nossa decisão definindo uma função de perda \\(\\mathcal{L}(\\theta,T)\\), com as seguintes características:\n\n\\(\\mathcal{L}(\\theta,T)=0\\) sempre que \\(T\\) for a decisão correta em relação à \\(\\theta\\)\n\\(\\mathcal{L}(\\theta,T)&gt;0\\) em caso contrário.\n\nPor exemplo, se \\(T\\) for um estimador para \\(\\theta\\), a decisão correta seria ter \\(T=\\theta\\). Além disso, quanto mais afastado \\(T\\) estiver de \\(\\theta\\), pior é a decisão e maior deveria ser a perda.\nNo problema de estimação pontual, é usual utilizar a perda quadrática: \\[\\mathcal{L}(\\theta,T)=(T-\\theta)^2,\\] cujo esboço do gráfico é dado abaixo:\n\nplot.new()\nplot.window(xlim=c(-2,2), ylim=c(0,4))\ncurve( x^2,-2,2, lwd = 2, add = T)\naxis(1, at = c(-2,-1,0,1,2), labels = c(expression(theta -2),expression(theta -1),expression(theta),expression(theta +1),expression(theta +2) ))\naxis(2)\ntitle( ylab = 'Perda quadrática',xlab = 'T')\n\n\n\n\n\n\n\n\nPara uma decisão \\(T\\) podemos calcular a perda média \\[R_T(\\theta)=E(\\mathcal{L}(\\theta,T))=\\int L(\\theta,T(\\mathbf{x}))f(\\mathbf{x}|\\theta)d\\mathbf{x}\\] A função acima é conhecida como risco da decisão \\(T\\) e é variável em \\(\\theta\\). Seu uso é simples: se \\(R_T(\\theta)&lt;R_U(\\theta)\\), então em média a decisão \\(T\\) tem menor perda que \\(U\\). Assim, a melhor escolha entre as duas decisão é \\(U\\).\nO risco associado à perda quadrática é denominado erro quadrático médio:\n\\[R_T(\\theta)=E(T-\\theta)^2= Var(T)+(E(T|\\theta)-\\theta)^2\\] Ele possui papel importante na inferência pontual frequentista, como por exemplo, para definir o melhor estimador não viciado de variância uniformemente mínima.\nO risco de Bayes da decisão \\(T\\) é o valor esperado do seu respectivo risco , \\[r_T=\\int R_T(\\theta)f(\\theta)d\\theta,\\] sendo portanto uma constante. Qualquer decisão com o menor risco para todo \\(\\theta\\) também tem o menor risco de Bayes. Dizemos que \\(T\\) é o estimador de Bayes se \\(r_T&lt;r_U\\) para qualquer decisão \\(U\\).\n\nTeorema\nO estimador \\(T\\) que minimiza \\[\\int \\mathcal{L}(\\theta,T(\\mathbf{x}))f(\\theta|\\mathbf{x})d\\theta\\] é o estimador de Bayes.\n\n\nExemplo\nVamos encontrar o estimador de Bayes para a perda quadrática. Temos que\n\\[\\begin{align*}\\int \\mathcal{L}(\\theta,T(\\mathbf{x}))f(\\theta|\\mathbf{x})d\\theta&=\\int (T(\\mathbf{x})-\\theta)^2f(\\theta|\\mathbf{x})d\\theta\\\\\n    &=T(\\mathbf{x})^2 +\\int \\theta^2f(\\theta|\\mathbf{x})d\\theta-2T(\\mathbf{x})\\int \\theta f(\\theta|\\mathbf{x})d\\theta\\\\\n    &= T(\\mathbf{x})^2 + E(\\theta^2|\\mathbf{x}) -2T(\\mathbf{x})E(\\theta|\\mathbf{x})\\\\\n    &= T(\\mathbf{x})^2 + E(\\theta^2|\\mathbf{x}) -2T(\\mathbf{x})E(\\theta|\\mathbf{x}) \\pm E(\\theta|\\mathbf{x})^2\\\\\n    &=\\left( T(\\mathbf{x}) - E(\\theta|\\mathbf{x})\\right)^2 +E(\\theta^2|\\mathbf{x})-E(\\theta|\\mathbf{x})^2\\\\\n    &=\\left( T(\\mathbf{x}) - E(\\theta|\\mathbf{x})\\right)^2 +Var(\\theta|\\mathbf{x})\n\\end{align*}\\] A função acima é minimizada em \\(T(\\mathbf{x})=E(\\theta|\\mathbf{x})\\). Disto, mostra-se que \\[r_T\\geq Var(\\theta|\\mathbf{x})\\] e a variância da posteriori pode ser utilizada como medida de erro. Como a unidade deste erro está ao quadrado, é usual utilizarmos o desvio padrão da posteriori como medida de erro.\n\n\nExample 4.1 Seja \\(X_1,\\ldots,X_n\\) uma amostra aleatória do modelo Exponencial(\\(\\theta\\)) e considere a priori \\(\\theta\\sim\\hbox{Gama}(a,b)\\). Sabemos que \\(\\theta|\\boldsymbol{x}\\sim\\hbox{Gama}(s+n,r+\\sum_{i=1}^n x_i)\\). Então, o estimador de Bayes segundo a perda quadrática é \\[T(\\boldsymbol{x})=E(\\theta|\\boldsymbol{x})=\\frac{s+n}{r+\\sum_{i=1}^n x_i},\\] e o erro associado é \\[\\sqrt{Var(\\theta|\\boldsymbol{x})}=\\sqrt{\\frac{s+n}{(r+\\sum_{i=1}^n x_i)^2}}=\\sqrt{\\frac{E(\\theta|\\boldsymbol{x})^2}{s+n}}=\\frac{E(\\theta|\\boldsymbol{x})}{\\sqrt{n+s}}.\\]\nNote que, como esperado, o erro decresce na medida que \\(n\\) cresce.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>O estimador de bayes</span>"
    ]
  },
  {
    "objectID": "bernoulli.html",
    "href": "bernoulli.html",
    "title": "5  O modelo Bernoulli",
    "section": "",
    "text": "5.1 O modelo univariado\nA distribuição \\(F\\) é dita pertencer à família Bernoulli, com parâmetro \\(\\theta\\in(0,1)\\) se sua função de probabilidade é dada por \\[f(x|\\theta)=\\theta^x(1-\\theta)^{1-x},\\] com \\(x\\in\\{0,1\\}\\). É imediato que \\(\\theta\\) representa a probabilidade de \\(\\{X=1\\}\\), sendo este evento conhecido como ‘sucesso’ em alguns textos (em contrapartida, \\(\\{X=0\\}\\) é conhecido como `fracasso’).\nEsta distribuição faz a importante conexão entre variáveis categóricas e aleatórias, tendo papel fundamental na inferência não paramétrica. Por exemplo, seja \\(S\\) o sexo de um indivíduo selecionado ao acaso. Tal variável é categórica, podendo assumir os resultados \\(A=\\){feminino} ou \\(A^c\\). Contudo, pode-se definir a variável \\(X=I(A)\\), onde \\(I(.)\\) é a função indicadora, definida por \\[I(A)=\\left\\{\\begin{array}{ll} 1,&\\hbox{ se $A$ ocorre,} \\\\ 0,&\\hbox{ se $A^c$ ocorre.}\\end{array}\\right.\n\\] Deste modo \\(X\\sim\\hbox{Bernoulli}(\\theta)\\).\nComo discutido anteriormente, o modelo Bernoulli(\\(\\theta\\)) pertence à família exponencial e sua distribuição conjugada é a Beta\\((a,b)\\). A distribuição a posteriori é dada por\n\\[f(\\theta|\\boldsymbol{x})\\propto \\theta^{a+\\sum_{i=1}^n x_i-1}(1-\\theta)^{n-\\sum_{i=1}^n x_i+b-1},\\] ou seja, \\(\\theta|\\boldsymbol{x}\\sim\\hbox{Beta}(a+\\sum_{i=1}^n x_i,n-\\sum_{i=1}^n x_i + b).\\) Observe que \\(a\\) pode ser interpretado como o número de sucessos a priori e \\(b\\) o número de fracassos. É comum utilizarmos a priori Beta\\((1,1)\\), que é equivalente à Uniforme(0,1), como priori pouco informativa.\nNo exemplo anterior foi possível verificar graficamente que as probabilidades de morte por febre puerperal em ambas as clínicas eram distintas. Recordando que as respectivas probabilidades foram identificadas por \\(\\alpha\\) e \\(\\beta\\), era evidente que \\(P(\\alpha&gt;\\beta|\\hbox{dados})=1\\).\nQuando a evidência gráfica não é clara, é necessário calcular tal probabilidade. Sejam \\(X_1,\\ldots,X_n\\) e \\(Y_1,\\ldots,Y_m\\) duas amostras aleatórias independentes com \\(X_i|\\alpha\\sim\\hbox{Bernoulli}(\\alpha)\\) e \\(Y_i|\\beta\\sim\\hbox{Bernoulli}(\\beta)\\). Considerando prioris conjugadas, teremos que \\(\\alpha|\\boldsymbol{x}\\) e \\(\\beta|\\boldsymbol{y}\\) possuem distribuição beta e são independentes. Para testar uma hipótese do tipo \\(H: \\alpha&gt;\\beta\\) é necessário calcular\n\\[p=P(\\alpha&gt;\\beta|\\boldsymbol{x},\\boldsymbol{y}).\\] Contudo, podemos definir a variável \\(A=\\left\\{\\begin{array}{ll}1,&\\alpha&gt;\\beta\\\\ 0,&\\alpha\\leq \\beta\\end{array}\\right.\\) Deste modo, \\(A\\sim\\hbox{Bernoulli}(p)\\). Acontece que \\(p=E(A)\\) e, pela Lei Forte dos Grandes Números, para a sequência \\(A_1,A_2,\\ldots,\\) teremos que \\[\\frac{1}{B}\\sum_{j=1}^B A_j\\rightarrow E(A)=p,\\;\\; B\\rightarrow\\infty\\] Deste modo, se tivermos uma observação da amostra aleatória \\(A_1,\\ldots,A_B\\) é possível calcular \\(p\\) com boa precisão para \\(B\\) suficientemente grande. Podemos obter essa amostra via simulação. Esse é o princípio do Método de Monte Carlo.\nPara calcular \\(p=P(\\alpha&gt;\\beta|\\hbox{dados})\\) apresentado anteriormente, podemos realizar os seguintes passos:\n\\[\\frac{1}{B}\\sum_{j=1}^B I(\\alpha_j&gt;\\beta_j)\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>O modelo Bernoulli</span>"
    ]
  },
  {
    "objectID": "bernoulli.html#o-modelo-univariado",
    "href": "bernoulli.html#o-modelo-univariado",
    "title": "5  O modelo Bernoulli",
    "section": "",
    "text": "Example 5.1 Um estudo investiga a eficácia de uma nova campanha de vacinação contra a gripe em uma grande cidade. Antes da campanha, a taxa de vacinação na população adulta era de 40%. Após a campanha, uma amostra aleatória de 500 adultos revelou que 250 deles foram vacinados. Os pesquisadores querem determinar se a campanha aumentou significativamente a taxa de vacinação.\nSeja \\(\\theta\\) a nova taxa de vacinação. Estamos interessados em testar a hipótese de que \\(\\theta&gt;0,4\\). Considerando que o evento de interesse é um adulto vacinado, teremos que \\(x_i=1\\) se o \\(i\\)-ésimo adulto da amostra foi vacinado e \\(x_i=0\\) em caso contrário. Utilizando a priori Beta(1,1), teremos \\(\\theta|x_1,\\ldots,x_{500}\\sim\\hbox{Beta}(251,251)\\). Deste modo a probabilidade a posteriori da hipótese é\n\\[P(\\theta&gt;0,4|\\boldsymbol{x})=\\int_{0,4}^1 f(\\theta|\\boldsymbol{x})d\\theta.\\] Utilizando o R, obtemos\n\n1-pbeta(.4,251,251)\n\n[1] 0.999997\n\n\nlogo, a probabilidade de que a campanha aumentou a taxa de vacinação é maior que 99,999%.\n\n\nExample 5.2 As duas clínicas\nEm 1846, Ignaz Philipp Semmelweis se tornou assistente na Primeira Clínica de Obstetrícia do Hospital Geral de Viena, Áustria (algo como o residente chefe). Neste hospital o parto era oferecido de gratuitamente, pois o mesmo serveria de treinamento para os médicos e parteiras.\nNaquela época, a febre puerperal era comum e muitas vezes fatal, sendo que a mortalidade variava entre 10% a 35%.\nHaviam duas maternidades no Hospital Geral de Viena, conhecidas como a Primeira e a Segunda. A Primeira era considerada um local de morte e era evitada quando possível. Abaixo temos os dados registrados pelo Dr. Semmelweis\n\\[\\begin{array}{c|cc|cc}\\hline \\hbox{} & \\hbox{Primeira} & \\hbox{Clínica} & \\hbox{Segunda} & \\hbox{Clínica}\\\\ \\hline\n\\hbox{Ano} & \\hbox{Partos} & \\hbox{Mortes} &\\hbox{Partos} & \\hbox{Mortes} \\\\ \\hline\n1841 & 3036 & 237 & 2442 & 86 \\\\\n1842 & 3287 & 518 & 2659 & 202 \\\\\n1843 & 3060 & 274 & 2739 & 164 \\\\\n1844 & 3157 & 260 & 2956 & 68 \\\\\n1845 & 3492 & 241 & 3241 & 66 \\\\\n1846 & 4010 & 459 & 3754 & 105 \\\\ \\hline\n\\hbox{Total} & 20.042 & 1.989 & 17.791 & 691 \\\\ \\hline\n\\end{array}\\]\nPode-se considerar que cada parto gera duas possibilidades de eventos: a sobrivência ou a morte da mãe. Considere que, dentro da mesma clínica, esses eventos para cada mãe são indepentes e possuem a mesma probabilidade. Seja \\(\\alpha\\) a probabilidade de morte na Primeira Clínica e \\(\\beta\\) a mesma probabilidade para a Segunda Clínica. Então, as funções de verossimilhança para cada probabilidade são\n\\[\\begin{align}L(\\alpha)&\\propto \\alpha^{1989} (1-\\alpha)^{18053}\\\\L(\\beta)&\\propto \\beta^{691} (1-\\beta)^{17100}\\end{align}\\] Utilizando distribuição Uniforme(0,1) como priori para \\(\\alpha\\) e \\(\\beta\\), teremos que\n\\[\\begin{align}\\alpha|\\boldsymbol{x}&\\sim \\hbox{Beta}(1990,18054) \\\\\\beta|\\boldsymbol{x}&\\sim \\hbox{Beta}(692,17101)\\end{align}\\]\nAbaixo, mostramos as duas posterioris, de onde podemos concluir que a probabilidade de morte na Primeira Clínica é certamente maior que na Segunda.\n\ncurve(dbeta(x,1990,18054),0.03,.11, lwd = 2,ylab='Densidades a posteriori',xlab='Probabilidade de morte',ylim=c(0,300))\ncurve(dbeta(x,692,17101), lwd = 2, add = T)\ntext(c(.04,.1),c(290,210),c('Segunda Clínica','Primeira Clínica'))\n\n\n\n\n\n\n\n\nO Dr. Semmelweis ainda não tinha descoberto o motivo dessas mortes até a morte de seu amigo Jakob Kolletschka, que se cortou acidentalmente com um bisturi durante uma autópsia. Durante a autópsia de Jakob, o Dr. Semmelweis viu semelhanças com as autópsias as mulheres que havia morrido por febre puerperal.\nNa Primeira Clínica estudavam os alunos de medicina, que realizavam autópsias. Na Segunda Clínica estudavam as parteiras, que não realizam autópsias. A sua hipótese foi: estudantes de medicina carregavam partículas cadavéricas que causavam a febre puerperal. Com essa hipótese, ele instituiu que todos os médicos deveriam lavar as mãos antes dos partos em maio de 1847. Abaixo, seguem os dados de Junho de 1848 até Março 1849, apenas para a Primeira Clínica\n\\[\\begin{array}{c|cc} \\hline \\hbox{Período} & \\hbox{Partos} & \\hbox{Mortes}\\\\ \\hline\n\\hbox{Jun/1847-Dez/1847} & 1841 & 56 \\\\\n\\hbox{Jan/1848-Dez/1848} & 3556 & 45 \\\\\n\\hbox{Jan/1849-Mar/1849} & 1198 & 41 \\\\ \\hline\n\\hbox{Total} & 6.595 & 142 \\\\ \\hline\n\\end{array}\\]\nSeja \\(\\gamma\\) a probabilidade de morte por febre puerperal na Primeira Clínica após a instrução de lavagem das mãos. Sua função de verossimilhança é\n\\[L(\\gamma)\\propto \\gamma^{142}(1-\\gamma)^{6453}.\\] Assumindo a priori Uniforme(0,1) para \\(\\gamma,\\) teremos que \\(\\gamma|\\boldsymbol{x}\\sim\\hbox{Beta}(143,6454)\\). Abaixo, apresentamos o gráfico das três densidades a posteriori obtidas, mostrando que \\(\\gamma\\) é certamente menor que as outras probabilidades.\n\ncurve(dbeta(x,1990,18054),0,.11, lwd = 2,ylab='Densidades a posteriori',xlab='Probabilidade de morte',ylim=c(0,300))\ncurve(dbeta(x,692,17101), lwd = 2, add = T)\ncurve(dbeta(x,143,6454), lwd = 2, add = T)\n\ntext(c(.01,.04,.1),c(250,290,212),c('Primeira Clínica \\n(1847-1849)','Segunda Clínica','Primeira Clínica\\n(1841-1846)'))\n\n\n\n\n\n\n\n\nApós a publicação de seus achados, as ideia do Dr. Semmelweis foram amplamente rejeitadas por seus colegas médicos, que se sentiram ofendidos com a sugestão de que poderiam estar causando a morte de seus pacientes. A rejeição e o ridículo que Semmelweis enfrentou levaram a um declínio em sua saúde mental. Ele foi internado no hospício em 1865, onde morreu pouco tempo depois. Morreu em 13 de agosto de 1865, em um hospício em Viena, aos 47 anos. A causa exata de sua morte ainda é debatida, mas a teoria mais aceita é que ele morreu de septicemia, uma infecção sanguínea, após ser espancado pelos guardas do hospício. \\[\\blacksquare\\]\n\n\n\n\n\nMétodo de Monte Carlo Considere o problema de calcular \\[p=E(X).\\] * Passo 1. Simule \\(x_1,\\ldots,x_B\\) com \\(B\\) suficientemente grande\n\nPasso 2. Estime \\(p\\) através de\n\n\\[\\frac{1}{B}\\sum_{j=1}^B x_j\\]\n\n\n\nPasso 1. Escolha \\(B\\) suficientemente grande\nPasso 2. Simule \\(\\alpha_1,\\ldots,\\alpha_B\\) a posteriori \\(\\alpha|\\hbox{x}\\)\nPasso 3. Simule \\(\\beta_1,\\ldots,\\beta_B\\) a posteriori \\(\\beta|\\hbox{y}\\)\nPasso 4. Calcule\n\n\n\nExample 5.3 Naufrágio do Lusitania (1915)\nEm 7 de maio de 1915, durante a Primeira Guerra Mundial, o RMS Lusitania, um luxuoso transatlântico britânico, navegava a cerca de 18 km da costa sul da Irlanda. A bordo, passageiros de diversas nacionalidades, incluindo muitos americanos, desfrutavam de uma viagem que deveria levá-los de Nova York a Liverpool. No entanto, o que era para ser uma travessia rotineira transformou-se em tragédia quando o navio foi torpedeado pelo submarino alemão U-20.\nAtingido no lado estibordo, o Lusitania sofreu uma segunda explosão interna, cuja causa ainda é debatida, e afundou em apenas 18 minutos. A rapidez com que o navio submergiu, aliada à dificuldade de lançar os botes salva-vidas, resultou na morte de 1.198 pessoas, entre passageiros e tripulantes. O naufrágio do Lusitania gerou indignação internacional e intensificou a pressão para que os Estados Unidos entrassem na guerra, o que ocorreu dois anos depois.\nO número de passageiros que morreram e sobreviveram em cada classe é dado abaixo.\n\\[\\begin{array}{l|cc} \\hline\n\\hbox{Classe} & \\hbox{Sobreviventes} & \\hbox{Mortos} \\\\ \\hline\n\\hbox{Primeira} & 113 & 177 \\\\\n\\hbox{Segunda} & 229 & 372 \\\\\n\\hbox{Terceira}  & 134 & 239 \\\\ \\hline\n\\end{array}\\]\nNeste exemplo, vamos testar a hipótese de que tripulantes da Classe 1 tinham maior probabilidade de sobrevivência que os dados classes inferiores. Seja \\(\\alpha,\\beta,\\gamma\\) as probabilidades de sobrevivência das classes 1, 2 e 3, respectivamente, Considerando uma priori Beta(1,1) para cada classe, teremos que a posteriori para a probabilidade de sobrevivência é dada por\n\n\\(\\alpha\\sim\\)Beta(114,178) para a classe 1\n\\(\\beta\\sim\\)Beta(230,373) para a classe 2\n\\(\\gamma\\sim\\)Beta(135,240) para a classe 3\n\nO gráfico das posterioris é dado abaixo\n\ncurve(dbeta(x, 114,178), lwd = 2, ylim=c(0,20), ylab = 'Densidades das posterioris', xlab = 'Probabilidade de sobrevivência', xlim=c(.2,.6))\ncurve(dbeta(x, 230,373), add = T, col =2, lwd = 2)\ncurve(dbeta(x, 135,240), add = T ,col =3, lwd = 2)\nlegend('topright',c('Classe 1','Classe 2','Classe 3'), lwd =2, col=1:3, bty='n')\n\n\n\n\n\n\n\n\nVamos simular uma amostra de tamanho \\(B=1000000\\) das posterioris de \\(\\alpha,\\beta,\\gamma\\).\n\nB &lt;- 1000000\nalfa &lt;- rbeta(B, 114,178)\nbeta  &lt;- rbeta(B, 230,373)\ngama  &lt;- rbeta(B, 135,240)\n\nVamos testar a hipótese de que a probabilidade de sobrevivência de um indivíduo da Classe 1 foi maior que a de um indivíduo da Classe 2 e 3.\n\nset.seed(123)\nmean(alfa&gt;beta)\n\n[1] 0.600482\n\nmean(alfa&gt;gama)\n\n[1] 0.789385\n\n\nObserve que \\(P(\\alpha&gt;\\gamma|\\hbox{dados})\\approx 0,78\\), o que não dá suporte para afirmar que a probabilidade de sobrevivência dos tripulantes da primeira classe foi maior do que o da terceira. \\[\\blacksquare\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>O modelo Bernoulli</span>"
    ]
  },
  {
    "objectID": "bernoulli.html#o-modelo-multivariado",
    "href": "bernoulli.html#o-modelo-multivariado",
    "title": "5  O modelo Bernoulli",
    "section": "5.2 O modelo multivariado",
    "text": "5.2 O modelo multivariado\nA distribuição Bernoulli pode ser generalizada para o caso multivariado: considere um evento aleatório com possibilidades \\(A_1,\\ldots,A_k\\). Seja \\(X_j=I(A_j)\\) e seja \\(\\theta_j\\) a probabilidade do evento resultar em \\(A_j\\). Então, o vetor \\(\\boldsymbol{X}=(X_1,\\ldots,X_k)\\) tem distribuição Bernoulli multivariada, cuja função de probabilidade é dada por \\[f(\\boldsymbol{x}|\\boldsymbol{\\theta})=\\prod_{j=1}^k\\theta_j^{x_{j}},\\] onde \\(x_j\\in\\{0,1\\}\\), \\(\\sum_{j=1}^kx_j=1\\), \\(\\theta_j\\in(0,1)\\) e \\(\\sum_{j=1}^k\\theta_j=1\\). É importante notar que vetor \\(\\boldsymbol{\\theta}\\) tem apenas \\(k-1\\) parâmetros de fato, uma vez que \\(\\theta_k=1-\\sum_{j=1}^{k-1}\\theta_j\\). Conjuntos do tipo \\[\\mathcal{S}^k=\\left\\{(\\theta_1,\\ldots,\\theta_{k-1}):0&lt;\\theta_j&lt;1,0&lt;\\sum_{j=1}^{k-1}\\theta_j&lt;1\\right\\}\\] são denominados simplex.\nSeja \\(\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_n\\) uma amostra de vetores Bernoulli Multivariada(\\(\\theta_1,\\ldots,\\theta_k\\)), onde \\(\\boldsymbol{x}_i=\\{x_{i,1},\\ldots,x_{i,k}\\}\\). Então,\n\\[\\begin{align}L(\\boldsymbol{\\theta})&=\\prod_{i=1}^nf(\\boldsymbol{x}_i|\\boldsymbol{\\theta})=\\prod_{i=1}^n\\left(\\prod_{j=1}^k \\theta_j^{x_{i,j}}\\right)=\\prod_{j=1}^k \\prod_{i=1}^n\\theta_j^{x_{i,j}}\\\\&=\\prod_{j=1}^k \\theta_j^{\\sum_{i=1}^nx_{i,j}}=\\prod_{j=1}^n\\theta_j^{n_j}\\end{align}\\] onde \\(n_j\\) é o número de vezes que ocorreu a categoria \\(A_j\\). É imediado que\n\\[L(\\boldsymbol{\\theta})=\\exp\\left\\{\\sum_{j=1}^k n_j\\log(\\theta_j)\\right\\},\\] o que implica que este modelo pertence à família exponencial. Seu modelo conjugado é a Dirichlet(\\(a_1,\\ldots,a_k\\)), cuja função densidade é \\[f(\\theta_1,\\ldots,\\theta_k)=\\frac{\\Gamma\\left(\\sum_{j=1}^k a_j\\right)}{\\prod_{j=1}^k \\Gamma(a_j)}\\prod_{j=1}^k \\theta^{a_j-1},\\] onde \\((\\theta_1,\\ldots,\\theta_{k-1})\\) pertence ao simplex \\(\\mathcal{S}^k\\).\nA Dirichlet\\((a_1,\\ldots,a_k)\\) possui as seguintes propriedades:\n\n\\(\\theta_j\\sim\\hbox{Beta}(a_j,\\sum_{i\\neq j}a_i)\\)\n\\((\\theta_1,\\ldots,\\theta_i+\\theta_j,\\ldots,\\theta_k)\\sim\\hbox{Dirichlet}(a_1,\\ldots,a_i+a_j,\\ldots,a_k)\\)\n\nDa primeira propriedade, concluímos que \\[E(\\theta_j)=\\frac{a_j}{\\sum_{i=1}^k a_i},\\;\\;Var(\\theta_j)=\\frac{E(\\theta_j)(1-E(\\theta_j))}{\\sum_{i=1}^k a_i+1}.\\]\nUtilizando o modelo conjugado, a distribuição a posteriori de \\(\\theta_1,\\ldots,\\theta_k\\) é\n\\[f(\\boldsymbol{\\theta}|\\boldsymbol{x})\\propto \\prod_{i=j}^k \\theta_j^{n_j+a_j-1}\\] ou seja, \\(\\boldsymbol{\\theta}|\\boldsymbol{x}\\sim\\hbox{Dirichlet}(n_1+a_1,\\ldots,n_k+a_k)\\). Novamente, pode-se utilizar \\(a_1=\\cdots=a_k=1\\) para obter uma priori pouco informativa.\n\nExample 5.4 Imagem corporal\nO projeto Estado nutricional e sua relação com a imagem corporal em escolares do município de Manaus foi submetido ao LabEst em 2013. Nele, estudantes identificavam como gostaria que fosse o seu corpo segundo a Escala de Stunkard, apresentada na imagem abaixo. Em seguida, uma série de medidas foram realizadas para determinar a real classificação do estudante. Com base nessas informações, cada estudante foi classificado segundo sua satisfação com o próprio corpo do seguinte modo:\n\nSatisfeito: seu desejo é equivalente ao seu estado atual.\nInsatisfeito por excesso: o estudante gostaria ter medidas menores.\nInsatisfeito por magreza: o estudante gostaria ter medidas maiores.\n\n\n\n\nEscala de Stunkard\n\n\nNeste exemplo, vamos analisar o recorte dos resultados para alunos entre 16 e 17 anos, diferenciando entre os sexos. As frequências estão sumariadas na tabela abaixo.\n\\[\\begin{array}{c|ccc|c}\\hline\n&\\hbox{Satisfeito} & \\hbox{Insatisfeito por excesso} & \\hbox{Insatisfeito por magreza} &\\hbox{Total}\\\\ \\hline\n\\hbox{Masculino} & 24 & 10 & 24 & 58 \\\\\n\\hbox{Feminino} & 14 & 22 & 24 & 60 \\\\ \\hline\n\\end{array}\n\\] Cada estudante pode assumir uma das três classificações. Sejam \\(\\alpha_S,\\alpha_E,\\alpha_M\\) as probabilidades de alguém do sexo masculino estar classificado como Satisfeito, Insatisfeito por Excesso ou Insatisfeito por magreza, respectivamente. Então a função de verossimilhança para \\(\\boldsymbol{\\alpha}\\) é\n\\[L(\\boldsymbol{\\alpha})=\\alpha_S^{24}\\alpha_E^{10}\\alpha_M^{24}.\\] Analogamente, fazendo \\(\\boldsymbol{\\beta}=(\\beta_S,\\beta_E,\\beta_M)\\), as mesmas probabilidades para o sexo feminino, teremos que\n\\[L(\\boldsymbol{\\alpha})=\\beta_S^{14}\\beta_E^{22}\\beta_M^{24}.\\]\nUtilizando a priori Dirichlet(1,1,1) tanto para \\(\\boldsymbol{\\alpha}\\) quanto para \\(\\boldsymbol{\\beta}\\), teremos que as respectivas posterioris para \\(\\boldsymbol{\\alpha}\\) e \\(\\boldsymbol{\\beta}\\) são Dirichelt(25,11,25) e Dirichlet(15,23,25).\nAs posterioris para \\(\\alpha_M\\) e \\(\\beta_M\\) e são Beta(25,36) Beta(25,38). As estimativas pontuais são 0,40 e 0,39, respectivamente. A imagem abaixo mostra a insatisfação por magreza entre os sexos deve ser a mesma.\n\ncurve(dbeta(x,25,36), lwd=2, xlab = 'Probabilidade de insatisfação por magreza', ylab= 'Densidades marginais a posteriori', ylim=c(0,8),xlim=c(.1,.8),col='blue')\ncurve(dbeta(x,25,38),add = T, lwd=2, col='red')\ntext(c(.6,.2),c(6,6), c('Masculino','Feminino'),col=c('blue','red'))\n\n\n\n\n\n\n\n\nAs posterioris para \\(\\alpha_E\\) e \\(\\beta_E\\) são Beta(11,50)e Beta(23,40). As estimativas pontuais são 0,21 e 0,36, respectivamente. A imagem abaixo mostra que as mulheres em geral parecem possuir maior probabilidade de insatisfação por excesso.\n\ncurve(dbeta(x,11,50), lwd=2, xlab = 'Probabilidade de insatisfação por excesso', ylab= 'Densidades marginais a posteriori', ylim=c(0,10),xlim=c(0,.6))\ncurve(dbeta(x,23,40),add = T, lwd=2)\ntext(c(.2,.4),c(9,7), c('Masculino','Feminino'))\n\n\n\n\n\n\n\n\nPodemos então construir a hipótese \\(H:\\alpha_E&lt;\\beta_E\\). Abaixo, testamos essa hipótese:\n\nset.seed(123)\nB &lt;- 1000000\nalfaE &lt;- rbeta(B, 11,50)\nbetaE &lt;- rbeta(B, 23,40)\nmean(alfaE&lt;betaE)\n\n[1] 0.990628\n\n\nCom uma probabilidade maior que 99%, há fortes evidências de que mulheres entre 16 e 17 anos se sentem mais insatisfeitas por excesso do que os homens de mesma idade.\n\n\nExample 5.5 Imagem corporal (continuação)\nNeste exemplo, lidaremos apenas com o recorte dos indivíduos do sexo masculino entre 16 e 17 anos, reproduzido abaixo.\n\\[\\begin{array}{c|ccc|c}\\hline\n&\\hbox{Satisfeito} & \\hbox{Insatisfeito por excesso} & \\hbox{Insatisfeito por magreza} &\\hbox{Total}\\\\ \\hline\n\\hbox{Masculino} & 24 & 10 & 24 & 58 \\\\ \\hline\n\\end{array}\n\\]\nConsiderando \\(\\boldsymbol{alpha}=(\\alpha_S,\\alpha_E,\\alpha_M)\\) como definidos anteriormente e utilizando a priori Dirichlet(1,1,1), obtivemos a posteriori \\(\\boldsymbol{\\alpha}\\sim\\hbox{Dirichlet}(25,11,25)\\).\nVamos testar se a probabilidade de insatisfação por magreza é maior do que a por excesso, ou seja \\(H: \\alpha_M&gt;\\alpha_E\\).\n\n#install.packages('extraDistr')\nrequire(extraDistr)\n\nCarregando pacotes exigidos: extraDistr\n\nB &lt;- 10000\nalpha &lt;- rdirichlet(B, c(25,11,25))\nmean( alpha[,3] &gt; alpha[,2])\n\n[1] 0.9893\n\n\nCom uma probabilidade maior que 0,99, existem fortes evidências de que, para um indivíduo do sexo masculino entre 16 e 17 anos, a probabilidade de estar insatisfeito por excesso é menor do que por magreza.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>O modelo Bernoulli</span>"
    ]
  },
  {
    "objectID": "bernoulli.html#exercícios",
    "href": "bernoulli.html#exercícios",
    "title": "5  O modelo Bernoulli",
    "section": "5.3 Exercícios",
    "text": "5.3 Exercícios\n\n5.3.1 Eficácia de um Novo Medicamento\nUma empresa farmacêutica desenvolveu um novo medicamento para tratar enxaquecas. Antes do lançamento, eles afirmam que o medicamento alivia a dor em pelo menos 80% dos pacientes. Um estudo independente com 250 pacientes revelou que 180 deles relataram alívio da dor. Os resultados do estudo fornecem evidências suficientes para rejeitar a alegação da empresa farmacêutica?\n\n\n5.3.2 Preferência por uma Marca de Café\nUma pesquisa de mercado afirma que 55% dos consumidores preferem a marca A de café à marca B. Uma amostra aleatória de 300 consumidores revelou que 180 deles preferem a marca A. Os resultados da amostra fornecem evidências suficientes para rejeitar a alegação da pesquisa de mercado?\n\n\n5.3.3 Taxa de Aprovação em um Exame\nUma escola afirma que a taxa de aprovação em um exame padronizado é de 70%. Uma amostra de 200 alunos revelou que 120 deles foram aprovados. Os resultados da amostra fornecem evidências suficientes para rejeitar a alegação da escola?\n\n\n5.3.4 Eficácia de uma Campanha de Vacinação\nUma campanha de vacinação contra a gripe foi realizada em uma cidade. Antes da campanha, a taxa de vacinação era de 35%. Após a campanha, uma amostra de 400 pessoas revelou que 180 delas foram vacinadas. Os resultados da amostra fornecem evidências suficientes para concluir que a campanha aumentou a taxa de vacinação?\n\n\n5.3.5 A eficácia da Pfizer\nO artigo Polack et al. (2020) apresenta um estudo clínico de fase 3 randomizado e controlado por placebo que avaliou a eficácia da vacina BNT162b2 (Pfizer-BioNTech COVID-19) em participantes com 16 anos ou mais sem evidências de infecção por SARS-CoV-2. A tabela abaixo apresenta o número de participantes por grupo e o número de casos de Covid-19.\n\\[\\begin{array}{l|cc}\\hline\n\\hbox{Grupo} & \\hbox{Participantes} & \\hbox{Casos de Covid-19}\\\\\\hline\n\\hbox{Vacina} & 18.198 & 8 \\\\\n\\hbox{Placebo} & 18.325 & 162 \\\\ \\hline\n\\end{array}\\]\nConsidere que o evento de interesse é contrair Covid-19\n\nEncontre a função de verossimilhança para cada grupo\nUtilizando a priori Beta(1,1) para a probabilidade de contrair Covid-19, encontre a distribuição a posteriori para cada grupo\nFaça um gráfico das posterioris e verifique se há evidências de que a vacinação é eficaz.\n\n\n\n5.3.6 O Naufrágio do Lusitania (1915)\nNeste capítulo, abordamos a tragédia do Lusitania. A tabela abaixo acrescenta os dados sobre a tripulação.\n\\[\\begin{array}{l|cc} \\hline\n\\hbox{Categoria} & \\hbox{Sobreviventes} & \\hbox{Mortos} \\\\ \\hline\n\\hbox{Primeira classe} & 113 & 177 \\\\\n\\hbox{Segunda classe} & 229 & 372 \\\\\n\\hbox{Terceira classe}  & 134 & 239 \\\\ \\hline\n\\hbox{Tripulação - abastecimento} & 139 & 167 \\\\\n\\hbox{Tripulação - engenharia} & 112 & 201 \\\\\n\\hbox{Tripulação - deck} & 41 & 37 \\\\\n\\hline\n\\end{array}\\]\nCompare a probabilidade de sobrevivência entre os indivíduos dos diferentes tipos de tripulação e classes de passageiros, testando as hipóteses necessárias.\n\n\n5.3.7 Imagem corporal\nNeste capítulo, mostramos que homens e mulheres com idades entre 16 e 17 anos possuem expectativas diferentes em relação ao seu próprio corpo.\nNeste exercício, você vai verificar como essas expectativas variam dentro do mesmo sexo. Especificamente:\n\nTeste se há evidências de que os homens possuem probabilidade maior de estarem insatisfeitos por magreza do que satisfeitos.\nTeste se há evidências de que as mulheres possuem probabilidade maior de estarem insatisfeitas por excesso do que satisfeitas.\n\n\n\n\n\nPolack, Fernando P, Stephen J Thomas, Nicholas Kitchin, Judith Absalon, Alejandra Gurtman, Stephen Lockhart, John L Perez, et al. 2020. “Safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine.” New England Journal of Medicine 383 (27): 2603–15.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>O modelo Bernoulli</span>"
    ]
  },
  {
    "objectID": "teste.html",
    "href": "teste.html",
    "title": "6  Testes de hipóteses",
    "section": "",
    "text": "6.1 Testes baseados na teoria da decisão",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#testes-baseados-na-teoria-da-decisão",
    "href": "teste.html#testes-baseados-na-teoria-da-decisão",
    "title": "6  Testes de hipóteses",
    "section": "",
    "text": "6.1.1 A Função de Perda 0-1\nConsidere que \\(X_1,\\ldots,X_n\\) é uma amostra do modelo \\(F(.|\\theta)\\). Seja \\(H_0:\\theta\\in\\Theta_0\\) a hipótese nula.\nUm teste de hipóteses é uma regra \\(\\varphi(x)\\) que recebe o valor 1 se a hipótese \\(H_0\\) é aceita e 0 em caso contrário.\nEm relação à natureza da hipótese, observe que \\[I(\\theta\\in\\Theta_0)=\\left\\{\\begin{array}{ll}1,&\\hbox{ se }H_0\\hbox{ é verdadeira}\\\\0,&\\hbox{ se }H_0\\hbox{ é falsa}\\end{array}\\right..\\]\nNovamente, considere a função de perda quadrática:\n\\[ \\mathcal{L}(\\theta,\\varphi)=(\\varphi(x)-I(\\theta\\in\\Theta_0))^2.\\] Definida deste modo, esta função também é denominada Função de Perda 0-1, uma vez que ela assume o valor 0 quando uma decisão correta é tomada e 1 caso contrário.\nA esperança a posteriori desta função de perda é\n\\[E_{\\theta|X}(\\mathcal{L}(\\theta,\\varphi))=\\int \\left(\\phi(x)- I(\\theta\\in\\Theta_0)\\right)^2 f(\\theta|x)d\\theta\\]\ne o estimador de Bayes é o valor de \\(\\varphi\\) que minimiza a esperança acima. Como \\(\\varphi\\) é uma indicadora, teremos duas situações:\n\nSe \\(\\phi(x)=0\\), então\n\n\\[\\begin{align}E_{\\theta|X}(\\mathcal{L}(\\theta,\\varphi))&=\\int I(\\theta\\in\\Theta_0)^2 f(\\theta|x)d\\theta\\\\&=\\int I(\\theta\\in\\Theta_0) f(\\theta|x)d\\theta\\\\&=\\int_{\\Theta_0 }f(\\theta|x)d\\theta=P(\\theta\\in\\Theta_0|x)\\end{align}\\]\n\nSe \\(\\phi(x)=1\\), então\n\n\\[\\begin{align}E_{\\theta|X}(\\mathcal{L}(\\theta,\\varphi))&=\\int (1-I(\\theta\\in\\Theta_0)^2 f(\\theta|x)d\\theta\\\\&=\\int I(\\theta\\in\\Theta_0^c) f(\\theta|x)d\\theta\\\\&=\\int_{\\Theta_0^c }f(\\theta|x)d\\theta=P(\\theta\\notin\\Theta_0|x)\\end{align}\\]\nDeste modo, se \\(P(\\theta\\in\\Theta_0|x)&gt;P(\\theta\\in\\Theta_0^c|x)\\), temos que \\(\\phi(\\boldsymbol{x})=1\\) é a decisão que minimiza a perda a posteriori, ou seja, aceitamos \\(H_0\\). Em caso contrário, rejeitamos \\(H_0\\).\n\nExample 6.1 Fast food\nUma cadeia de fast food deseja saber se vale a pena trocar seus freezers tradicionais, que mantém a carne entre -\\(17^o\\)C e \\(-9^oC\\) por um com uma nova tecnologia (e mais cara!) que mantém a temperatura consistentemente em \\(-17^oC\\). Para tomar essa decisão, 32 bifes foram armazenados por 8 meses, sendo 16 bifes colocados no freezer tradicional e 16 no novo. Em seguida, um chefe preparou os 32 bifes de maneira idêntica e 16 clientes foram escolhidos ao acaso para avaliar o sabor dos bifes. Cada cliente recebeu um bife de cada freezer, mas a prova foi realizada às cegas.\nPodemos considerar a variável \\(Y_i=1\\) se o \\(i\\)-ésimo cliente preferiu o bife armazenado no freezer mais caro e \\(Y_i=0\\) em caso contrário. Deste modo, \\(Y_1,\\ldots,Y_{16}|\\theta\\sim\\hbox{Bernoulli}(\\theta)\\). Claramente, estamos interessados em testar \\(H_0:\\theta&gt;1/2\\).\nConsidere as seguintes prioris:\n\n\n\n\n\n\n\n\n\nA distribuiação a priori Beta(.5,.5) dá mais massa para valores extremos, o que poderia favorecer a hipótese \\(H_0\\). A priori Beta(1,1) é aquela que parece não dar qualquer preferência. Por último, a priori Beta(2,2) pode ser vista como uma leve resistência à rejeitar que os dois armazenamentos são iguais.\nDos 16 clientes, 13 preferiram os bifes que foram armazenados com a tecnologia mais cara. Como as três prioris acima são casos particulares da distribuição Beta\\((a,b)\\), decidiremos sobre \\(H_0\\) calculando\n\\[P(\\theta&gt;1/2|\\textbf{y})=\\int_0^{1/2}\\frac{\\theta^{13+a-1}(1-\\theta)^{3+b-1}}{B(13+a,3+b)}\\]\nque pode ser facilmente obtida com o comando pbeta(.5,13+a,3+b, lower.tail =F) Temos os seguintes resultados:\n\n\n\nPriori\n\\(P(H_0|\\textbf{y})\\)\n\n\n\n\nBeta(.5,.5)\n0,995\n\n\nUniforme\n0,993\n\n\nBeta(2,2)\n0,990\n\n\n\nConsiderando as prioris acima, a probabilidade a posteriori da hipótese nula é de pelo menos 0,99, o que nos leva a concluir que o sabor da carne é melhor preservado no freezer com alta tecnologia\n\n\n\n6.1.2 A Função de Perda a-b\nSuponha que \\(P(\\theta\\in\\Theta_0|\\boldsymbol{x})=0,51\\). Segundo a Função de Perda 0-1, deveríamos aceitar \\(H_0\\), uma vez que\n\\[P(\\theta\\in\\Theta_0|\\boldsymbol{x})=0,51&gt;0,49=P(\\theta\\in\\Theta_0^c|\\boldsymbol{x})\\]\nIsto ocorre porque a perda associada ao erro no teste de hipóteses é igual para qualquer decisão. Podemos associar valores diferentes, reforçando que um erro é mais sério que o outro.\nConsidere que rejeitar \\(H_0\\) quando ela é verdadeira (erro tipo I) gera uma perda \\(a\\), enquanto que aceitar \\(H_0\\) quando ela é falsa (erro tipo II) gera uma perda \\(b\\). Para o erro mais grave, associamos um valor maior para a perda. A função de perda respectiva é denominada Perda \\(a-b\\) e é dada por\n\\[\\mathcal{L}(\\theta,\\varphi)=\\left\\{\\begin{array}{l}0,\\hbox{ se }\\varphi(x)=I(\\theta\\in\\Theta_0)\\\\\na,\\hbox{ se }\\varphi(x)=0\\hbox{ e }\\theta\\in\\Theta_0\\\\b,\\hbox{ se }\\varphi(x)=1\\hbox{ e }\\theta\\notin\\Theta_0\\end{array}\\right.\\]\nA média a posteriori dessa função de perda é\n\\[E_{\\theta|\\boldsymbol{x}}(\\mathcal{L}(\\theta,\\varphi))=a\\int_{\\Theta_0}I(\\varphi(x)=0)f(\\theta|x)d\\theta+b\\int_{\\Theta_0^c}I(\\varphi(x)=1)f(\\theta|x)d\\theta\\]\n\nSe \\(\\varphi(x)=1\\), teremos \\[E_{\\theta|x}(\\mathcal{L}(\\theta,\\varphi))=b\\int_{\\Theta_0^c}I(\\varphi(x)=1)f(\\theta|\\boldsymbol{x})d\\theta=bP(\\theta\\in\\Theta_0^c|x)\\]\nSe \\(\\varphi(x)=0\\) teremos \\[E_{\\theta|x}(\\mathcal{L}(\\theta,\\varphi))=a\\int_{\\Theta_0}I(\\varphi(x)=0)f(\\theta|x)d\\theta=aP(\\theta\\in\\Theta_0|x)\\] logo:\nSe \\(bP(\\theta\\in\\Theta_0^c|x)&gt;aP(\\theta\\in\\Theta_0|x)\\) então a decisão minimiza a perda a posteriori é \\(\\varphi(\\boldsymbol{x})=0\\), ou seja, rejeitamos \\(H_0\\).\nSe \\(bP(\\theta\\in\\Theta_0^c|x)&lt;aP(\\theta\\in\\Theta_0|x)\\) então a decisão minimiza a perda a posteriori é \\(\\varphi(\\boldsymbol{x})=1\\), ou seja, aceitamos \\(H_0\\).\n\nNa prática, aceitamos \\(H_0\\) se \\[P(\\theta\\in\\Theta_0|\\boldsymbol{x})&gt;\\frac{b}{b+a}\\]\nObserve que, diferente do ponto de vista frequentista, estamos interessados em aceitar a hipótese \\(H_0\\). Deste modo, o erro tipo II é o mais preocupante, o que implica em \\(b&gt;a\\). Na prática, fixamos um valor para \\(b/(a+b)\\), como 0,95 ou 0,99 e comparamos com \\(P(\\theta\\in\\Theta_0|\\boldsymbol{x})\\) para decidir se aceitamos \\(H_0\\).\n\nExample 6.2 Mudança de opinião\nDurante a eleição presidencial americana de 1980 um estudo foi conduzido para determinar se um debate televisionado foi capaz de mudar as preferências dos telespectadores pelos candidatos. Foram selecionados 75 adultos aleatoriamente e sua preferência entre os dois candidatos foi registrada. Após a conclusão do detabe, foi perguntado para as mesmas 75 pessoas a sua preferência entre os dois candidatos. Os resultados estão sumariados abaixo.\n\\[\\begin{array}{c|c|c}\\hline\n\\text{Preferência antes } & \\text{Preferência depois} & \\text{Resultado} \\\\  \n\\text{do debate} & \\text{do debate} & \\\\ \\hline\n\\text{Carter} & \\text{Carter} & 28 \\\\\n\\text{Carter} & \\text{Reagan} & 13 \\\\\n\\text{Reagan} & \\text{Reagan} & 27 \\\\\n\\text{Reagan} & \\text{Carter} & 7 \\\\ \\hline\n\\end{array}\\]\nNeste exemplo, vamos testar se os dois candidatos foram igualmente capazes de mudar a opinião dos eleitores.\nSabemos que 20 eleitores mudaram de opinição\n\n\\(\\theta_{CC}\\): a probabilidade do indivíduo preferir o candidato Carter antes de depois do debate\n\\(\\theta_{RR}\\): a probabilidade do indivíduo preferir o candidato Reagan antes de depois do debate\n\\(\\theta_{CR}\\): a probabilidade do indivíduo preferir o candidato Carter e depois mudar para o Reagan.\n\\(\\theta_{RC}\\): a probabilidade do indivíduo preferir o candidato Reagan e depois mudar para o Carter.\n\nA função de verossimilhança para \\(\\boldsymbol{\\theta}=(\\theta_{CC},\\theta_{CR},\\theta_{RC},\\theta_{RR})\\) é\n\\[L(\\boldsymbol{\\theta})\\propto \\theta_{CC}^{28}\\theta_{CR}^{13}\\theta_{RR}^{27}\\theta_{RC}^{7}.\\]\nConsiderando a priori \\(\\boldsymbol{\\theta}\\sim\\hbox{Dirichlet}(1,1,1,1)\\), teremos a posteriori\n\\[\\boldsymbol{\\theta}\\sim\\hbox{Dirichlet}(29,14,28,8),\\]\nEstamos interessados nas probabilidades sobre mudança de opinião, ou seja, em \\(\\theta_{CR}\\) e \\(\\theta_{RC}\\), cujas posterioris são \\[\\begin{align}\n\\theta_{CR}&\\sim\\hbox{Beta}(14,65)\\\\\n\\theta_{RC}&\\sim\\hbox{Beta}(7,68)\n\\end{align}\\]\nAbaixo, apresentamos as posterioris de \\(\\theta_{CR}\\) e \\(\\theta_{RC}\\). Pode-se observar que o candidato Reagan parece ter certa vantagem.\n\ncurve(dbeta(x,14,65), ylim=c(0,15), xlim=c(0,.5), xlab= 'Probabilidade de mudança', ylab='Densidade a posteriori', lwd = 2)\ncurve(dbeta(x,7,68), add = T, lwd = 2, lty = 2)\nlegend('topright',c('Mudança em favor do Reagan', 'Mudança em favor do Carter'), lwd=2, lty=1:2, bty='n')\n\n\n\n\n\n\n\n\nVamos testar se o debate do candidato Reagan foi mais eficaz para provocar a mudança de opinião, ou seja, \\(H:\\theta_{RC}&lt;\\theta_{CR}\\).\n\nrequire(extraDistr)\n\nCarregando pacotes exigidos: extraDistr\n\nB &lt;- 20000\ntheta &lt;- rdirichlet(B, c(29,14,28,8))\nthetaCR &lt;- theta[,2]\nthetaRC &lt;- theta[,4]\nmean(thetaRC &lt; thetaCR)\n\n[1] 0.9071\n\n\nNão há evidência forte o suficiente para aceitar a superioridade do Reagan para a mudança de opinião. Abaixo, mostramos o gráfico estimado para a posteriori de \\(\\theta_{CR},\\theta_{RC}\\).\n\nrequire(MASS)\n\nCarregando pacotes exigidos: MASS\n\ncontour(kde2d(thetaCR,thetaRC), xlab=expression(theta[CR]),ylab=expression(theta[RC]), lwd = 2)\nabline(0,1,lty=2, lwd = 2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#testes-utilizando-modelos",
    "href": "teste.html#testes-utilizando-modelos",
    "title": "6  Testes de hipóteses",
    "section": "6.2 Testes utilizando modelos",
    "text": "6.2 Testes utilizando modelos\nConsidere novamente o problema dos freezers, da seção anterior. Note que a teoria desenvolvida acima não consegue testar \\(H_0:\\theta=1/2\\), uma vez que este evento possui probabilidade nula a priori.\nPara contornar este problema, suponha que existem dois modelos concorrentes:\n\nModelo \\(M_0\\): \\(y_i\\sim\\hbox{Bernoulli}(1/2)\\)\nModelo \\(M_1:\\)\n\n\\[\\begin{align}\ny_i|\\theta&\\sim\\hbox{Bernoulli}(\\theta),\\\\\n\\theta&\\sim\\hbox{Uniforme}(0,1)\\end{align}\\]\nSeja \\(M_0\\) o evento no qual o modelo \\(M_0\\) é o verdadeiro gerador da amostra. Observe que \\[f(y_1,\\ldots,y_{16}|M_0)=\\prod_{i=1}^{16}f(y_i|M_0)=\\left(\\frac{1}{2}\\right)^{16}\\]\nJá para o modelo \\(M_1\\), observe que\n\\[\\begin{align}f(y_1,\\ldots,y_{16}|M_1)&=\n\\int_0^1 f(y_1,\\ldots,y_{16}|\\theta)f(\\theta)d\\theta\\\\\n&=\\int_0^1 \\prod_{i=1}^{16}f(y_i|\\theta)f(\\theta)d\\theta\\\\\n&=\\int_0^1 \\prod_{i=1}^{16}\\theta^{y_i}(1-\\theta)^{1-y_i}d\\theta\\\\\n&=\\int_0^1\\theta^{\\sum_{i=1}^{16}y_i}(1-\\theta)^{16-\\sum_{i=1}^{16}y_i}d\\theta=B\\left(\\sum_{i=1}^{16}y_i+1,16-\\sum_{i=1}^{16}y_i+1\\right),\\end{align}\\] onde \\(B(.,.)\\) é a função beta.\nSejam \\(P(M_0)\\) e \\(P(M_1)=1-P(M_0)\\) as probabilidades a priori dos modelos \\(M_0\\) e \\(M_1\\). Então, a probabilidade a posteriori do modelo \\(M_0\\) é dada por\n\\[P(M_0|y_1,\\ldots,y_{16})=\\frac{\\left(\\frac{1}{2}\\right)^{16}P(M_0)}{\\left(\\frac{1}{2}\\right)^{16}P(M_0)+B\\left(\\sum_{i=1}^{16}y_i+1,16-\\sum_{i=1}^{16}y_i+1\\right)P(M_1)}\\] Ainda considerando o exemplo anterior, assumindo \\(P(M_0)=P(M_1)=1/2\\) e lembrando que \\(\\sum_i y_i=13\\), tem-se\n\\[P(M_0|y_1,\\ldots,y_{16})=\\frac{\\left(\\frac{1}{2}\\right)^{17}}{\\left(\\frac{1}{2}\\right)^{17}+B\\left(14,4\\right)\\frac{1}{2}}\\approx0,1268,\\] o que nos leva a rejeitar \\(H_0\\).\n\nCaso geral.\nPara a amostra \\(x_1,\\ldots,x_n\\), sejam \\(M_1,\\ldots,M_k\\) \\(k\\) modelos paramétricos. Sejam \\(\\boldsymbol{\\theta}_1,\\ldots,\\boldsymbol{\\theta}_k\\), e \\(f(\\boldsymbol{\\theta}_1),\\ldots,f(\\boldsymbol{\\theta}_k)\\) seus respectivos parâmetros e prioris. Para determinar o modelo mais adequado:\n\nAtribua os valores a priori para \\(P(M_1),\\ldots,P(M_k)\\)\nPara \\(j=1,\\ldots,k\\), calcule \\[f(x_1,\\ldots,x_n|M_j)=\\int f(x_1,\\ldots,x_n|\\theta_j)f_j(\\theta_j)d\\theta_j\\]\nCompute\n\n\\[P(M_j|x_1,\\ldots,x_n)=\\frac{f(x_1,\\ldots,x_n|M_j)P(M_j)}{\\sum_{i=1}^k f(x_1,\\ldots,x_n|M_i)P(M_i)}\\]\n\nConsidere como adequado o modelo com maior probabilidade a posteriori\n\n\n\nDistribuição preditiva para o caso Bernoulli multivariado\nA distribuição \\[f(x)=\\int L(\\theta)f(\\theta)d\\theta=E(L(\\theta))\\] é denominada preditiva. Se \\(\\boldsymbol{X}|\\boldsymbol{\\theta}\\sim\\hbox{Bernoulli}(\\theta_1,\\ldots,\\theta_k)\\) e considerando o modelo conjugado \\(\\boldsymbol{\\theta}\\sim\\hbox{Dirichlet}(\\theta_1,\\ldots,\\theta_k)\\), teremos que\n\\[\\begin{align}\nf(x)&=\\int_{\\mathcal{S}^k}\\prod_{j=1}^k\\theta_j^{n_j}\\frac{\\Gamma(\\sum_{j=1}^k a_j)}{\\prod_{j=1}^k \\Gamma(a_j)}\\prod_{j=1}^k \\theta_j^{a_j-1}d\\boldsymbol{\\theta}\\\\\n&=\\frac{\\Gamma(\\sum_{j=1}^k a_j)}{\\prod_{j=1}^k \\Gamma(a_j)}\\int_{\\mathcal{S}^k}\\prod_{j=1}^k\\theta_j^{n_j+a_j-1}d\\boldsymbol{\\theta}\\\\\n&=\\frac{\\Gamma(\\sum_{j=1}^k a_j)}{\\Gamma(n+\\sum_{j=1}^k a_j)}\\prod_{j=1}^k\\frac{\\Gamma(a_j+n_j)}{\\Gamma(a_j)}\n\\end{align}\\]\nAlém disso, se \\(a_1=\\cdots=a_k=1\\), então\n\\[f(x)=\\frac{(k-1)!}{(n+k-1)!}\\prod_{j=1}^k n_j!\\]\n\n\nExample 6.3 Imagem corporal\nConsidere novamente os dados sobre imagem corporal em escolares entre 16 e 17 anos, vistos no capítulo anterior e reproduzidos novamente abaixo.\nvamos analisar o recorte dos resultados para alunos entre 16 e 17 anos, diferenciando entre os sexos. As frequências estão sumariadas na tabela abaixo.\n\\[\\begin{array}{c|ccc|c}\\hline\n&\\hbox{Satisfeito} & \\hbox{Insatisfeito por excesso} & \\hbox{Insatisfeito por magreza} &\\hbox{Total}\\\\ \\hline\n\\hbox{Masculino} & 24 & 10 & 24 & 58 \\\\\n\\hbox{Feminino} & 14 & 22 & 24 & 60 \\\\ \\hline\n\\end{array}\n\\]\nAnteriormente, assumimos que as probabilidades entre os sexos deveriam ser diferentes. Denotamos por \\(\\alpha_S,\\alpha_E,\\alpha_M\\) a probabilidade de um indivíduo do sexo masculino ser classificado como Satisfeito, Insatisfeito por Excesso e Insatisfeito por Magreza. Também denotamos por \\(\\beta_S,\\beta_E,\\beta_M\\) as mesmas probabilidades para o sexo feminino. Por último, Utilizamos a priori Dirichlet(1,1,1) para ambos os sexos. Vamos denotar esse modelo por \\(M_1\\).\nSeja \\(x=(24,10,24)\\) as informações registradas para o sexo masculino e \\(y=(14,22,24)\\) as informações para o sexo feminino. Então\n\\[\\begin{align}\nf(x,y|M_1)&=f(x|M_1)f(y|M_1)\\\\\n&=\\left[\\frac{2!}{60!}24!10!24!\\right]\\left[\\frac{2!}{62!}14!22!24!\\right]\n\\end{align}\\]\nConsidere agora o modelo \\(M_2\\), no qual não há diferença entre os sexos. Nesse caso, \\(x\\) e \\(y\\) são provenientes do mesmo modelo, com probabilidades \\(\\gamma_S,\\gamma_E,\\gamma_M\\), respectivamente. Utilizando a priori Dirichlet(1,1,1), teremos\n\\[\\begin{align}f(x,y|M_2)&=\\frac{2!}{120!}38!32!48!\\end{align}\\]\nVamos assumir a priori que \\(P(M_1)=P(M_2)=1/2\\). Então, vamos testar se não há diferença na percepção da imagem corporal entre os sexos:\n\\[P(M_2|x,y)=\\frac{P(x,y|M_2)}{P(x,y|M_1)+P(x,y|M_2)}\\]\nVamos realizar esse cálculo no R:\n\n\\(P(x,y|M_1)\\):\n\n\n# logaritmo da probabilidade:\nlprobA &lt;- lfactorial(2)-lfactorial(60)+sum(lfactorial(c(24,10,24)))\nlprobB &lt;- lfactorial(2)-lfactorial(62)+sum(lfactorial(c(14,22,24)))\n# probabilidade\nm1 &lt;- exp(lprobA +lprobB)\n\n\n\\(P(x,y|M_2)\\):\n\n\n# logaritmo da probabilidade:\nlprob &lt;- lfactorial(2)-lfactorial(120)+sum( lfactorial(c(38,32,48)))\n# probabilidade\nm2 &lt;- exp(lprob)\n\n\n\\(P(M_2|x,y)\\)\n\n\nm2 / (m1 + m2)\n\n[1] 0.2824985\n\n\nPortanto, ficamos com o modelo que assume diferença entre os sexos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#o-fator-de-bayes",
    "href": "teste.html#o-fator-de-bayes",
    "title": "6  Testes de hipóteses",
    "section": "6.3 O Fator de Bayes",
    "text": "6.3 O Fator de Bayes\nAnteriormente, vimos que para uma coleção de \\(k\\) modelos competidores, o modelo \\(M_j\\) é preferível aos demais se \\[P(M_j|x)&gt;P(M_i|x).\\] para todo \\(i\\neq j\\). Observe que\n\\[\\begin{align}P(M_j|x)&=\\frac{f(x|M_j)P(M_j)}{\\sum_{i=1}^kf(x|M_j)P(M_j)}\\\\&=P(M_j)\\left[P(M_j)+\\sum_{i\\neq j}\\frac{f(x|M_i)}{f(x|M_j)}P(M_i)\\right]^{-1}\\\\\n&=P(M_j)\\left[P(M_j)+\\sum_{i\\neq j}B_{ij}(x)P(M_i)\\right]^{-1}\\end{align}\\] onde a quantidade \\[B_{ij}(x)=\\frac{f(x|M_i)}{f(x|M_j)},\\] denominada Fator de Bayes, sumariza a informação da amostra para relacionar os modelo \\(M_i\\) e \\(M_j\\).\nPara auxiliar na interpretação do Fator de Bayes, considere o caso com apenas dois modelos onde \\(P(M_1)=P(M_2)\\). Então \\[\\begin{align}P(M_1|x)&=\n&=\\left[1+B_{21}(x)\\right]^{-1}\\end{align}\\] Observe que, quanto maior for o valor \\(B_{21}(x)\\), menor será a evidência a favor do modelo \\(M_1\\).\nA escala de Jeffreys pode ser útil para tomada de decisão:\n\\[\\begin{array}{cl}\\hline B_{01}(x) & \\text{Interpretação}\\\\ \\hline\n&gt;100 & \\text{Evidência decisiva para } H_0 \\\\\n30-100 & \\text{Evidência muito forte para } H_0 \\\\\n10-30 & \\text{Evidência forte para } H_0 \\\\\n3-10 & \\text{Evidência substancial para } H_0 \\\\\n1-3 & \\text{Evidência fraca para } H_0 \\\\\n1/3-1 & \\text{Evidência fraca contra } H_0 \\\\\n1/10-1/3 & \\text{Evidência substancial contra } H_0 \\\\\n1/30-1/10 & \\text{Evidência forte contra } H_0 \\\\\n1/100-1/30 & \\text{Evidência muito forte contra } H_0 \\\\\n&lt;1/100 & \\text{Evidência decisiva contra } H_0 \\\\ \\hline\n\\end{array}\\]\nNote que, se \\(M_0\\) é equivalente à \\(\\theta_0\\) e \\(M_1\\) é equivalente à \\(\\theta=\\theta_1\\), então o Fator de Bayes se torna a estatística do teste de Neyman-Pearson\n\\[B_{01}(x)=\\frac{f(x|\\theta_0)}{f(x|\\theta_1)}.\\]\n\nExample 6.4 Imagem corporal\nConsiderando \\(M_1\\) como o modelo no qual as percepções sobre o corpo são provenientes de populações distintas e \\(M_2\\) como o modelo no qual não havia diferença entre os grupos delimitados pelo sexo, obtivemos \\(P(M_2|x,y)\\approx 0,28\\). Utilizando os mesmos comandos em R, teremos que o Fator de Bayes \\(B_{21}\\) é dado por\n\nm2/m1\n\n[1] 0.3937254\n\n\nque gera evidência fraca em favor de \\(M_1\\).\n\n\nExample 6.5 Pesquisa Quaest\nUma pesquisa foi realizada entre os dias 27 e 31 de março de 2025 e ouviu 2.024 eleitores presencialmente. Uma das perguntas foi: O quão frustrado você está com o governo Lula hoje? As opções eram 1) Muito frustrado, (2) Pouco frustrado, (3), Nada frustrado e (4) Não sabe/Não respondeu.\n\n\n\n\n\n\n\n\nCategoria\nPercentual de respostas\nNúmero de pessoas (N=2024)\n\n\n\n\nMuito frustrado\n36%\n729\n\n\nPouco frustrado\n31%\n627\n\n\nNada frustrado\n30%\n607\n\n\nNão sabe/Não responderam\n3%\n61\n\n\n\nObserve que esta é uma pergunta tendenciosa, com uma opção neutra e duas negativas.\nDesconsiderando a categoria dos que não responderam, seja \\(\\boldsymbol{\\theta}=(\\theta_M,\\theta_P,\\theta_N)\\) as probabilidades do indivíduo estar muito, pouco ou nada frustrado, respectivamente.\nConsidere inicialmente o modelo, denotado por \\(M_1\\), no qual os entrevistados respondem esta pergunta ao acaso, ou seja \\(\\theta_M=\\theta_P=\\theta_N=1/3\\). Então\n\\[P(M_1|\\text{dados})=\\left(\\frac{1}{3}\\right)^{2024}\\]\nEm seguida considere o modelo \\(M_2\\), no qual a verossimilhança é dada por \\[L(\\boldsymbol{\\theta})\\propto \\theta_M^{729}\\theta_P^{627}\\theta_N^{607}.\\] Escolhendo a priori \\(\\boldsymbol{\\theta}\\sim\\hbox{Dirichlet}(1,1,1)\\), teremos\n\\[P(\\text{Dados}|M_2)=\\frac{2}{2026!}(729!)(627!)(607!)\\]\nO fator de Bayes \\(B_{21}\\) é dado por\n\n# logP(dados|M2)\nlogPm2 &lt;- -2024*log(3)\n\n# logP(dados|M1)\nlogPm1 &lt;- log(2)+sum(lfactorial( c(729,627,607)))-lfactorial(1965)\n\n# Fator de Bayes\nexp( logPm2 - logPm1)\n\n[1] 1.02445e-29\n\n\nO fator de Bayes é muito pequeno, indicando que a hipótese de que as três probabilidades são iguais não é verdadeira.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "teste.html#exercícios",
    "href": "teste.html#exercícios",
    "title": "6  Testes de hipóteses",
    "section": "6.4 Exercícios",
    "text": "6.4 Exercícios\n\n6.4.1 Mudança de opinião sobre vacinação\nUma pesquisadora está investigando a eficácia de uma nova campanha de saúde pública para aumentar a adesão à vacinação contra a gripe em uma determinada comunidade. Ela seleciona uma amostra de 100 indivíduos e registra se cada um tomou a vacina na temporada anterior (Antes da Campanha) e na temporada atual (Depois da Campanha). Os resultados estão apresentado abaixo.\n\n\n\n\n\n\n\n\n\n\nVacinado Depois\nNão Vacinado Depois\nTotal\n\n\n\n\nVacinado Antes\n15\n5\n20\n\n\nNão Vacinado Antes\n40\n40\n80\n\n\nTotal\n55\n45\n100\n\n\n\nVerifique se a campanha teve um efeito na adesão à vacinação.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Testes de hipóteses</span>"
    ]
  },
  {
    "objectID": "poisson.html",
    "href": "poisson.html",
    "title": "7  O modelo Poisson",
    "section": "",
    "text": "7.1 Sobre o modelo\nSeja \\(N(t)\\) o número de ocorrências observadas no intervalo de tempo \\([0,t]\\) (considere que \\(N(0)=0\\)). Note que o número de eventos no intervalo \\((s,t]\\) é dado por \\(N(t)-N(s)\\).\nDizemos que \\(N(t)\\) tem incrementos independentes se, para quaisquer intervalos disjuntos \\((s_0,t_0]\\) e \\((s_1,t_1]\\), as contagens \\(N(t_0)-N(s_0)\\) e \\(N(t_1)-N(s_1)\\) são independentes.\n\\(N(t)\\) é denominado Processo de Poisson quando ele possui incrementos indepentes e, para qualquer intervalo \\((s,t]\\),\n\\[P(N(t)-N(s)=x)=\\frac{e^{-\\lambda(t-s)[\\lambda(t-s)]^x}}{x!},\\] onde \\(x=0,1,\\ldots\\) e \\(\\lambda&gt;0\\). Isto implica que \\[E(N(t))=\\lambda t,\\] ou seja, o número esperado de ocorrências até o tempo \\(t\\) é diretamente proporcional à \\(t\\) e \\(\\lambda\\) representa a taxa de crescimento. Para este processo, é verdade que \\[\\lim_{\\delta\\rightarrow 0}P(N(t+\\delta)-N(t)&gt;1)=0,\\] ou seja, não é possível observar duas ou mais ocorrências simultaneamente.\nEm geral, os experimentos são desenhados para registrar contagens em intervalos regulares e disjuntos de tempo, como semanas ou anos. Considere que tais intervalos são \\([0,s_1],(s_1,s_2],\\ldots,(s_{n-1},t]\\) e seja \\(c\\) o comprimento destes intervalos. Em geral, os dados são apresentados como contagens dentro destes intevalos, gerando as seguintes variáveis:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>O modelo Poisson</span>"
    ]
  },
  {
    "objectID": "poisson.html#sobre-o-modelo",
    "href": "poisson.html#sobre-o-modelo",
    "title": "7  O modelo Poisson",
    "section": "",
    "text": "\\(X_1=N(s_1)\\sim\\hbox{Poisson}(\\lambda c)\\)\n\\(X_2=N(s_2)-N(s_1)\\sim\\hbox{Poisson}(\\lambda c)\\)\n\\(\\cdots\\)\n\\(X_n=N(t)-N(s_{n-1})\\sim\\hbox{Poisson}(\\lambda c)\\) ou seja, \\(X_1,\\ldots,X_n\\) são uma amostra aleatória do modelo Poisson(\\(\\lambda c\\)). Na prática, \\(c=1\\) por ser a unidade de medida de tempo associada ao experimento (uma semana, um ano, etc).\n\n\n7.1.1 Tempo de chegada e de espera\nPara um processo de Poisson \\(N(t)\\), definimos o tempo de chegada como o tempo entre duas observações consecutivas. Denotaremos o tempo de chegadas entre a \\(i\\)-ésima e a \\((i-1)\\)- ésima ocorrência por \\(T_i\\).\nÉ possível mostrar que \\(T_i\\) é independente de \\(T_j\\), para \\(i\\neq j\\) e que \\(T_i\\sim\\hbox{Exponencial}(\\lambda)\\). Por isso, para uma amostra aleatória de um modelo Exponencial(\\(\\lambda\\)), o parâmetro \\(\\lambda\\) é denominado taxa.\nDefinimos por tempo de espera da ocorrência \\(n\\) como o tempo transcorrido desde o início do processo até a ocorrência do \\(n\\)-ésimo evento. Este tempo de espera é denotado por \\(S_n\\). Exsitem dois resultados importantes relacionados ao tempo de espera:\n\n\\(S_n=T_1+\\cdots+T_n\\) tem distribuição Gama(\\(n,\\lambda\\))\nDado que \\(N(t)=n\\), os tempos de espera dos eventos estão uniformemente distribuídos dentro do intervalo \\((0,t)\\).\n\n\n\n7.1.2 Ocorrências de diversas classes\nSuponha que as ocorrências observadas podem ser classificadas em \\(k\\) categorias. Suponha que qualquer ocorrência tem probabilidade \\(p_j\\) de pertencer a categoria \\(j\\). Então\n\nO número de ocorrências da classe \\(j\\) é um processo de Poisson com taxa \\(\\lambda p_j\\)\nO número de ocorrências da classe \\(j\\) é independente do número de ocorrências da classe \\(i\\), com \\(i\\neq j\\)\n\n\n\n7.1.3 O processo de Poisson Espacial\nSeja \\(N(A)\\) o número de ocorrências observadas em uma região de área \\(A\\). \\(N(A)\\) é denominado Processo de Poisson Espacial quando \\(N(A)\\sim\\hbox{Poisson}(\\lambda A)\\) e, para duas regiões distintas de áreas \\(B\\) e \\(C\\), \\(N(B)\\) e \\(N(C)\\) são independentes.\nNote que, para um Processo de Poisson Espaical, dado \\(N(A)=n\\) as \\(n\\) ocorrências estão uniformemente distribuídas dentro da região \\(A\\)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>O modelo Poisson</span>"
    ]
  },
  {
    "objectID": "poisson.html#verossimilhança-e-priori-conjugada",
    "href": "poisson.html#verossimilhança-e-priori-conjugada",
    "title": "7  O modelo Poisson",
    "section": "7.2 Verossimilhança e priori conjugada",
    "text": "7.2 Verossimilhança e priori conjugada\nSeja \\(X_1,\\ldots,X_n\\) uma amostra aleatória do modelo Poisson\\((\\lambda)\\). A verossimilhança deste modelo é dada por\n\\[L(\\theta)=\\frac{e^{-n\\theta}\\theta^{\\sum_{i=1}^{n}x_i}}{\\prod_{i=1}^{n}x_i!}\\propto \\theta^{\\sum_{i=1}^n x_i}e^{-n\\theta}.\\] O modelo Poisson pertence à família exponencial e sua priori conjugada é \\(\\theta\\sim\\hbox{Gama}(r,s)\\) e a posteriori é \\(\\hbox{Gama}(r+\\sum_{i=1}^n x_i, s+n)\\), conforme já discutido na Introdução. Os hiperparâmetros \\(r\\) e \\(s\\) podem ser interpretados como o total da contagem e o tamanho da amostra a priori.\nA média da posteriori é \\[E(\\theta|\\mathbf{x})=\\frac{\\sum_{i=1}^{n}x_i+r}{n+s}=\\frac{n}{n+s}\\bar{x}+\\frac{s}{n+s}E(\\theta),\\] onde fica claro que este estimador é uma média ponderada das informações provenientes das duas fontes de informação (sendo \\(\\bar{x}\\) a estimativa de máxima verossimilhança e \\(E(\\theta)\\) a média a priori).\nSe \\(n\\gg s\\), então a média a posteriori dará maior peso para a informação dos dados.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>O modelo Poisson</span>"
    ]
  },
  {
    "objectID": "poisson.html#preditiva-a-posteriori",
    "href": "poisson.html#preditiva-a-posteriori",
    "title": "7  O modelo Poisson",
    "section": "7.3 Preditiva a posteriori",
    "text": "7.3 Preditiva a posteriori\nA inferência bayesiana é baseada em duas fontes de informação: verossimilhança e priori. Já discutimos que, na maioria dos casos, estamos interessados em deixar a verossimilhança ter mais peso na posteriori. Agora, vamos discutir como verificar se a verossimilhança é adequada ao problema.\nSeja \\(\\boldsymbol{x}=\\{x_1,\\ldots,x_n\\}\\) a amostra observada e \\(f(\\theta|\\boldsymbol{x})\\) a posteriori obtida. Supondo que a informação sobre os parâmetros foi capturada de forma adequada, é de se esperar que uma nova observação \\(x^*\\) se comporte de modo semelhante a amostra observada. Podemos então obter a seguinte distribuição, denominada preditiva a posteriori:\n\\[\\begin{align}f(x^*|\\boldsymbol{x})=\\int f(x^*|\\theta)f(\\theta|\\boldsymbol{x})d\\theta.\\end{align}\\]\nPodemos comparar as características preditiva a posteriori com estatísticas livres de modelos como box-plots, histogramas, etc.\n\nPreditiva a posteriori para o modelo Poisson\nPara o modelo Poisson(\\(\\lambda\\)) e para a posteriori Gama\\((r_1,s_1)\\), onde \\(r_1=r+\\sum_{i=1}^n x_i\\) e \\(s_1=n+s\\), \\[\\begin{align}\nf(x^*|\\boldsymbol{x})&=\\int_0^\\infty f(x^*|\\lambda)f(\\lambda|\\boldsymbol{x})d\\lambda\\\\\n&=\\int_0^\\infty\\frac{e^{-\\lambda}\\lambda^{x^*}}{x^*!}\\frac{s_1^{r_1}}{\\Gamma(r_1)}\\lambda^{r_1-1}e^{-s_1\\lambda}d\\lambda\\\\\n&=\\frac{s_1^{r_1}}{\\Gamma(r_1)x^*!}\\int_0^\\infty \\lambda^{r_1+x^*-1}e^{-\\lambda(s_1+1)}d\\lambda\\\\\n&=\\frac{\\Gamma(r_1+x^*)}{\\Gamma(r_1)x^*!}\\left(\\frac{s_1}{1+s_1}\\right)^{r_1}\\left(1 - \\frac{s_1}{s_1+1}\\right)^{x^*}\n\\end{align}\\] ou seja, a preditiva a posteriori tem distribuição\n\\[\\hbox{Binomial Negativa}\\left(r_1,\\frac{s_1}{1+s_1}\\right).\\]\n\n\nExample 7.1 A Blitz e os Bombardeios de Londres\nDurante a Segunda Guerra Mundial, Londres sofreu intensos bombardeios aéreos pela Alemanha Nazista (conhecido como “Blitz”). Estatísticos analisaram a distribuição das quedas de 537 bombas pela cidade para procurar padrões.\nUma questão chave era se as bombas caíam aleatoriamente ou se havia algum padrão de alvo. Se as quedas de bombas fossem aleatórias, elas deveriam seguir uma distribuição de Poisson. Londres foi dividida em uma grade de com 576 setores de áreas iguais. O número de quedas de bombas em cada setor foi registrado.\n\nQuedas de bombas em Londres durante o Blitz.\n\n\n\n\n\n\nNúmero de bombas\nNúmero de setores com x bombas\n\n\n\n\n0\n229\n\n\n1\n211\n\n\n2\n93\n\n\n3\n35\n\n\n4\n7\n\n\n5 ou mais\n1\n\n\n\nSupondo que os dados seguem uma distribuição Poisson(\\(\\lambda\\)), teremos \\[L(\\lambda)\\propto e^{-576\\lambda}\\lambda^{537}.\\] Considerando a priori \\(\\lambda\\sim\\hbox{Gama}(1,1)\\), teremos a posteriori Gama\\((538,577)\\). A preditiva a posteriori para problema é\n\\[\\hbox{Binomial Negativa}(538,.9982).\\]\nObserve que podemos estimar a frequência relativa dos eventos da tabela. Podemos comparar esses resultados com o que seria esperado da preditiva. O resultado é dado a seguir.\n\nr1 = 538\np = 577/578\n`Número de bombas no setor` &lt;- c(0,1,2,3,4,'&gt;4')\n`Frequência relativa` &lt;- c(229,211,93,35,7,1)/576\n`Preditiva a posteriori` &lt;- c(dnbinom( 0:4, size=r1, prob = p), 1-pnbinom(4,size=r1,prob=p))\n\ndt &lt;- data.frame(`Número de bombas no setor`, `Frequência relativa`,`Preditiva a posteriori`)\n\nprint(dt)\n\n  Número.de.bombas.no.setor Frequência.relativa Preditiva.a.posteriori\n1                         0         0.397569444            0.393922155\n2                         1         0.366319444            0.366661107\n3                         2         0.161458333            0.170960499\n4                         3         0.060763889            0.053240294\n5                         4         0.012152778            0.012458045\n6                        &gt;4         0.001736111            0.002757901\n\n\nA proximidade entre as frequências relativas e os resultados obtidos através da preditiva a posteriori dão evidências de que o modelo Poisson é adequado, ou ainda, que as bombas foram lançadas ao acaso.\n\n\nNúmero de suicídios revisitado\nNa introdução, apresentamos o número de suicídios no Amazonas para os anos 2021, 2022 e 2023. Os dados podem ser vistos abaixo.\n\nno_suicidios &lt;- c(19, 26, 30, 28, 25, 23,23, 21,\n22, 27, 31, 22, 23, 21, 29, 27, 26, 23,\n36, 27, 24, 21, 18, 22, 34, 27, 26, 26, 34,\n22, 27, 25, 32, 36, 28, 22 )\n\nAnalisamos estes dados e obtivemos a posteriori Gama(953.8, 37.1) para a taxa. A distribuição da preditiva a posteriori é Binomial Negativa\\((953.8\\;,\\;0,9737)\\).\nA figura abaixo apresenta a função de distribuição empírica dos dados comparada com a função de distribuição da preditiva a posteriori. A aproximação é razoável o suficiente para aceitarmos o modelo proposto como válido.\n\nplot( ecdf(no_suicidios), main = '', ylab='Função de distribuição', xlab=expression(x))\ncurve(pnbinom(x,sum(no_suicidios)+1,37/38), add=T, lwd = 2, col = 'tomato')\nlegend('bottomright', c('Empírica','Preditia a posteriori'), col=c(1,'tomato'), bty='n')\n\n\n\n\n\n\n\n\n\n7.4 O modelo Poisson para taxas\n\n7.4.1 Modelo de taxa única\nA taxa é o quociente entre o número de casos de um evento em determinado intervalo de tempo e a população em risco, definida em um espaço e no mesmo intervalo de tempo “pessoas-tempo”. Note que, pela definição, a taxa é uma estatística.\nSeja \\(N\\) o tamanho da população no espaço/tempo e seja \\(y\\) o número de casos do evento de interesse. Então,\n\\[\\hbox{taxa} = \\frac{y}{N}\\]\nContudo, como \\(N\\) tende a ser muito maior que \\(y\\), é comum reportar a taxa vezes \\(10^k\\), para algum \\(k&gt;0\\). O mais comum é ter \\(k=5\\) e esta convenção é adotada aqui.\n\nCrime de estupro no país Segundo o Anuário de Segurança Pública 2023, em 2022 houveram 74.930 casos de estupro. Considerando uma população de 208,2 milhões de habitantes, a taxa de estupro para aquele ano foi de \\[\\frac{68.885}{208.200.000}\\times 10^{-5}=35,98\\] casos por pessoa-ano.\nPortanto, temos uma taxa de 35,98 casos para cada 100.000 habitantes.\n\nAgora, considere que \\(\\lambda\\) é o parâmetro taxa. Então,\n\\[\\hat{\\lambda}=\\frac{y}{N}\\] é a estimativa para \\(\\lambda\\). Como \\(y\\) é uma contagem, é razoável supor que \\[\\lambda =\\frac{1}{N}E(Y|\\lambda),\\] e um modelo com essa parametrização seria \\(y|\\lambda\\sim\\hbox{Poisson}(\\lambda N)\\). Observe que, na prática \\(N\\) já está dividido por \\(10^5\\).\n\nCrime de estupro no país (cont.) Seja \\(y\\) o número de crimes de estupro dados no exemplo anterior. Seja \\(n=212.700.000/10^5=2082\\) a população do país dividida por \\(10^5\\). Considerando o modelo \\(y|\\lambda\\hbox{Poisson}(2082\\lambda)\\) temos a seguinte verossimilhança para \\(\\lambda\\):\n\\[L(\\lambda)\\propto \\lambda^{74930}e^{-2082\\lambda  }\\] Utilizando a priori Gama(1,1) (que representa um caso para cada 100.000 habitantes), teremos a posteriori Gama(74931,2083) e a estimativa \\[E(\\lambda|y)=\\frac{74931}{2083}=35,97.\\] ou seja, 35,97 casos a cada 100.000 habitantes.\n\nAgora, considere que a população está particionada em \\(m\\) localidades. Sejam \\(N_i\\) e \\(y_i\\) a população da localidade \\(i\\) e seu respectivo número de casos observados. Suponha ainda que a taxa \\(\\lambda\\) é comum para a população e que \\(y_i\\) e \\(y_j\\) são independentes dado \\(\\lambda\\). Assumindo a distribuição Poisson, teremos\n\\[L(\\lambda)=\\prod_{i=1}^m\\frac{e^{-\\lambda n_i}(\\lambda N_i)^{y_i}}{y_i!}\\varpropto \\lambda^{\\sum_{i=1}^m y_i}e^{-\\lambda \\sum_{i=1}^m N_i}=\\lambda^{\\sum_{i=1}^n y_i}e^{-\\lambda N},\\] onde \\(N=\\sum_{i=1}^m N_i\\) é o tamanho da população. Como a verossimilhança pertence à família exponencial, temos que o modelo Gama\\((r,s)\\) é conjugado gerando a posteriori\n\\[\\lambda|\\mathbf{y}\\sim\\hbox{Gama}\\left(\\sum_{i=1}^{m}y_i+r,N+s\\right)\\equiv \\hbox{Gamma}(r_1,s_1).\\] Observe que essa posteriori é identica a obtida no exemplo anterior, quando consideramos o número de casos na população.\nConsidere agora um novo valor observado da localidade \\(i\\). Sua preditiva a posteriori é dada por\n\\[\\begin{align}\nf(y^*_i|\\boldsymbol{y})&=\\int_0^\\infty f(y^*_i|\\lambda)f(\\lambda|\\boldsymbol{y})d\\lambda\\\\\n&\\int_0^\\infty \\frac{e^{-\\lambda N_i}(\\lambda N_i)^{y_i^*}}{y_i^*!}\\frac{s_1^{r_1}}{\\Gamma(r_1)}\\lambda^{r_1-1}e^{-\\lambda s_1}d\\lambda\\\\\n&=\\frac{\\Gamma(r_1+y_i^*)}{y_i^*!\\Gamma(r_1)}\\left(\\frac{s_i}{N_i+s_i}\\right)^{r_1}\\left(1-\\frac{s_i}{N_i+s_i}\\right)^{y_i^*},\n\\end{align}\\] ou seja, \\[y_i^*|\\boldsymbol{y}\\sim\\text{Binomial Negativa}\\left(r_1,\\frac{s_1}{N_i+s_1}\\right),\\] cujo valor esperado é \\[E(y_i^*|\\boldsymbol{y})=\\frac{r_1}{s_1}N_i.\\]\nDeste modo, a taxa da preditiva a posteriori é dada por \\[E(\\frac{y_i^*}{N_i}|\\boldsymbol{y})=\\frac{r_1}{s_1}\\] e podemos comparar o ajuste considerando a distribuição de \\(y^*_i/N_i\\) com \\(y_i/N_i\\).\n\nCrime de estupro no país (cont.) Os dados deste exemplo estão no banco abaixo.\n\nrequire(gsheet)\n\nCarregando pacotes exigidos: gsheet\n\nurl &lt;- 'https://docs.google.com/spreadsheets/d/11Sr8mqilWCe6Dj8TO6PgTYpJT292vbon1XnB0Co1Trc/edit?usp=sharing'\n\ndados &lt;- data.frame(gsheet2tbl(url))\nprint(dados)\n\n   Unidade.Federativa..UF. População.Estimada..2023. Crimes.de.estupro\n1                     Acre                    830018               745\n2                  Alagoas                   3127511              1040\n3                    Amapá                    733759               628\n4                 Amazonas                   4145525               836\n5                    Bahia                  14659023              4558\n6                    Ceará                   9187078              1897\n7         Distrito Federal                   2817068               754\n8           Espírito Santo                   4018650              1736\n9                    Goiás                   7206589              3667\n10                Maranhão                   6775152              2273\n11             Mato Grosso                   3784239              1889\n12      Mato Grosso do Sul                   2756700              2191\n13            Minas Gerais                  20812060              4491\n14                    Pará                   8442765              4557\n15                 Paraíba                   4039277               546\n16                  Paraná                  11835799              6648\n17              Pernambuco                   9496294              2705\n18                   Piauí                   3280062              1241\n19          Rio de Janeiro                  16615526              5627\n20     Rio Grande do Norte                   3302970               881\n21       Rio Grande do Sul                  11088065              5193\n22                Rondônia                   1616379              1027\n23                 Roraima                    636303               726\n24          Santa Catarina                   7762154              4541\n25               São Paulo                  45533984             12615\n26                 Sergipe                   2240560               885\n27               Tocantins                   1496880              1033\n\n\nUtilizando a posteriori Gama(74931,2083), teremos que \\[y_i^*|\\hbox{dados}\\sim\\hbox{Binomial Negativa}\\left(74931,\\frac{2083}{N_i+2083}\\right).\\]\nPodemos construir intervalos de 95% (de predição) para \\(y^*_i\\) utilizando os quantis da preditiva a posteriori, ou seja, encontrando \\(q_1\\) e \\(q_2\\) tais que \\[\\begin{align}\nP(Y_i^*\\leq q_1|\\boldsymbol{y})&=0,025\\\\\nP(Y_i^*\\leq q_2|\\boldsymbol{y})&=0,975.\n\\end{align}\n\\]\nObserve ainda que \\[0,95\\approx P(q_1\\leq Y_i^*\\leq q_2|\\boldsymbol{y})=P\\left(\\frac{q_1}{N_i}\\leq \\frac{Y_i^*}{N_i}\\leq \\frac{q_2}{N_i}|\\boldsymbol{y}\\right),\\] o que implica que \\((q_1,q_2)/N_i\\) é um intervalo de predição de 95% para taxa esperada. Abaixo construímos estes intervalos e contrastamos com a taxa observada.\n\n# taxas observadas\nN &lt;- unlist(dados[,2]/100000)\ntaxas &lt;- unlist(dados[,3]/N)\n\n# posteriori\nr1 = 74931\ns1 = 2083\n\n# limites do intervalo da preditiva a posteriori\nlim_inf &lt;- qnbinom(.025, size = r1, prob = s1/(N+s1))\nlim_sup &lt;- qnbinom(.975, size = r1, prob = s1/(N+s1))\n\n# gráfico\ncores = c('red','green4','red',rep('orange',4),'red','red','green4',\n          'red','red',rep(c('orange','red'),2), 'orange','green4','green4','orange',rep('red',4),'orange','green4','red')\nplot.new()\nplot.window( xlim = c(-70,120), ylim=c(0,27))\nsegments(lim_inf/N,1:27,lim_sup/N,1:27, lwd = 2)\ntext(-70,1:27, unlist(dados[,1]), adj =0 ,col=cores)\npoints(taxas, 1:27, pch = 22, cex =.9, bg = cores)\naxis(1,at = seq(0,120,20))\n\n\n\n\n\n\n\n\nObserve que o modelo de considera uma taxa única para o país se ajusta bem para os estados Alagoas, Maranhão, Piauí, Rio de Janeiro e Sergipe. Unidades da Federação como Amazonas, Bahia, Ceará, Distrito Federal, Minas Gerais, Pernambuco, Rio Grande do Norte e São Paulo, possuem taxas menores do que as preditas. Os demais estados possuem taxas maiores do que as preditas.\n\n\n\n7.4.2 Modelo com uma taxas por localidade\nO último exemplo da seção anterior mostra que o modelo com taxa única pode ser falho. Existem algumas explicações para este fenômeno, como:\n\nO evento observado não depende apenas do tamanho da população. O crime de estupro, por exemplo, depende de variáveis como vunerabilidade social e aparelhamento do estado para o acolhimento das vítimas.\nO evento observado pode ser raro. Eventos raros são mais difíceis de serem observados em populações menores, o que causa distorções.\n\nPodemos tentar mitigar os efeitos acima considerando um modelo no qual cada região possui sua própria taxa, i.e.\n\\[y_i|\\lambda_i\\sim\\hbox{Poisson}(\\lambda_i N_i).\\] Considerando a priori \\(\\lambda_i\\sim\\hbox{Gama}(r,s)\\), teremos\n\\[\\begin{align}\n\\lambda_i| \\hbox{dados} & \\sim \\hbox{Gama}(r+y_i,s+N_i)\\\\\ny^*_i|\\hbox{Dados}&\\sim\\hbox{Binomial Negativa}\\left(r+y_i,\\frac{s}{s+N_i}\\right)\n\\end{align}\\]\nObserve que mesmo que cada região tenha a sua própria taxa, a informação a priori é a mesma para todas elas. Deste modo, é importante que a priori reflita as várias possibilidades de taxas.\n\nCrime de estupro no país (cont.) Considere que as taxas para cada unidade da federação são independentes e identicamente distribuídas. Abaixo apresentamos a densidade estimada via método do núcleo para as taxas.\n\nplot(density(taxas))\ncurve(dgamma(x,100,.5),add = T)\n\n\n\n\n\n\n\n\nVimos na Introdução que uma priori Gama\\((r,s)\\) pode ser elicitada utilizando as seguintes fórmulas:\n\\[\\begin{align}a&=\\left(\\frac{\\hbox{média}}{desvio}\\right)^2\\\\\nb=\\frac{a}{\\hbox{média}}\\end{align}\\]\nFazendo os cálculos abaixo\n\nmedia = mean(taxas)\ndesvio = sd(taxas)\nr = (media/desvio)^2\ns = r/media\nr;s\n\n[1] 3.608031\n\n\n[1] 0.07758706\n\n\nA próxima figura reapresenta a densidade estimada em conjunto com a densidade Gama(3,6;,;0,07)\n\nplot(density(taxas))\ncurve(dgamma(x,3.6,.07),add = T, lwd = 2, col ='tomato')\n\n\n\n\n\n\n\n\nVamos utilizar a priori \\(\\lambda_i\\sim\\hbox{Gama}(3,6\\;,\\;0,07)\\) para analizar este banco de dados, agora com múltiplas taxas.\n\n# hiperparametros\nr = 3.6\ns = .07\n\n# posterioris\nr1 = unlist(dados[,3])+r\ns1 = N + s\n\n# limites do intervalo da preditiva a posteriori\nlim_inf &lt;- qnbinom(.025, size = r1, prob = s1/(N+s1))\nlim_sup &lt;- qnbinom(.975, size = r1, prob = s1/(N+s1))\n\n# gráfico\ncores = c('red','green4','red',rep('orange',4),'red','red','green4',\n          'red','red',rep(c('orange','red'),2), 'orange','green4','green4','orange',rep('red',4),'orange','green4','red')\nplot.new()\nplot.window( xlim = c(-70,120), ylim=c(0,27))\nsegments(lim_inf/N,1:27,lim_sup/N,1:27, lwd = 2)\ntext(-70,1:27, unlist(dados[,1]), adj =0 ,col=cores)\npoints(taxas, 1:27, pch = 22, cex =.9, bg = cores)\naxis(1, at=seq(0,120,20))\n\n\n\n\n\n\n\n\nAs múltiplas taxas apresentam um cenário mais honesto, acomodando cada estado a sua própria realidade. Abaixo, apresentamos um mapa com a taxa estimada.\n\n# Carregar as bibliotecas necessárias\nlibrary(leaflet)\nlibrary(geobr)\n\nCarregando namespace exigido: sf\n\n# Obter os dados geográficos das Unidades da Federação do Brasil usando geobr\nbrasil_uf &lt;- read_state() # Ou o ano mais recente disponível\n\nUsing year/date 2010\n\n# colocar os estados em ordem alfabética\nbrasil_uf &lt;- brasil_uf[order(brasil_uf$name_state), ]\n\n# adicionar as taxas\nbrasil_uf$taxa &lt;- r1/s1\n\n# Definir uma paleta de cores com base nos valores das taxas\npal &lt;- colorNumeric(palette = \"viridis\", domain = brasil_uf$taxa)\n\n# Criar o mapa leaflet\nmapa_leaflet &lt;- leaflet(brasil_uf) %&gt;%\n  setView(lng = -55, lat = -15, zoom = 3) %&gt;% # Centralizar o mapa no Brasil\n  addTiles() %&gt;% # Adicionar camadas de mapa base (OpenStreetMap por padrão)\n  addPolygons(\n    fillColor = ~pal(taxa),\n    weight = 1,\n    color = \"#000000\",\n    fillOpacity = 0.7,\n    label = ~paste0(name_state, \": \", round(taxa, 2)), # Adicionar rótulos ao passar o mouse\n    highlightOptions = highlightOptions(color = \"white\", weight = 2, bringToFront = TRUE)\n  ) %&gt;%\n  addLegend(pal = pal, values = ~taxa, title = \"Taxa\", opacity = 1)\n\nWarning: sf layer has inconsistent datum (+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs).\nNeed '+proj=longlat +datum=WGS84'\n\n# Exibir o mapa (opcional, se você estiver em um ambiente interativo)\nmapa_leaflet\n\n\n\n\n\n\n\n\n7.4.3 Análise de agrupamentos para taxas - modelagem 1\nAté o momento estudamos dois exemplos extremos:\n\nUm modelo com uma única taxa por localidade\nUm modelo com uma taxa por localidade\n\nUm modo útil para decidir qual abordagem é a mais interessante é o uso de um critério de informação. Recordemos que tais critério são escritos como\n\\[-2\\log L(\\hat{\\theta})+2k,\\] onde \\(L(\\theta)\\) é a função de verossimilhança, \\(\\hat{\\theta}\\) é uma estimativa para \\(\\theta\\) e \\(k\\) é uma penalidade relacionada ao número de parâmetros do modelo. Por causa do sinal negativo em \\(L(.)\\), temos que o modelo preferível é aquele com menor valor do critério.\nEm inferência bayesiana é comum o uso do Critério de Informação de Desvio (DIC), onde \\(\\hat{\\theta}=E(\\theta|\\boldsymbol{x})\\) e \\[k=\\frac{1}{2}Var_{\\theta|\\boldsymbol{x}}(\\log L(\\theta)).\\]\nObserve que o cálculo direto de \\(k\\) não é trivial. Entretanto, o DIC pode ser facilmente obtido via o Método de Monte Carlo.\n\nAlgoritmo: Calculando o DIC via Monte Carlo\n\nSimule \\(\\theta_1,\\ldots,\\theta_B\\) da distribuição a posteriori de \\(\\theta\\).\nEstime \\(E(\\theta|\\boldsymbol{x})\\) por \\[\\hat{\\theta}=\\frac{1}{B}\\sum_{j=1}^B \\theta_j\\]\nFaça \\(v_j=-2\\log L(\\theta_j)\\). Estime \\(k\\) por \\[k=\\frac{1}{2B}\\sum_{j=1}^B(v_j-\\bar{v})^2\\]\nCalcule o DIC:\n\n\\[DIC=-2\\log L(\\hat{\\theta})+2k.\\]\n\n\nComparando os dois modelos para as taxas\nNo começo desta seção, estudamo a taxa de crimes de estupro no Brasil, considerando uma única taxa \\(\\lambda\\) comum a todas as unidades da federação. Encontramos a posteriori \\(\\lambda\\sim\\hbox{Gama}(74931,2083)\\). O DIC para este modelo é\n\nB = 10000 # número de simulações\nlambda &lt;- rgamma( B, 74931, 2083) # simulações da posteriori\n\n# média a posteriori\nlambda_chapeu &lt;- mean(lambda)\n\n# calculo de k\nvj &lt;- sapply( lambda, function(l) -2*sum(dpois( dados[,3], l*N, log = T)))\nk &lt;- .5*var(vj)\n\nDIC0 &lt;- -2*sum( dpois(dados[,3], lambda_chapeu*N, log = T) ) +2*k\nDIC0\n\n[1] 11771.31\n\n\nPosteriormente, criamos um modelo com uma taxa por unidade da federação. Para a \\(i\\)ésima unidade, a posteriori da taxa foi dada ´por \\(\\lambda_i\\sim\\hbox{Gama}(y_i+3,6\\;\\;,\\;\\;N_i+0,07)\\). O DIC para este modelo é\n\nB = 10000 # número de simulações\n# hiperparâmetros comuns\nr = 3.6\ns = .07\n\n# simulações da posteriori\nlambda &lt;- sapply(1:B, function(x) rgamma(27, dados[,3]+3.6, N+.07) )\n\n# média a posteriori para cada taxa\nlambda_chapeu &lt;- rowMeans(lambda)\n\n# calculo de k\nvj &lt;- apply( lambda, 2, function(l) -2*sum(dpois( dados[,3], l*N, log = T)))\nk &lt;- .5*var(vj)\n\nDICtodos &lt;- -2*sum( dpois(dados[,3], lambda_chapeu*N, log = T) ) +2*k\nDICtodos\n\n[1] 308.5074\n\n\nObserve que o modelo com uma taxa por unidade da federação possui o menor valor do DIC, sendo assim o mais parcimonioso entre os dois.\n\nSeja \\(S=\\{1,\\ldots,m\\}\\) o conjunto das \\(m\\) localidades. Suponha que é razoável particionar \\(S\\) em \\(k\\) grupos. Por último, considere que todas as localidades dentro de uma partição compartilham a mesma taxa, ou seja, para \\(j\\) dentro da partição \\(S_t\\), tem-se que \\(y_i|\\lambda_t\\sim\\hbox{Poisson}(\\lambda_tN_i)\\), onde \\(\\lambda_t\\sim\\hbox{Gama}(r_t,s_t)\\). O desafio aqui é determinar se a localidade pertence à partição \\(S_t\\).\nPodemos utilizar alguma técnica não paramétrica de agrupamento e então consideramos essa classificação para fins da modelagem.\n\nAnálise de agrupamento para as taxas de crimes de estupro\nConsiderando o mapa dado no exemplo anterior, podemos conjecturar que existem em torno de 3 a 5 agrupamentos das taxas.\nComeçando nossa análise com três grupos, podemos fazer uma classificação inicial das taxas utilizando o método das \\(k\\)-médias para obter uma classificação inicial\n\ngrupos = 3\nkm = kmeans(taxas,grupos)\n\nApresentamos a seguir os agrupamentos encontrados:\n\n# Grupo 1\ndados[,1][km$cluster == 1]\n\n [1] \"Alagoas\"             \"Amazonas\"            \"Bahia\"              \n [4] \"Ceará\"               \"Distrito Federal\"    \"Maranhão\"           \n [7] \"Minas Gerais\"        \"Paraíba\"             \"Pernambuco\"         \n[10] \"Piauí\"               \"Rio de Janeiro\"      \"Rio Grande do Norte\"\n[13] \"São Paulo\"           \"Sergipe\"            \n\n# Grupo 2\ndados[,1][km$cluster == 2]\n\n[1] \"Acre\"               \"Amapá\"              \"Mato Grosso do Sul\"\n[4] \"Roraima\"           \n\n# Grupo 3\ndados[,1][km$cluster == 3]\n\n[1] \"Espírito Santo\"    \"Goiás\"             \"Mato Grosso\"      \n[4] \"Pará\"              \"Paraná\"            \"Rio Grande do Sul\"\n[7] \"Rondônia\"          \"Santa Catarina\"    \"Tocantins\"        \n\n\nEm seguinda, podemos utilizar essa classificação para construir as três prioris para as taxas. Lembremos que \\[E(\\lambda)=\\frac{r}{s}\\] e que \\[Var(\\lambda)=\\frac{E(\\lambda)}{s}\\]\nVamos escolher para os parâmetros da priori \\(r\\approx \\tau\\text{taxa}\\) e \\(s=\\tau\\). Deste modo, a média da priori estará próxima da taxa e a variância vai ser controlada por \\(\\tau.\\). Vamos escolhe \\(\\tau=0,1\\)\n\nr = s = NULL\ntau = .1\nfor(i in 1:grupos){\n  media = mean(taxas[km$cluster == i])\n  r[i] &lt;- media*tau\n  s[i] &lt;- tau\n}\n\nAs posterioris estão podem ser calculadas para cada um dos três agrupamentos.\n\nr1 = s1 = NULL\nfor(i in 1:grupos){\n  r1[i] &lt;- r[i] + sum( dados[,3][km$cluster == i])\n  s1[i] &lt;- s[i] + sum( N[km$cluster == i])\n}\n\nAbaixo apresentamos as 3 posterioris.\n\ncurve(dgamma(x,r1[1],s1[1]),10,120, ylab = 'Posteriori',xlab='Taxa')\ncurve(dgamma(x,r1[2],s1[2]),add=TRUE, col = 2)\ncurve(dgamma(x,r1[3],s1[3]),add=TRUE, col = 3)\nlegend('topright',c('Grupo 1','Grupo 2', 'Grupo 3'), col=1:3, lty=1, bty='n')\n\n\n\n\n\n\n\n\nPodemos então calcular o DIC para esse novo modelo.\n\nB = 1000 # número de simulações\n\n# simulações da posteriori\nlambda1 &lt;- rgamma(B, r1[1], s1[1]) \nlambda2 &lt;- rgamma(B, r1[2], s1[2]) \nlambda3 &lt;- rgamma(B, r1[3], s1[3]) \n\n# média a posteriori para cada taxa\nlambda_chapeu &lt;- c(mean(lambda1),mean(lambda2),mean(lambda3)) \n# calculo de k\nvj &lt;- apply( cbind(lambda1,lambda2,lambda3), 1, function(l){ \n  t1 = -2*sum(dpois( dados[,3][km$cluster==1], l[1]*N[km$cluster==1], log = T))\n  t2 = -2*sum(dpois( dados[,3][km$cluster==2], l[2]*N[km$cluster==2], log = T))\n  t3 = -2*sum(dpois( dados[,3][km$cluster==3], l[3]*N[km$cluster==3], log = T))\n  t1+t2+t3\n})\nk &lt;- .5*var(vj)\n\n\n  t1 = -2*sum(dpois( dados[,3][km$cluster==1], lambda_chapeu[1]*N[km$cluster==1], log = T))\n  t2 = -2*sum(dpois( dados[,3][km$cluster==2], lambda_chapeu[2]*N[km$cluster==2], log = T))\n  t3 = -2*sum(dpois( dados[,3][km$cluster==3], lambda_chapeu[3]*N[km$cluster==3], log = T))\n\nDIC3 &lt;- (t1+t2+t3) +2*k\nDIC3\n\n[1] 2202.747\n\n\nObserve que este modelo é mais interessante que o modelo com uma única taxa (DIC 11.771) mas menos interessante que o modelo com uma taxa por UF (DIC 307).\n\n\n\n7.4.4 Análise de agrupamento - modelagem 2\nAnteriormente, utilizamos os dados para construir a priori. Nesta seção, vamos tratar o problema sob o ponto de vista puramente bayesiano.\nSeja \\(z_{j}=(z_{j,1},\\ldots,z_{j,k})\\sim\\hbox{Bernoulli Multivariada}(p_1,\\ldots,p_k)\\). Aqui, a coordenada onde \\(z_j\\) é igual a um representa o conjunto da partição a qual a localidade \\(j\\) pertence. Sem perda de generalidade, podemos escrever\n\\[f(y_j|z_j,\\lambda_1,\\ldots,\\lambda_k)=\\prod_{t=1}^k\\left[\\frac{e^{-\\lambda_t N_t}(\\lambda_tN_t)^{y_j}}{y_j!}\\right]^{z_{j,t}},\\]\nObserve que a verossimilhança original não é mais Poisson, uma vez que \\[f(y_j|\\lambda)=\\sum_{z_{j}}\\prod_{t=1}^k\\left[\\frac{e^{-\\lambda_t N_t}(\\lambda_tN_t)^{y_j}}{y_j!}\\right]^{z_{j,t}} f(z_{j})\\] Observe que é natural assumir que \\(z_j\\sim\\hbox{Bernoulli M}(p_1,\\ldots,p_k)\\). Considerando as prioris \\(lambda_t\\sim\\hbox{Gama}(r_t,s_t)\\), e \\(p\\hbox{Dirichlet}(a_1,\\ldots,a_k)\\) teremos a posteriori\n\\[\\begin{align} f(\\lambda_1,\\ldots,\\lambda_k,z_1,\\ldots,z_m|\\hbox{dados})&\\propto \\prod_{j=1}^m\\prod_{t=1}^k\\left[\\frac{e^{-\\lambda_t N_j}(\\lambda_tN_j)^{y_j}}{y_j!}\\right]^{z_{j,t}}\\\\&\\times \\prod_{t=1}^k \\frac{s_t^{r_t}}{\\Gamma(r_t)}\\lambda_t^{r_t-1}e^{-s_t\\lambda_t}\\\\&\\times \\prod_{j=1}^m \\prod_{t=1}^k p_t^{z_{j,t}}\\times \\prod_{t=1}^k p_t^{a_t-1} \\end{align}\\]\n\n**Amostrador de Gibbs** Considere que desejamos simular amostras da distribuição conjunta de $X,Y,Z$.\n\nComece com um valor arbitrário $(x_0,y_0,z_0)$. Para $i$ variando de 1 até $B$:\n\n1. Simule $x_i\\sim f(x|y_{i-1},z_{i-1})$\n\n2. Simule $y_i\\sim f(y|x_{i},z_{i-1})$\n\n3. Simule $z_i\\sim f(z|x_{i},y_{i})$\n\n\nAnálise de agrupamento para as taxas de crimes de estupro\nConsiderando o mapa dado no exemplo anterior, podemos conjecturar que existem em torno de 3 a 5 agrupamentos das taxas.\nComençando nossa análise com três grupos, podemos fazer uma classificação inicial das taxas utilizando o método das \\(k\\)-médias para obter uma classificação inicial\n\ngrupos = 3\nkm = kmeans(taxas,grupos)\n\nEm seguinda, podemos utilizar essa classificação para construir as três prioris para as taxas.\n\nr = s = NULL\ntau = .1\nfor(i in 1:grupos){\n  media = mean(taxas[km$cluster == i])\n  r[i] &lt;- tau*media\n  s[i] &lt;- tau\n}\n\nConsiderando a priori \\(p\\sim\\hbox{Dirichlet}(1,1,1)\\), temos os seguinte amostrador de Gibbs:\n\nrequire(extraDistr)\n\nCarregando pacotes exigidos: extraDistr\n\nB &lt;- 50000\ny = dados[,3]\nN &lt;- unlist(dados[,2]/100000)\n\nlambda &lt;- array( NA_real_, c(B+1,grupos) )\np      &lt;- array( NA_real_, c(B+1,grupos) )\nz      &lt;- array( NA_real_, c(B+1,27))\nlambda[1,] &lt;- r/s\nz[1,] &lt;- km$cluster\np[1,] &lt;- as.vector(table(z)/27)\n\n# condicional completa de lambda\nfor(i in 1:B){\n  for(t in 1:grupos){\n    lambda[i+1,t] &lt;- rgamma(1, r[t]+sum(y[z[i,]==t]), s[t]+sum(N[z[i,]==t]))\n  }\n  \n# condicional completa de p  \n  a = NULL\n  for(t in 1:grupos){\n    a = c(a, sum(z[i,]==t))\n  }\n  p[i+1,] &lt;- rdirichlet(1, 1+a)\n  \n# condicional completa de z\n  for(j in 1:27){\n    z[i+1,j] &lt;- sample(1:grupos,1,T, p[i+1,]*dpois(y[j],lambda[i+1,]*N[j]))  \n  }\n  \n}\n\nVamos eliminar metade das simulações (burn-in) e manter as amostras de 15 em 15. Abaixo apresentamos o traceplot das simulação e um dos correlogramas.\n\nlambda_post &lt;- lambda[seq(B/2,B,15),]\nz_post &lt;-      z[seq(B/2,B,15),]\np_post &lt;-      p[seq(B/2,B,15),]\nts.plot(lambda_post)\n\n\n\n\n\n\n\nacf(lambda_post[,1])\n\n\n\n\n\n\n\n\nVamos calcular o DIC para o modelo encontrado.\n\n# média a posteriori para os parâmetros\nlambda_chapeu &lt;- colMeans(lambda_post)\np_chapeu &lt;- colMeans(p_post)\n\n# calculo de k\nvj &lt;- apply( cbind(lambda_post,p_post), 1, function(w){\n   veross = NULL\n   u = ncol(lambda)\n   for(i in 1:u){\n     veross = cbind(veross , w[i+u]*dpois(dados[,3],w[i]*N))\n   }\n   -2*sum( log(rowSums(veross)))\n}) \n  \nk &lt;- .5*var(vj)\n\nveross = NULL\n   for(i in 1:ncol(lambda_post)){\n      veross = cbind(veross , p_chapeu[i]*dpois(dados[,3],lambda_chapeu[i]*N))\n   }\nDIC3 &lt;- -2*sum( log(rowSums(veross) )) +2*k\nDIC3\n\n[1] 2210.651\n\n\nObserve que este valor semelhante ao encontrado na análise anterior. Para determinar os agrupamentos, podemos verificar a distribuição a posteriori de \\(z_j\\). Por exemplo, a posteriori de \\(z_j\\) para o Acre é dada abaixo\n\ntb &lt;- table(z_post[,1])\nplot(prop.table(tb), ylab='f(z|dados)',xlab='Grupo')\n\n\n\n\n\n\n\n\nVariando o número de grupos, obtivemos os seguintes valores para o DIC\n\n\n   Número.de.grupos  DIC\n1                 2 3043\n2                 3 2200\n3                 4 1442\n4                 5 1247\n5                 6  732\n6                 7  672\n7                 8  630\n8                 9  535\n9                10  489\n10               11  502\n11               12 1015\n\n\nA tabela acima mostra que parece ser razoável dividir estes dados em 10 grupos. Após refazer a análise com 10 grupos, identificamos os seguintes agrupamentos através da moda da posteriori de \\(z_j\\)\n\ngrupo_posteriori &lt;- c(8,1,2,6,1,6,7,5,3,1,5,10,6,3,9,3,7,1,1,7,5,3,8,10,7,4,10)\n\nmedia_post = c(32.78140,  82.46029,  56.16715,  40.46941,  48.68677,  21.15481,  27.73506, 114.13073,  13.53351,  66.20056)\nEstados = `Taxa média a posteriori` = NULL\nfor(i in 1:10){\n  Estados[i] &lt;- paste(dados[,1][grupo_posteriori==i], collapse = ', ')\n  `Taxa média a posteriori`[i] = media_post[i] \n}\nprint(data.frame(Estados,`Taxa média a posteriori`),width = 30)\n\n                                                        Estados\n1               Alagoas, Bahia, Maranhão, Piauí, Rio de Janeiro\n2                                                         Amapá\n3                                 Goiás, Pará, Paraná, Rondônia\n4                                                       Sergipe\n5                Espírito Santo, Mato Grosso, Rio Grande do Sul\n6                                 Amazonas, Ceará, Minas Gerais\n7  Distrito Federal, Pernambuco, Rio Grande do Norte, São Paulo\n8                                                 Acre, Roraima\n9                                                       Paraíba\n10                Mato Grosso do Sul, Santa Catarina, Tocantins\n   Taxa.média.a.posteriori\n1                 32.78140\n2                 82.46029\n3                 56.16715\n4                 40.46941\n5                 48.68677\n6                 21.15481\n7                 27.73506\n8                114.13073\n9                 13.53351\n10                66.20056\n\n\n\n\n\n\n7.5 Exercícios\n\n7.5.1 Mortes por coice de cavalo\nLadislaus Bortkiewicz é o responsável pela popularização da distribuição Poisson. Em seu livro intitulado A Lei dos Pequenos Números, é apresentado um conjunto de dados no qual foi rastreado o número de mortes por coice de cavalo em 14 corpos do exército prussiano ao longo de 20 anos (de 1875 a 1894).\n\n\n\nMortes por corpo \\(\\times\\) ano\n0\n1\n2\n3\n\n\n\n\n\n109\n65\n22\n3\n\n\n\nDetermine se a distribuição Poisson é adequada para este conjunto de dados. Em caso afirmativo, estime a taxa e dê um intervalo de credibilidade de 95%.\n\n\n7.5.2 Suicídios no Amazonas considerando capital e interior\nO Amazonas possui uma característica peculiar: aproximadamente 50% da população vive na capital. Vimos anteriormente que o número de suicídios, considerando os anos entre 2021 e 2023, podem ser modelados por uma Poisson. A tabela abaixo divide esses dados entre capital e interior.\n\nNúmero de suicídios divididos entre capital e interior\n\n\nAno\n2021\n2022\n2023\nTotal\n\n\n\n\nCapital\n133\n124\n138\n395\n\n\nInterior\n164\n173\n201\n538\n\n\n\nDetermine se há evidências de que essas taxas são diferentes.\n\n\n7.5.3 Crime de estupro de vulnerável no interior do Amazonas**\nOs dados a seguir foram cedidos pelo Observatório de Violência de Gênero no Amazonas e compreendem os anos entre 2010 e 2012. A população em risco é o número de mulheres com menos de 14 anos.\n\n\n\nCidade\nVítimas\nPopulacao feminina\n\n\n\n\nAmatura\n3\n639\n\n\nAtalaia do Norte\n6\n905\n\n\nBarreirinha\n12\n1899\n\n\nBenjamin Constant\n2\n2036\n\n\nBoa Vista do Ramos\n6\n1060\n\n\nFonte Boa\n0\n1438\n\n\nJutai\n1\n1143\n\n\nMaues\n13\n3421\n\n\nNhamunda\n9\n1168\n\n\nParintins\n20\n6700\n\n\nSanto Antonio do Ica\n7\n1608\n\n\nSao Paulo de Olivenca\n5\n2033\n\n\nTabatinga\n8\n3095\n\n\nTonantins\n1\n1186\n\n\n\nAjuste o modelo de taxa única e o modelo de uma taxa para cada município, calcule o DIC de cada e verifique qual é o modelo mais adequado. Em seguida, tente melhorar o ajuste procurando um agrupamento.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>O modelo Poisson</span>"
    ]
  },
  {
    "objectID": "poisson.html#o-modelo-poisson-para-taxas",
    "href": "poisson.html#o-modelo-poisson-para-taxas",
    "title": "7  O modelo Poisson",
    "section": "7.4 O modelo Poisson para taxas",
    "text": "7.4 O modelo Poisson para taxas\n\n7.4.1 Modelo de taxa única\nA taxa é o quociente entre o número de casos de um evento em determinado intervalo de tempo e a população em risco, definida em um espaço e no mesmo intervalo de tempo “pessoas-tempo”. Note que, pela definição, a taxa é uma estatística.\nSeja \\(N\\) o tamanho da população no espaço/tempo e seja \\(y\\) o número de casos do evento de interesse. Então,\n\\[\\hbox{taxa} = \\frac{y}{N}\\]\nContudo, como \\(N\\) tende a ser muito maior que \\(y\\), é comum reportar a taxa vezes \\(10^k\\), para algum \\(k&gt;0\\). O mais comum é ter \\(k=5\\) e esta convenção é adotada aqui.\n\nCrime de estupro no país Segundo o Anuário de Segurança Pública 2023, em 2022 houveram 74.930 casos de estupro. Considerando uma população de 208,2 milhões de habitantes, a taxa de estupro para aquele ano foi de \\[\\frac{68.885}{208.200.000}\\times 10^{-5}=35,98\\] casos por pessoa-ano.\nPortanto, temos uma taxa de 35,98 casos para cada 100.000 habitantes.\n\nAgora, considere que \\(\\lambda\\) é o parâmetro taxa. Então,\n\\[\\hat{\\lambda}=\\frac{y}{N}\\] é a estimativa para \\(\\lambda\\). Como \\(y\\) é uma contagem, é razoável supor que \\[\\lambda =\\frac{1}{N}E(Y|\\lambda),\\] e um modelo com essa parametrização seria \\(y|\\lambda\\sim\\hbox{Poisson}(\\lambda N)\\). Observe que, na prática \\(N\\) já está dividido por \\(10^5\\).\n\nCrime de estupro no país (cont.) Seja \\(y\\) o número de crimes de estupro dados no exemplo anterior. Seja \\(n=212.700.000/10^5=2082\\) a população do país dividida por \\(10^5\\). Considerando o modelo \\(y|\\lambda\\hbox{Poisson}(2082\\lambda)\\) temos a seguinte verossimilhança para \\(\\lambda\\):\n\\[L(\\lambda)\\propto \\lambda^{74930}e^{-2082\\lambda  }\\] Utilizando a priori Gama(1,1) (que representa um caso para cada 100.000 habitantes), teremos a posteriori Gama(74931,2083) e a estimativa \\[E(\\lambda|y)=\\frac{74931}{2083}=35,97.\\] ou seja, 35,97 casos a cada 100.000 habitantes.\n\nAgora, considere que a população está particionada em \\(m\\) localidades. Sejam \\(N_i\\) e \\(y_i\\) a população da localidade \\(i\\) e seu respectivo número de casos observados. Suponha ainda que a taxa \\(\\lambda\\) é comum para a população e que \\(y_i\\) e \\(y_j\\) são independentes dado \\(\\lambda\\). Assumindo a distribuição Poisson, teremos\n\\[L(\\lambda)=\\prod_{i=1}^m\\frac{e^{-\\lambda n_i}(\\lambda N_i)^{y_i}}{y_i!}\\varpropto \\lambda^{\\sum_{i=1}^m y_i}e^{-\\lambda \\sum_{i=1}^m N_i}=\\lambda^{\\sum_{i=1}^n y_i}e^{-\\lambda N},\\] onde \\(N=\\sum_{i=1}^m N_i\\) é o tamanho da população. Como a verossimilhança pertence à família exponencial, temos que o modelo Gama\\((r,s)\\) é conjugado gerando a posteriori\n\\[\\lambda|\\mathbf{y}\\sim\\hbox{Gama}\\left(\\sum_{i=1}^{m}y_i+r,N+s\\right)\\equiv \\hbox{Gamma}(r_1,s_1).\\] Observe que essa posteriori é identica a obtida no exemplo anterior, quando consideramos o número de casos na população.\nConsidere agora um novo valor observado da localidade \\(i\\). Sua preditiva a posteriori é dada por\n\\[\\begin{align}\nf(y^*_i|\\boldsymbol{y})&=\\int_0^\\infty f(y^*_i|\\lambda)f(\\lambda|\\boldsymbol{y})d\\lambda\\\\\n&\\int_0^\\infty \\frac{e^{-\\lambda N_i}(\\lambda N_i)^{y_i^*}}{y_i^*!}\\frac{s_1^{r_1}}{\\Gamma(r_1)}\\lambda^{r_1-1}e^{-\\lambda s_1}d\\lambda\\\\\n&=\\frac{\\Gamma(r_1+y_i^*)}{y_i^*!\\Gamma(r_1)}\\left(\\frac{s_i}{N_i+s_i}\\right)^{r_1}\\left(1-\\frac{s_i}{N_i+s_i}\\right)^{y_i^*},\n\\end{align}\\] ou seja, \\[y_i^*|\\boldsymbol{y}\\sim\\text{Binomial Negativa}\\left(r_1,\\frac{s_1}{N_i+s_1}\\right),\\] cujo valor esperado é \\[E(y_i^*|\\boldsymbol{y})=\\frac{r_1}{s_1}N_i.\\]\nDeste modo, a taxa da preditiva a posteriori é dada por \\[E(\\frac{y_i^*}{N_i}|\\boldsymbol{y})=\\frac{r_1}{s_1}\\] e podemos comparar o ajuste considerando a distribuição de \\(y^*_i/N_i\\) com \\(y_i/N_i\\).\n\nCrime de estupro no país (cont.) Os dados deste exemplo estão no banco abaixo.\n\nrequire(gsheet)\n\nCarregando pacotes exigidos: gsheet\n\nurl &lt;- 'https://docs.google.com/spreadsheets/d/11Sr8mqilWCe6Dj8TO6PgTYpJT292vbon1XnB0Co1Trc/edit?usp=sharing'\n\ndados &lt;- data.frame(gsheet2tbl(url))\nprint(dados)\n\n   Unidade.Federativa..UF. População.Estimada..2023. Crimes.de.estupro\n1                     Acre                    830018               745\n2                  Alagoas                   3127511              1040\n3                    Amapá                    733759               628\n4                 Amazonas                   4145525               836\n5                    Bahia                  14659023              4558\n6                    Ceará                   9187078              1897\n7         Distrito Federal                   2817068               754\n8           Espírito Santo                   4018650              1736\n9                    Goiás                   7206589              3667\n10                Maranhão                   6775152              2273\n11             Mato Grosso                   3784239              1889\n12      Mato Grosso do Sul                   2756700              2191\n13            Minas Gerais                  20812060              4491\n14                    Pará                   8442765              4557\n15                 Paraíba                   4039277               546\n16                  Paraná                  11835799              6648\n17              Pernambuco                   9496294              2705\n18                   Piauí                   3280062              1241\n19          Rio de Janeiro                  16615526              5627\n20     Rio Grande do Norte                   3302970               881\n21       Rio Grande do Sul                  11088065              5193\n22                Rondônia                   1616379              1027\n23                 Roraima                    636303               726\n24          Santa Catarina                   7762154              4541\n25               São Paulo                  45533984             12615\n26                 Sergipe                   2240560               885\n27               Tocantins                   1496880              1033\n\n\nUtilizando a posteriori Gama(74931,2083), teremos que \\[y_i^*|\\hbox{dados}\\sim\\hbox{Binomial Negativa}\\left(74931,\\frac{2083}{N_i+2083}\\right).\\]\nPodemos construir intervalos de 95% (de predição) para \\(y^*_i\\) utilizando os quantis da preditiva a posteriori, ou seja, encontrando \\(q_1\\) e \\(q_2\\) tais que \\[\\begin{align}\nP(Y_i^*\\leq q_1|\\boldsymbol{y})&=0,025\\\\\nP(Y_i^*\\leq q_2|\\boldsymbol{y})&=0,975.\n\\end{align}\n\\]\nObserve ainda que \\[0,95\\approx P(q_1\\leq Y_i^*\\leq q_2|\\boldsymbol{y})=P\\left(\\frac{q_1}{N_i}\\leq \\frac{Y_i^*}{N_i}\\leq \\frac{q_2}{N_i}|\\boldsymbol{y}\\right),\\] o que implica que \\((q_1,q_2)/N_i\\) é um intervalo de predição de 95% para taxa esperada. Abaixo construímos estes intervalos e contrastamos com a taxa observada.\n\n# taxas observadas\nN &lt;- unlist(dados[,2]/100000)\ntaxas &lt;- unlist(dados[,3]/N)\n\n# posteriori\nr1 = 74931\ns1 = 2083\n\n# limites do intervalo da preditiva a posteriori\nlim_inf &lt;- qnbinom(.025, size = r1, prob = s1/(N+s1))\nlim_sup &lt;- qnbinom(.975, size = r1, prob = s1/(N+s1))\n\n# gráfico\ncores = c('red','green4','red',rep('orange',4),'red','red','green4',\n          'red','red',rep(c('orange','red'),2), 'orange','green4','green4','orange',rep('red',4),'orange','green4','red')\nplot.new()\nplot.window( xlim = c(-70,120), ylim=c(0,27))\nsegments(lim_inf/N,1:27,lim_sup/N,1:27, lwd = 2)\ntext(-70,1:27, unlist(dados[,1]), adj =0 ,col=cores)\npoints(taxas, 1:27, pch = 22, cex =.9, bg = cores)\naxis(1,at = seq(0,120,20))\n\n\n\n\n\n\n\n\nObserve que o modelo de considera uma taxa única para o país se ajusta bem para os estados Alagoas, Maranhão, Piauí, Rio de Janeiro e Sergipe. Unidades da Federação como Amazonas, Bahia, Ceará, Distrito Federal, Minas Gerais, Pernambuco, Rio Grande do Norte e São Paulo, possuem taxas menores do que as preditas. Os demais estados possuem taxas maiores do que as preditas.\n\n\n\n7.4.2 Modelo com uma taxas por localidade\nO último exemplo da seção anterior mostra que o modelo com taxa única pode ser falho. Existem algumas explicações para este fenômeno, como:\n\nO evento observado não depende apenas do tamanho da população. O crime de estupro, por exemplo, depende de variáveis como vunerabilidade social e aparelhamento do estado para o acolhimento das vítimas.\nO evento observado pode ser raro. Eventos raros são mais difíceis de serem observados em populações menores, o que causa distorções.\n\nPodemos tentar mitigar os efeitos acima considerando um modelo no qual cada região possui sua própria taxa, i.e.\n\\[y_i|\\lambda_i\\sim\\hbox{Poisson}(\\lambda_i N_i).\\] Considerando a priori \\(\\lambda_i\\sim\\hbox{Gama}(r,s)\\), teremos\n\\[\\begin{align}\n\\lambda_i| \\hbox{dados} & \\sim \\hbox{Gama}(r+y_i,s+N_i)\\\\\ny^*_i|\\hbox{Dados}&\\sim\\hbox{Binomial Negativa}\\left(r+y_i,\\frac{s}{s+N_i}\\right)\n\\end{align}\\]\nObserve que mesmo que cada região tenha a sua própria taxa, a informação a priori é a mesma para todas elas. Deste modo, é importante que a priori reflita as várias possibilidades de taxas.\n\nCrime de estupro no país (cont.) Considere que as taxas para cada unidade da federação são independentes e identicamente distribuídas. Abaixo apresentamos a densidade estimada via método do núcleo para as taxas.\n\nplot(density(taxas))\ncurve(dgamma(x,100,.5),add = T)\n\n\n\n\n\n\n\n\nVimos na Introdução que uma priori Gama\\((r,s)\\) pode ser elicitada utilizando as seguintes fórmulas:\n\\[\\begin{align}a&=\\left(\\frac{\\hbox{média}}{desvio}\\right)^2\\\\\nb=\\frac{a}{\\hbox{média}}\\end{align}\\]\nFazendo os cálculos abaixo\n\nmedia = mean(taxas)\ndesvio = sd(taxas)\nr = (media/desvio)^2\ns = r/media\nr;s\n\n[1] 3.608031\n\n\n[1] 0.07758706\n\n\nA próxima figura reapresenta a densidade estimada em conjunto com a densidade Gama(3,6;,;0,07)\n\nplot(density(taxas))\ncurve(dgamma(x,3.6,.07),add = T, lwd = 2, col ='tomato')\n\n\n\n\n\n\n\n\nVamos utilizar a priori \\(\\lambda_i\\sim\\hbox{Gama}(3,6\\;,\\;0,07)\\) para analizar este banco de dados, agora com múltiplas taxas.\n\n# hiperparametros\nr = 3.6\ns = .07\n\n# posterioris\nr1 = unlist(dados[,3])+r\ns1 = N + s\n\n# limites do intervalo da preditiva a posteriori\nlim_inf &lt;- qnbinom(.025, size = r1, prob = s1/(N+s1))\nlim_sup &lt;- qnbinom(.975, size = r1, prob = s1/(N+s1))\n\n# gráfico\ncores = c('red','green4','red',rep('orange',4),'red','red','green4',\n          'red','red',rep(c('orange','red'),2), 'orange','green4','green4','orange',rep('red',4),'orange','green4','red')\nplot.new()\nplot.window( xlim = c(-70,120), ylim=c(0,27))\nsegments(lim_inf/N,1:27,lim_sup/N,1:27, lwd = 2)\ntext(-70,1:27, unlist(dados[,1]), adj =0 ,col=cores)\npoints(taxas, 1:27, pch = 22, cex =.9, bg = cores)\naxis(1, at=seq(0,120,20))\n\n\n\n\n\n\n\n\nAs múltiplas taxas apresentam um cenário mais honesto, acomodando cada estado a sua própria realidade. Abaixo, apresentamos um mapa com a taxa estimada.\n\n# Carregar as bibliotecas necessárias\nlibrary(leaflet)\nlibrary(geobr)\n\nCarregando namespace exigido: sf\n\n# Obter os dados geográficos das Unidades da Federação do Brasil usando geobr\nbrasil_uf &lt;- read_state() # Ou o ano mais recente disponível\n\nUsing year/date 2010\n\n# colocar os estados em ordem alfabética\nbrasil_uf &lt;- brasil_uf[order(brasil_uf$name_state), ]\n\n# adicionar as taxas\nbrasil_uf$taxa &lt;- r1/s1\n\n# Definir uma paleta de cores com base nos valores das taxas\npal &lt;- colorNumeric(palette = \"viridis\", domain = brasil_uf$taxa)\n\n# Criar o mapa leaflet\nmapa_leaflet &lt;- leaflet(brasil_uf) %&gt;%\n  setView(lng = -55, lat = -15, zoom = 3) %&gt;% # Centralizar o mapa no Brasil\n  addTiles() %&gt;% # Adicionar camadas de mapa base (OpenStreetMap por padrão)\n  addPolygons(\n    fillColor = ~pal(taxa),\n    weight = 1,\n    color = \"#000000\",\n    fillOpacity = 0.7,\n    label = ~paste0(name_state, \": \", round(taxa, 2)), # Adicionar rótulos ao passar o mouse\n    highlightOptions = highlightOptions(color = \"white\", weight = 2, bringToFront = TRUE)\n  ) %&gt;%\n  addLegend(pal = pal, values = ~taxa, title = \"Taxa\", opacity = 1)\n\nWarning: sf layer has inconsistent datum (+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs).\nNeed '+proj=longlat +datum=WGS84'\n\n# Exibir o mapa (opcional, se você estiver em um ambiente interativo)\nmapa_leaflet\n\n\n\n\n\n\n\n\n7.4.3 Análise de agrupamentos para taxas - modelagem 1\nAté o momento estudamos dois exemplos extremos:\n\nUm modelo com uma única taxa por localidade\nUm modelo com uma taxa por localidade\n\nUm modo útil para decidir qual abordagem é a mais interessante é o uso de um critério de informação. Recordemos que tais critério são escritos como\n\\[-2\\log L(\\hat{\\theta})+2k,\\] onde \\(L(\\theta)\\) é a função de verossimilhança, \\(\\hat{\\theta}\\) é uma estimativa para \\(\\theta\\) e \\(k\\) é uma penalidade relacionada ao número de parâmetros do modelo. Por causa do sinal negativo em \\(L(.)\\), temos que o modelo preferível é aquele com menor valor do critério.\nEm inferência bayesiana é comum o uso do Critério de Informação de Desvio (DIC), onde \\(\\hat{\\theta}=E(\\theta|\\boldsymbol{x})\\) e \\[k=\\frac{1}{2}Var_{\\theta|\\boldsymbol{x}}(\\log L(\\theta)).\\]\nObserve que o cálculo direto de \\(k\\) não é trivial. Entretanto, o DIC pode ser facilmente obtido via o Método de Monte Carlo.\n\nAlgoritmo: Calculando o DIC via Monte Carlo\n\nSimule \\(\\theta_1,\\ldots,\\theta_B\\) da distribuição a posteriori de \\(\\theta\\).\nEstime \\(E(\\theta|\\boldsymbol{x})\\) por \\[\\hat{\\theta}=\\frac{1}{B}\\sum_{j=1}^B \\theta_j\\]\nFaça \\(v_j=-2\\log L(\\theta_j)\\). Estime \\(k\\) por \\[k=\\frac{1}{2B}\\sum_{j=1}^B(v_j-\\bar{v})^2\\]\nCalcule o DIC:\n\n\\[DIC=-2\\log L(\\hat{\\theta})+2k.\\]\n\n\nComparando os dois modelos para as taxas\nNo começo desta seção, estudamo a taxa de crimes de estupro no Brasil, considerando uma única taxa \\(\\lambda\\) comum a todas as unidades da federação. Encontramos a posteriori \\(\\lambda\\sim\\hbox{Gama}(74931,2083)\\). O DIC para este modelo é\n\nB = 10000 # número de simulações\nlambda &lt;- rgamma( B, 74931, 2083) # simulações da posteriori\n\n# média a posteriori\nlambda_chapeu &lt;- mean(lambda)\n\n# calculo de k\nvj &lt;- sapply( lambda, function(l) -2*sum(dpois( dados[,3], l*N, log = T)))\nk &lt;- .5*var(vj)\n\nDIC0 &lt;- -2*sum( dpois(dados[,3], lambda_chapeu*N, log = T) ) +2*k\nDIC0\n\n[1] 11771.31\n\n\nPosteriormente, criamos um modelo com uma taxa por unidade da federação. Para a \\(i\\)ésima unidade, a posteriori da taxa foi dada ´por \\(\\lambda_i\\sim\\hbox{Gama}(y_i+3,6\\;\\;,\\;\\;N_i+0,07)\\). O DIC para este modelo é\n\nB = 10000 # número de simulações\n# hiperparâmetros comuns\nr = 3.6\ns = .07\n\n# simulações da posteriori\nlambda &lt;- sapply(1:B, function(x) rgamma(27, dados[,3]+3.6, N+.07) )\n\n# média a posteriori para cada taxa\nlambda_chapeu &lt;- rowMeans(lambda)\n\n# calculo de k\nvj &lt;- apply( lambda, 2, function(l) -2*sum(dpois( dados[,3], l*N, log = T)))\nk &lt;- .5*var(vj)\n\nDICtodos &lt;- -2*sum( dpois(dados[,3], lambda_chapeu*N, log = T) ) +2*k\nDICtodos\n\n[1] 308.5074\n\n\nObserve que o modelo com uma taxa por unidade da federação possui o menor valor do DIC, sendo assim o mais parcimonioso entre os dois.\n\nSeja \\(S=\\{1,\\ldots,m\\}\\) o conjunto das \\(m\\) localidades. Suponha que é razoável particionar \\(S\\) em \\(k\\) grupos. Por último, considere que todas as localidades dentro de uma partição compartilham a mesma taxa, ou seja, para \\(j\\) dentro da partição \\(S_t\\), tem-se que \\(y_i|\\lambda_t\\sim\\hbox{Poisson}(\\lambda_tN_i)\\), onde \\(\\lambda_t\\sim\\hbox{Gama}(r_t,s_t)\\). O desafio aqui é determinar se a localidade pertence à partição \\(S_t\\).\nPodemos utilizar alguma técnica não paramétrica de agrupamento e então consideramos essa classificação para fins da modelagem.\n\nAnálise de agrupamento para as taxas de crimes de estupro\nConsiderando o mapa dado no exemplo anterior, podemos conjecturar que existem em torno de 3 a 5 agrupamentos das taxas.\nComeçando nossa análise com três grupos, podemos fazer uma classificação inicial das taxas utilizando o método das \\(k\\)-médias para obter uma classificação inicial\n\ngrupos = 3\nkm = kmeans(taxas,grupos)\n\nApresentamos a seguir os agrupamentos encontrados:\n\n# Grupo 1\ndados[,1][km$cluster == 1]\n\n [1] \"Alagoas\"             \"Amazonas\"            \"Bahia\"              \n [4] \"Ceará\"               \"Distrito Federal\"    \"Maranhão\"           \n [7] \"Minas Gerais\"        \"Paraíba\"             \"Pernambuco\"         \n[10] \"Piauí\"               \"Rio de Janeiro\"      \"Rio Grande do Norte\"\n[13] \"São Paulo\"           \"Sergipe\"            \n\n# Grupo 2\ndados[,1][km$cluster == 2]\n\n[1] \"Acre\"               \"Amapá\"              \"Mato Grosso do Sul\"\n[4] \"Roraima\"           \n\n# Grupo 3\ndados[,1][km$cluster == 3]\n\n[1] \"Espírito Santo\"    \"Goiás\"             \"Mato Grosso\"      \n[4] \"Pará\"              \"Paraná\"            \"Rio Grande do Sul\"\n[7] \"Rondônia\"          \"Santa Catarina\"    \"Tocantins\"        \n\n\nEm seguinda, podemos utilizar essa classificação para construir as três prioris para as taxas. Lembremos que \\[E(\\lambda)=\\frac{r}{s}\\] e que \\[Var(\\lambda)=\\frac{E(\\lambda)}{s}\\]\nVamos escolher para os parâmetros da priori \\(r\\approx \\tau\\text{taxa}\\) e \\(s=\\tau\\). Deste modo, a média da priori estará próxima da taxa e a variância vai ser controlada por \\(\\tau.\\). Vamos escolhe \\(\\tau=0,1\\)\n\nr = s = NULL\ntau = .1\nfor(i in 1:grupos){\n  media = mean(taxas[km$cluster == i])\n  r[i] &lt;- media*tau\n  s[i] &lt;- tau\n}\n\nAs posterioris estão podem ser calculadas para cada um dos três agrupamentos.\n\nr1 = s1 = NULL\nfor(i in 1:grupos){\n  r1[i] &lt;- r[i] + sum( dados[,3][km$cluster == i])\n  s1[i] &lt;- s[i] + sum( N[km$cluster == i])\n}\n\nAbaixo apresentamos as 3 posterioris.\n\ncurve(dgamma(x,r1[1],s1[1]),10,120, ylab = 'Posteriori',xlab='Taxa')\ncurve(dgamma(x,r1[2],s1[2]),add=TRUE, col = 2)\ncurve(dgamma(x,r1[3],s1[3]),add=TRUE, col = 3)\nlegend('topright',c('Grupo 1','Grupo 2', 'Grupo 3'), col=1:3, lty=1, bty='n')\n\n\n\n\n\n\n\n\nPodemos então calcular o DIC para esse novo modelo.\n\nB = 1000 # número de simulações\n\n# simulações da posteriori\nlambda1 &lt;- rgamma(B, r1[1], s1[1]) \nlambda2 &lt;- rgamma(B, r1[2], s1[2]) \nlambda3 &lt;- rgamma(B, r1[3], s1[3]) \n\n# média a posteriori para cada taxa\nlambda_chapeu &lt;- c(mean(lambda1),mean(lambda2),mean(lambda3)) \n# calculo de k\nvj &lt;- apply( cbind(lambda1,lambda2,lambda3), 1, function(l){ \n  t1 = -2*sum(dpois( dados[,3][km$cluster==1], l[1]*N[km$cluster==1], log = T))\n  t2 = -2*sum(dpois( dados[,3][km$cluster==2], l[2]*N[km$cluster==2], log = T))\n  t3 = -2*sum(dpois( dados[,3][km$cluster==3], l[3]*N[km$cluster==3], log = T))\n  t1+t2+t3\n})\nk &lt;- .5*var(vj)\n\n\n  t1 = -2*sum(dpois( dados[,3][km$cluster==1], lambda_chapeu[1]*N[km$cluster==1], log = T))\n  t2 = -2*sum(dpois( dados[,3][km$cluster==2], lambda_chapeu[2]*N[km$cluster==2], log = T))\n  t3 = -2*sum(dpois( dados[,3][km$cluster==3], lambda_chapeu[3]*N[km$cluster==3], log = T))\n\nDIC3 &lt;- (t1+t2+t3) +2*k\nDIC3\n\n[1] 2202.747\n\n\nObserve que este modelo é mais interessante que o modelo com uma única taxa (DIC 11.771) mas menos interessante que o modelo com uma taxa por UF (DIC 307).\n\n\n\n7.4.4 Análise de agrupamento - modelagem 2\nAnteriormente, utilizamos os dados para construir a priori. Nesta seção, vamos tratar o problema sob o ponto de vista puramente bayesiano.\nSeja \\(z_{j}=(z_{j,1},\\ldots,z_{j,k})\\sim\\hbox{Bernoulli Multivariada}(p_1,\\ldots,p_k)\\). Aqui, a coordenada onde \\(z_j\\) é igual a um representa o conjunto da partição a qual a localidade \\(j\\) pertence. Sem perda de generalidade, podemos escrever\n\\[f(y_j|z_j,\\lambda_1,\\ldots,\\lambda_k)=\\prod_{t=1}^k\\left[\\frac{e^{-\\lambda_t N_t}(\\lambda_tN_t)^{y_j}}{y_j!}\\right]^{z_{j,t}},\\]\nObserve que a verossimilhança original não é mais Poisson, uma vez que \\[f(y_j|\\lambda)=\\sum_{z_{j}}\\prod_{t=1}^k\\left[\\frac{e^{-\\lambda_t N_t}(\\lambda_tN_t)^{y_j}}{y_j!}\\right]^{z_{j,t}} f(z_{j})\\] Observe que é natural assumir que \\(z_j\\sim\\hbox{Bernoulli M}(p_1,\\ldots,p_k)\\). Considerando as prioris \\(lambda_t\\sim\\hbox{Gama}(r_t,s_t)\\), e \\(p\\hbox{Dirichlet}(a_1,\\ldots,a_k)\\) teremos a posteriori\n\\[\\begin{align} f(\\lambda_1,\\ldots,\\lambda_k,z_1,\\ldots,z_m|\\hbox{dados})&\\propto \\prod_{j=1}^m\\prod_{t=1}^k\\left[\\frac{e^{-\\lambda_t N_j}(\\lambda_tN_j)^{y_j}}{y_j!}\\right]^{z_{j,t}}\\\\&\\times \\prod_{t=1}^k \\frac{s_t^{r_t}}{\\Gamma(r_t)}\\lambda_t^{r_t-1}e^{-s_t\\lambda_t}\\\\&\\times \\prod_{j=1}^m \\prod_{t=1}^k p_t^{z_{j,t}}\\times \\prod_{t=1}^k p_t^{a_t-1} \\end{align}\\]\n\n**Amostrador de Gibbs** Considere que desejamos simular amostras da distribuição conjunta de $X,Y,Z$.\n\nComece com um valor arbitrário $(x_0,y_0,z_0)$. Para $i$ variando de 1 até $B$:\n\n1. Simule $x_i\\sim f(x|y_{i-1},z_{i-1})$\n\n2. Simule $y_i\\sim f(y|x_{i},z_{i-1})$\n\n3. Simule $z_i\\sim f(z|x_{i},y_{i})$\n\n\nAnálise de agrupamento para as taxas de crimes de estupro\nConsiderando o mapa dado no exemplo anterior, podemos conjecturar que existem em torno de 3 a 5 agrupamentos das taxas.\nComençando nossa análise com três grupos, podemos fazer uma classificação inicial das taxas utilizando o método das \\(k\\)-médias para obter uma classificação inicial\n\ngrupos = 3\nkm = kmeans(taxas,grupos)\n\nEm seguinda, podemos utilizar essa classificação para construir as três prioris para as taxas.\n\nr = s = NULL\ntau = .1\nfor(i in 1:grupos){\n  media = mean(taxas[km$cluster == i])\n  r[i] &lt;- tau*media\n  s[i] &lt;- tau\n}\n\nConsiderando a priori \\(p\\sim\\hbox{Dirichlet}(1,1,1)\\), temos os seguinte amostrador de Gibbs:\n\nrequire(extraDistr)\n\nCarregando pacotes exigidos: extraDistr\n\nB &lt;- 50000\ny = dados[,3]\nN &lt;- unlist(dados[,2]/100000)\n\nlambda &lt;- array( NA_real_, c(B+1,grupos) )\np      &lt;- array( NA_real_, c(B+1,grupos) )\nz      &lt;- array( NA_real_, c(B+1,27))\nlambda[1,] &lt;- r/s\nz[1,] &lt;- km$cluster\np[1,] &lt;- as.vector(table(z)/27)\n\n# condicional completa de lambda\nfor(i in 1:B){\n  for(t in 1:grupos){\n    lambda[i+1,t] &lt;- rgamma(1, r[t]+sum(y[z[i,]==t]), s[t]+sum(N[z[i,]==t]))\n  }\n  \n# condicional completa de p  \n  a = NULL\n  for(t in 1:grupos){\n    a = c(a, sum(z[i,]==t))\n  }\n  p[i+1,] &lt;- rdirichlet(1, 1+a)\n  \n# condicional completa de z\n  for(j in 1:27){\n    z[i+1,j] &lt;- sample(1:grupos,1,T, p[i+1,]*dpois(y[j],lambda[i+1,]*N[j]))  \n  }\n  \n}\n\nVamos eliminar metade das simulações (burn-in) e manter as amostras de 15 em 15. Abaixo apresentamos o traceplot das simulação e um dos correlogramas.\n\nlambda_post &lt;- lambda[seq(B/2,B,15),]\nz_post &lt;-      z[seq(B/2,B,15),]\np_post &lt;-      p[seq(B/2,B,15),]\nts.plot(lambda_post)\n\n\n\n\n\n\n\nacf(lambda_post[,1])\n\n\n\n\n\n\n\n\nVamos calcular o DIC para o modelo encontrado.\n\n# média a posteriori para os parâmetros\nlambda_chapeu &lt;- colMeans(lambda_post)\np_chapeu &lt;- colMeans(p_post)\n\n# calculo de k\nvj &lt;- apply( cbind(lambda_post,p_post), 1, function(w){\n   veross = NULL\n   u = ncol(lambda)\n   for(i in 1:u){\n     veross = cbind(veross , w[i+u]*dpois(dados[,3],w[i]*N))\n   }\n   -2*sum( log(rowSums(veross)))\n}) \n  \nk &lt;- .5*var(vj)\n\nveross = NULL\n   for(i in 1:ncol(lambda_post)){\n      veross = cbind(veross , p_chapeu[i]*dpois(dados[,3],lambda_chapeu[i]*N))\n   }\nDIC3 &lt;- -2*sum( log(rowSums(veross) )) +2*k\nDIC3\n\n[1] 2210.651\n\n\nObserve que este valor semelhante ao encontrado na análise anterior. Para determinar os agrupamentos, podemos verificar a distribuição a posteriori de \\(z_j\\). Por exemplo, a posteriori de \\(z_j\\) para o Acre é dada abaixo\n\ntb &lt;- table(z_post[,1])\nplot(prop.table(tb), ylab='f(z|dados)',xlab='Grupo')\n\n\n\n\n\n\n\n\nVariando o número de grupos, obtivemos os seguintes valores para o DIC\n\n\n   Número.de.grupos  DIC\n1                 2 3043\n2                 3 2200\n3                 4 1442\n4                 5 1247\n5                 6  732\n6                 7  672\n7                 8  630\n8                 9  535\n9                10  489\n10               11  502\n11               12 1015\n\n\nA tabela acima mostra que parece ser razoável dividir estes dados em 10 grupos. Após refazer a análise com 10 grupos, identificamos os seguintes agrupamentos através da moda da posteriori de \\(z_j\\)\n\ngrupo_posteriori &lt;- c(8,1,2,6,1,6,7,5,3,1,5,10,6,3,9,3,7,1,1,7,5,3,8,10,7,4,10)\n\nmedia_post = c(32.78140,  82.46029,  56.16715,  40.46941,  48.68677,  21.15481,  27.73506, 114.13073,  13.53351,  66.20056)\nEstados = `Taxa média a posteriori` = NULL\nfor(i in 1:10){\n  Estados[i] &lt;- paste(dados[,1][grupo_posteriori==i], collapse = ', ')\n  `Taxa média a posteriori`[i] = media_post[i] \n}\nprint(data.frame(Estados,`Taxa média a posteriori`),width = 30)\n\n                                                        Estados\n1               Alagoas, Bahia, Maranhão, Piauí, Rio de Janeiro\n2                                                         Amapá\n3                                 Goiás, Pará, Paraná, Rondônia\n4                                                       Sergipe\n5                Espírito Santo, Mato Grosso, Rio Grande do Sul\n6                                 Amazonas, Ceará, Minas Gerais\n7  Distrito Federal, Pernambuco, Rio Grande do Norte, São Paulo\n8                                                 Acre, Roraima\n9                                                       Paraíba\n10                Mato Grosso do Sul, Santa Catarina, Tocantins\n   Taxa.média.a.posteriori\n1                 32.78140\n2                 82.46029\n3                 56.16715\n4                 40.46941\n5                 48.68677\n6                 21.15481\n7                 27.73506\n8                114.13073\n9                 13.53351\n10                66.20056",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>O modelo Poisson</span>"
    ]
  },
  {
    "objectID": "poisson.html#exercícios",
    "href": "poisson.html#exercícios",
    "title": "7  O modelo Poisson",
    "section": "7.5 Exercícios",
    "text": "7.5 Exercícios\n\n7.5.1 Mortes por coice de cavalo\nLadislaus Bortkiewicz é o responsável pela popularização da distribuição Poisson. Em seu livro intitulado A Lei dos Pequenos Números, é apresentado um conjunto de dados no qual foi rastreado o número de mortes por coice de cavalo em 14 corpos do exército prussiano ao longo de 20 anos (de 1875 a 1894).\n\n\n\nMortes por corpo \\(\\times\\) ano\n0\n1\n2\n3\n\n\n\n\n\n109\n65\n22\n3\n\n\n\nDetermine se a distribuição Poisson é adequada para este conjunto de dados. Em caso afirmativo, estime a taxa e dê um intervalo de credibilidade de 95%.\n\n\n7.5.2 Suicídios no Amazonas considerando capital e interior\nO Amazonas possui uma característica peculiar: aproximadamente 50% da população vive na capital. Vimos anteriormente que o número de suicídios, considerando os anos entre 2021 e 2023, podem ser modelados por uma Poisson. A tabela abaixo divide esses dados entre capital e interior.\n\nNúmero de suicídios divididos entre capital e interior\n\n\nAno\n2021\n2022\n2023\nTotal\n\n\n\n\nCapital\n133\n124\n138\n395\n\n\nInterior\n164\n173\n201\n538\n\n\n\nDetermine se há evidências de que essas taxas são diferentes.\n\n\n7.5.3 Crime de estupro de vulnerável no interior do Amazonas**\nOs dados a seguir foram cedidos pelo Observatório de Violência de Gênero no Amazonas e compreendem os anos entre 2010 e 2012. A população em risco é o número de mulheres com menos de 14 anos.\n\n\n\nCidade\nVítimas\nPopulacao feminina\n\n\n\n\nAmatura\n3\n639\n\n\nAtalaia do Norte\n6\n905\n\n\nBarreirinha\n12\n1899\n\n\nBenjamin Constant\n2\n2036\n\n\nBoa Vista do Ramos\n6\n1060\n\n\nFonte Boa\n0\n1438\n\n\nJutai\n1\n1143\n\n\nMaues\n13\n3421\n\n\nNhamunda\n9\n1168\n\n\nParintins\n20\n6700\n\n\nSanto Antonio do Ica\n7\n1608\n\n\nSao Paulo de Olivenca\n5\n2033\n\n\nTabatinga\n8\n3095\n\n\nTonantins\n1\n1186\n\n\n\nAjuste o modelo de taxa única e o modelo de uma taxa para cada município, calcule o DIC de cada e verifique qual é o modelo mais adequado. Em seguida, tente melhorar o ajuste procurando um agrupamento.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>O modelo Poisson</span>"
    ]
  },
  {
    "objectID": "normal.html",
    "href": "normal.html",
    "title": "8  O modelo normal",
    "section": "",
    "text": "8.1 A distribuição normal-gama\nDizemos que \\((X,Y)\\sim NG(\\mu,n_0,\\nu,d^2)\\) (lê-se normal-gama) se sua função densidade conjunta é dada por\n\\[f(x,y)\\propto y^{\\frac{\\nu+1}{2}-1}\\exp\\left\\{-\\frac{y}{2}n_0\\left[(x-\\mu)^2 + d^2\\right]\\right\\}\\]\nonde \\(\\mu,x\\in\\mathbb{R}\\) e \\(d,y,c\\in\\mathbb{R}_+\\). Colocando os termos que não dependem de \\(x\\) junto com a constante de proporcionalidade, podemos mostrar que\n\\[f(x|y)\\propto \\exp\\left\\{-\\frac{y}{2}n_0(x-\\mu)^2\\right\\}\\] ou seja, \\(X|y\\sim\\hbox{Normal}(\\mu,y^{-1}/n_0)\\). Além disso, integrando \\(f(x,y)\\) em \\(x\\), mostramos que\n\\[f(y)\\propto y^{\\frac{\\nu+1}{2}-1}e^{-\\frac{yn_0d^2}{2}}\\int_{\\mathbb{R}}\\exp\\left\\{-\\frac{y}{2}\\left[n_0(x-\\mu)^2\\right]\\right\\}d\\mu\\propto y^{\\frac{\\nu}{2}-1}e^{-\\frac{n_0d^2}{2}y}\\] ou seja, \\(Y\\sim\\hbox{Gama}(\\nu/2, n_0d^2/2)\\). Por último, integrando \\(f(x,y)\\) em \\(y\\) teremos\n\\[\\begin{align}f(x)&\\propto \\int_0^\\infty y^{\\frac{\\nu+1}{2}-1}\\exp\\left\\{-\\frac{y}{2}n_0\\left[(x-\\mu)^2 + d^2\\right]\\right\\}dy \\\\&\\propto \\Gamma\\left(\\frac{\\nu+1}{2}\\right)\\left\\{1+\\frac{\\nu}{d^2}\\frac{(x-\\mu)^2}{\\nu}\\right\\}^{-\\frac{\\nu+1}{2}}\\end{align}\\] ou seja, \\(X\\sim t_{\\nu}(\\mu, d^2/\\nu)\\). Em especial, se \\(\\nu&gt;1\\) então \\(E(X)=\\mu\\) e, se \\(\\nu&gt;2\\) teremos que \\[Var(X)=\\frac{d^2}{\\nu-2}\\]",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>O modelo normal</span>"
    ]
  },
  {
    "objectID": "normal.html#a-função-de-verossimilhança",
    "href": "normal.html#a-função-de-verossimilhança",
    "title": "8  O modelo normal",
    "section": "8.2 A função de verossimilhança",
    "text": "8.2 A função de verossimilhança\nSeja \\(X_1,\\ldots,X_n\\) uma amostra aleatória do modelo \\(X|\\mu,\\phi\\sim\\hbox{Normal}(\\mu,\\phi^{-1})\\), onde \\(\\phi\\), denominado precisão, é o inverso da variância. A função de verossimilhança deste modelo pode ser escrita como\n\\[L(\\mu,\\phi)\\propto \\phi^{\\frac{n}{2}}\\exp\\left\\{-\\frac{n\\phi}{2}(\\bar{x}-\\mu)^2 -\\frac{ns^2\\phi}{2}\\right\\}\\] onde \\[s^2=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2\\] é a estimativa de máxima verossimilhança para \\(\\phi^{-1}\\).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>O modelo normal</span>"
    ]
  },
  {
    "objectID": "normal.html#posteriori-com-prioris-impróprias",
    "href": "normal.html#posteriori-com-prioris-impróprias",
    "title": "8  O modelo normal",
    "section": "8.3 Posteriori com prioris impróprias",
    "text": "8.3 Posteriori com prioris impróprias\nConsiderando as prioris impróprias \\(\\pi(\\phi)\\propto \\phi^{-1}\\), \\(\\pi(\\mu)\\propto 1\\) e que \\(\\pi(\\mu,\\phi)=\\pi(\\mu)\\pi(\\phi)\\), teremos que\n\\[\\pi(\\mu,\\phi|\\boldsymbol{x})\\propto \\phi^{\\frac{n}{2}-1}\\left\\{-\\frac{\\phi}{2}n\\left[ (\\bar{x}-\\mu)^2 +s^2\\right]\\right\\}\\] ou seja, \\(\\mu,\\phi|\\boldsymbol{x}\\sim\\hbox{NG}(\\bar{x},n,n-1,s^2)\\), o que implica em:\n\\[\\begin{align}\n\\mu|\\phi,\\boldsymbol{x}&\\sim\\hbox{Normal}\\left(\\bar{x},\\frac{\\phi^{-1}}{n}\\right)\\\\\n\\phi|\\boldsymbol{x}&\\sim\\hbox{Gama}\\left(\\frac{n-1}{2},\\frac{ns^2}{2}\\right)\\\\\n\\mu|\\boldsymbol{x}&\\sim t_{n-1}\\left(\\bar{x},\\frac{s^2}{n-1}\\right)\n\\end{align}\\]\nDisto, teremos que\n\n\n\nParâmetro\nEstimativa\nErro\n\n\n\n\n\\(\\mu\\)\n\\(\\bar{x}\\)\n\\(\\frac{s}{\\sqrt{n-3}}\\)\n\n\n\\(\\phi\\)\n\\(\\frac{n-1}{ns^2}\\)\n\\(\\frac{\\sqrt{2(n-1)}}{s^2n}\\)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>O modelo normal</span>"
    ]
  },
  {
    "objectID": "normal.html#posteriori-com-a-priori-de-jeffreys",
    "href": "normal.html#posteriori-com-a-priori-de-jeffreys",
    "title": "8  O modelo normal",
    "section": "8.4 Posteriori com a priori de Jeffreys",
    "text": "8.4 Posteriori com a priori de Jeffreys\nO logaritmo da função de verossimilhança é\n\\[l(\\mu,\\phi)=\\frac{n}{2}\\log\\phi -\\frac{n}{2}\\phi\\left[(\\bar{x}-\\mu)^2 + s^2\\right]\\]\nAs derivadas de primeira ordem em \\(\\mu\\) e \\(\\phi\\) são \\[\\begin{align}\n\\frac{\\partial}{\\partial \\mu}l(\\mu,\\phi)&=n\\phi(\\bar{x}-\\mu)\\\\\n\\frac{\\partial}{\\partial \\phi}l(\\mu,\\phi)&=\\frac{n}{2\\phi}-\\frac{n}{2}\\left[(\\bar{x}-\\mu)^2 + s^2\\right]\\\\\n\\end{align}\\]\ne as de segunda ordem são \\[\\begin{align}\n\\frac{\\partial^2}{\\partial \\mu^2}l(\\mu,\\phi)&=-n\\phi\\\\\n\\frac{\\partial^2}{\\partial \\phi^2}l(\\mu,\\phi)&=-\\frac{n}{2\\phi^2}\\\\\n\\frac{\\partial^2}{\\partial \\mu\\partial \\phi}l(\\mu,\\phi)&=0\\\\\n\\end{align}\n\\] logo, a matriz de informação de Fisher é \\[\\mathcal{I}_n(\\mu,\\phi)=n\\left[\\begin{array}{cc}\\phi & 0 \\\\0 & \\frac{1}{2\\phi^2}\\end{array}\\right],\\] e a priori de Jeffreys é \\[\\pi(\\mu,\\phi)\\propto \\sqrt{|\\mathcal{I}_n(\\mu,\\phi)|}=\\phi^{-1/2},\\] que implica na posteriori\n\\[\\pi(\\mu,\\phi|\\boldsymbol{x})\\propto \\phi^{\\frac{n+1}{2}-1}\\left\\{-\\frac{n\\phi}{2}\\left[(\\bar{x}-\\mu)^2 +s^2 \\right]\\right\\}\\] ou seja, \\(\\mu,\\phi|\\boldsymbol{x}\\sim\\hbox{NG}(\\bar{x},n,n,s^2)\\), o que implica em:\n\\[\\begin{align}\n\\mu|\\phi,\\boldsymbol{x}&\\sim\\hbox{Normal}\\left(\\bar{x},\\frac{\\phi^{-1}}{n}\\right)\\\\\n\\phi|\\boldsymbol{x}&\\sim\\hbox{Gama}\\left(\\frac{n}{2},\\frac{ns^2}{2}\\right)\\\\\n\\mu|\\boldsymbol{x}&\\sim t_{n}\\left(\\bar{x},\\frac{s^2}{n}\\right)\n\\end{align}\\]\nDisto, teremos que\n\n\n\nParâmetro\nEstimativa\nErro\n\n\n\n\n\\(\\mu\\)\n\\(\\bar{x}\\)\n\\(\\frac{s}{\\sqrt{n-2}}\\)\n\n\n\\(\\phi\\)\n\\(\\frac{1}{s^{2}}\\)\n\\(\\frac{\\sqrt{2}}{s^2\\sqrt{n}}\\)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>O modelo normal</span>"
    ]
  },
  {
    "objectID": "normal.html#posteriori-para-a-priori-conjugada",
    "href": "normal.html#posteriori-para-a-priori-conjugada",
    "title": "8  O modelo normal",
    "section": "8.5 Posteriori para a priori conjugada",
    "text": "8.5 Posteriori para a priori conjugada\nConsidere que \\((\\mu,\\phi)\\sim \\hbox{NG}(m_0,n_0,\\nu_0,s^2_0)\\). Esta priori é conjugada para o modelo normal, uma vez que\n\\[\\begin{align}\n\\pi(\\mu,\\phi|\\boldsymbol{x})&\\propto \\phi^{\\frac{n}{2}}\\exp\\left\\{-\\frac{\\phi}{2}n\\left[(\\bar{x}-\\mu)^2+ s^2\\right]\\right\\}\\phi^{\\frac{\\nu_0+1}{2}-1}\\exp\\left\\{-\\frac{\\phi}{2}n_0\\left[(\\mu-m_0)^2 + s_0^2\\right]\\right\\}\\\\\n&\\phi^{\\frac{\\nu_0+n}{2}-1}\\exp\\left\\{-\\frac{\\phi}{2}\\left[n(\\bar{x}-\\mu)^2 + n_0(\\mu-m_0)^2+ns^2 + n_0s^2_0\\right]\\right\\}\\end{align}.\\] Como \\[n(\\bar{x}-\\mu)^2 +n_0(\\mu-m_0)^2 = (n+n_0)(\\mu-m_1)^2+\\frac{n n_0}{n+n_0}(\\bar{x}-m_0)^2\\] onde \\[\\begin{align}\nm_1&=\\frac{n}{n+n_0}\\bar{x}+\\frac{n_0}{n+n_0}m_0\n\\end{align},\\] teremos \\[\\begin{align}\n\\pi(\\mu,\\phi|\\boldsymbol{x})&\\propto \\phi^{\\frac{\\nu_1+1}{2}-1}\\exp\\left\\{-\\frac{\\phi}{2}n_1\\left[(\\mu-m_1)^2 + d_1^2\\right]\\right\\}\\end{align},\\] onde \\[\\begin{align}\n\\nu_1&=\\nu_0+n\\\\\nn_1&=n_0+n\\\\\nm_1&=\\frac{n}{n1}\\bar{x}+\\frac{n_0}{n_1}m_0\\\\\nd_1^2& = \\frac{n_0n}{n_1^2}(\\bar{x}-m_0)^2+\\frac{n}{n_1}s^2 + \\frac{n_0}{n_1}s^2_0\n\\end{align}\\] ou seja, \\(\\mu,\\phi|\\boldsymbol{x}\\sim\\hbox{NG}(m_1,n+n_0,\\nu_0+n,d_1^2)\\), o que implica em:\n\\[\\begin{align}\n\\mu|\\phi,\\boldsymbol{x}&\\sim\\hbox{Normal}\\left(m_1,\\frac{\\phi^{-1}}{n+n_0}\\right)\\\\\n\\phi|\\boldsymbol{x}&\\sim\\hbox{Gama}\\left(\\frac{n+\\nu_0}{2},\\frac{(n+n_0)d_1^2}{2}\\right)\\\\\n\\mu|\\boldsymbol{x}&\\sim t_{n}\\left(m_1,\\frac{d^2_1}{\\nu_0+n}\\right)\n\\end{align}\\]\nDisto, teremos que\n\n\n\n\n\n\n\n\nParâmetro\nEstimativa\nErro\n\n\n\n\n\\(\\mu\\)\n\\(\\frac{n}{n+n_0}\\bar{x}+\\frac{n_0}{n+n_0}m_0\\)\n\\(\\frac{d_1}{\\sqrt{n+\\nu_0-2}}\\)\n\n\n\\(\\phi\\)\n\\(\\frac{n+\\nu_0}{(n+n_0)d_1^2}\\)\n\\(\\frac{\\sqrt{2(n+\\nu_0)}}{d_1^2(n+n_0)}\\)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>O modelo normal</span>"
    ]
  },
  {
    "objectID": "normal.html#detecção-de-outliers",
    "href": "normal.html#detecção-de-outliers",
    "title": "8  O modelo normal",
    "section": "8.6 Detecção de outliers",
    "text": "8.6 Detecção de outliers",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>O modelo normal</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html",
    "href": "negativeBinomial.html",
    "title": "9  Binomial negativa",
    "section": "",
    "text": "9.1 O modelo binomial negativo\nA distribuição Poisson é muito comum em problemas de contagem. Como sua esperança e variância são iguais, o termo sobredispersão foi cunhado na literatura como uma variância maior que a média, o que seria indício de que o modelo Poisson não é adequado (de modo análogo, há o conceito de subdispersão, mas não é um fenômeno comum).\nDizemos que \\(X|\\rho,\\phi\\sim\\hbox{Binomial Negativa}\\) se\n\\[p(x|\\rho,\\phi)=\\frac{\\Gamma(\\phi+x)}{x!\\Gamma(\\phi)}\\rho^\\phi(1-\\rho)^x,\\] onde \\(x\\in\\mathbb{N}\\), \\(\\rho\\in(0,1)\\) e \\(\\phi&gt;0\\).\nExistem diversos motivos para considerar o modelo binomial negativo uma alternativa quando o modelo Poisson não parece ser adequado. Primeiro, temos que \\(E(X|\\rho,\\phi)=\\phi(1-\\rho)/\\rho\\) e \\(Var(X|\\rho,\\phi)=E(X|\\rho,\\phi)/\\rho\\), logo, a sobredispersão está presente no modelo. Além disso, se \\(X|\\lambda\\sim\\hbox{Poisson}(\\lambda)\\) e \\(\\lambda\\sim\\hbox{Gama}(\\phi, \\rho/(1-\\rho))\\), então \\(X|\\phi,\\rho\\sim\\hbox{Binomial Negativa}(\\phi,\\rho)\\) logo, este modelo é uma mistura do modelo Poisson. Por último, fazendo \\[\\mu=\\phi\\frac{1-\\rho}{\\rho}\\Rightarrow \\rho(\\phi)=\\frac{\\phi}{\\phi+\\mu},\\] pode-de mostrar que \\[\\lim_{\\phi\\rightarrow\\infty}p(x|\\phi)=\\frac{e^{-\\mu}\\mu^x}{x!}\\] ou seja, o modelo Poisson também pode ser vist como um caso limite do binomial negativo.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html#priori-para-phi-condicionado",
    "href": "negativeBinomial.html#priori-para-phi-condicionado",
    "title": "9  Binomial negativa",
    "section": "9.2 Priori para \\(\\phi\\) condicionado",
    "text": "9.2 Priori para \\(\\phi\\) condicionado\nQuando \\(\\phi\\) é conhecido, a verossimilhança do modelo se torna\n\\[L(\\rho|\\phi)\\propto \\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i},\\] logo, o modelo Beta\\((a,b)\\) é conjugado, com a posteriori dada por \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi+a,\\sum_{i=1}^n x_i+b\\right).\\]\nA priori de Jeffreys é dada por\n\\[\\pi(\\rho)\\propto \\frac{1}{\\rho(1-\\rho)^{1/2}},\\] o que implica na posteriori \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi,\\sum_{i=1}^n x_i+\\frac{1}{2}\\right).\\]",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html#priori-para-phi",
    "href": "negativeBinomial.html#priori-para-phi",
    "title": "9  Binomial negativa",
    "section": "9.3 Priori para \\(\\phi\\)",
    "text": "9.3 Priori para \\(\\phi\\)\nSeja \\(\\pi(\\phi)\\pi(\\rho)\\) a priori para \\((\\phi,\\rho)\\). Então, teremos que\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}\\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i}\\pi(\\phi)\\pi(\\rho).\\]\nAssumindo qualquer uma das prioris da seção anterior, teremos\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\pi(\\rho|\\phi,\\boldsymbol{x}),\\]\nlogo,\n\\[\\pi(\\phi|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\]\nComo a posteriori de \\(\\phi\\) não é uma distribuição conhecida, precisamos construir um simulador. O algoritmo Metropolis-Hastings é uma boa escolha, uma vez que a constante de proporcionalidade da densidade é desconhecida.\n\nAlgoritmo Metropolis-Hastings\nO Metropolis-Hastings simula se utiliza de uma distribuição que sabemos simular (denominada proposta) para gerar uma cadeia de Markov cuja distribuição estacionária é a distribuição de interesse.\nNa \\(j\\)-ésima itereção, a simulação do valor proposto \\(\\phi^*\\) é baseada no valor atual da cadeia, \\(\\phi^{(j-1)}\\). Como \\(\\phi&gt;0\\), a proposta \\(\\phi^*\\sim \\hbox{Gamma}(\\tau\\phi^{(j-1)},\\tau)\\) é adequada uma vez que \\[E(\\phi^*)=\\phi^{(j-1)}\\] e \\[\\sqrt{Var(\\phi^*)}=\\frac{\\phi^{(j-1)}}{\\tau}\\] Acima, \\(\\tau\\) é denominado tunning (afinação em tradução livre) e deve ser escolhido para que a cadeia tenha o número de aceites da proposta controlado (algo em torno de 23% ).\nAbaixo, segue o algoritmo\n\nFaça \\(j=0\\) e escolha um valor para \\(\\phi^{(0)}\\) (a estimativa de máxima verossimilhança, por exemplo). Faça um contador de aceites, começando com \\(k=0\\).\nPara o passo \\(j\\):\n\n\nSimule \\(\\phi^*\\sim\\hbox{Gama}(\\tau\\phi^{j-1},\\tau)\\)\nCalcule\n\n\\[prob = \\frac{\\pi(\\phi^*|\\boldsymbol{x})}{\\pi(\\phi^{(j-1)}|\\boldsymbol{x})}\\frac{g(\\phi^{(j-1)}|\\tau\\phi^*,\\tau)}{g(\\phi^*|\\tau\\phi^{(j-1)},\\tau)},\\] onde \\(g(.|a,b)\\) é a função densidade do modelo gama. + Simule \\(u\\sim\\hbox{Uniforme}(0,1)\\). Se \\(u&lt;prob\\), faça \\(\\phi^{(j)}=\\phi^*\\) e \\(k=k+1\\) (houve um aceite). Senão, faça \\(\\phi^{(j)}=\\phi^{(j-1)}\\).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html",
    "href": "aproximacaoNormal.html",
    "title": "10  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "",
    "text": "10.1 Aproximação da posteriori pela distribuição normal\nAssuma que \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^q\\). Seja \\(\\ell(\\boldsymbol{\\theta})=\\log L(\\boldsymbol{\\theta})\\) a função log-verossimilhança e \\(\\hat{\\boldsymbol{\\theta}}\\) a estimativa de máxima verossimilhaça para \\(\\boldsymbol{\\theta}\\). Considere a seguinte aproximação de \\(\\ell(\\boldsymbol{\\theta})\\) em séries de Taylor\n\\[\\ell(\\boldsymbol{\\theta})\\approx  \\ell(\\hat{\\boldsymbol{\\theta}})+\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\] onde \\(\\boldsymbol{\\theta}\\) é a matriz hessiana (de derivadas segunda) aplicada em \\(\\hat{\\boldsymbol{\\theta}}\\). Deste modo, teremos que \\[\\pi(\\boldsymbol{\\theta}|\\boldsymbol{x})\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\left[-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\right](\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\right\\}\\pi(\\boldsymbol{\\theta})\\]\nUtilizando a priori imprópria \\(\\pi(\\boldsymbol{\\theta})\\), temos que \\(\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx \\hbox{Normal}(\\hat{\\boldsymbol{\\theta}},-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})^{-1})\\).\nNote que as informações necessárias para a aproximação da posteriori acima podem ser obtidas via função optim.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html#aproximação-da-posteriori-pela-distribuição-normal",
    "href": "aproximacaoNormal.html#aproximação-da-posteriori-pela-distribuição-normal",
    "title": "10  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "",
    "text": "Exemplo  A amostra abaixo foi simulada do modelo Gama\\((\\alpha,\\beta)\\) (o valor dos parâmetros foram omitidos de propósito)\n\nx\n\n [1] 0.2769550 1.1902521 1.1543901 0.6836040 1.2951363 0.8468467 0.7626888\n [8] 0.3830976 0.2270072 0.2785412 0.3853067 0.4818242 0.2021683 0.8914625\n[15] 0.7718524 0.9455476 0.8702839 0.5309044 1.2858882 1.0415047\n\n\nComo \\(\\alpha,\\beta&gt;0\\), considere que \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\) (deste modo, \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^2\\)).\nA função de log-verossimilhança deste modelo é\n\nlogveross &lt;- function(theta){ sum(dgamma(x, exp(theta[1]), exp(theta[2]), log = T))\n}\n\nPodemos utilizar a função optim para obter as estimativas de máxima verossimilhança e a matriz hessiana. Contudo, primeiro devemos observar que esta função é um minimizador, logo, queremos que \\(\\boldsymbol{\\theta}\\) que minimize \\(-\\ell({\\boldsymbol{\\theta}})\\).\n\nopt &lt;- optim( c(0,0), function(q) -logveross(q), hessian = T)\nopt\n\n$par\n[1] 1.245897 1.567152\n\n$value\n[1] 7.435047\n\n$counts\nfunction gradient \n      65       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]      [,2]\n[1,]  80.46195 -69.52104\n[2,] -69.52104  69.52342\n\n\nNo objeto opt, a lista par é o vetor com as estimativas de máxima verossimilhança, enquanto que hessian é o valor de \\(-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\).\nA inversa de opt$hessian vai dar a matriz de covariância entre \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori.\n\nSigma &lt;- solve(opt$hessian)\nSigma\n\n           [,1]       [,2]\n[1,] 0.09138023 0.09137711\n[2,] 0.09137711 0.10575762\n\n\nAgora, podemos simular \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori:\n\nrequire(mvtnorm)\n\nCarregando pacotes exigidos: mvtnorm\n\ntheta_sim &lt;- rmvnorm(500, opt$par, Sigma)\n\nPor último, podemos fazer inferências sobre \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\):\n\n# intervalos de credibilidade para alfa\nquantile(exp(theta_sim[,1]), c(.025,.975))\n\n    2.5%    97.5% \n1.978850 6.350455 \n\n# intervalos de credibilidade para beta\nquantile(exp(theta_sim[,2]), c(.025,.975))\n\n    2.5%    97.5% \n2.582863 8.865732",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html#metropolis-revisitado",
    "href": "aproximacaoNormal.html#metropolis-revisitado",
    "title": "10  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "10.2 Metropolis revisitado",
    "text": "10.2 Metropolis revisitado\nA diferença entre o algoritmo Metropolis e o Metropolis-Hastings está na escolha da distribuição proposta. No primeiro, a proposta é simétrica, \\[g(x|y)=g(y|x).\\] Com isso, teremos que \\[\\frac{f(x)}{f(y)}\\frac{g(y|x)}{g(x|y)}=\\frac{f(x)}{f(y)}\\] e a probabilidade de aceitação da cadeia é baseada somente na distribuição alvo \\(f\\).\nNo algoritmo Metropolis, é comum escolher a distribuição proposta como sendo uma normal. Uma escolha razoável é utilizar como proposta aproximação normal vista na seção anterior.\n\nExemplo  Consideremos novamente a amostra do exemplo anterior. A função de verossimilhança é \\[L(\\theta)=\\prod_{i=1}^n \\frac{\\beta(\\theta_2)^{\\alpha(\\theta_1)}}{\\Gamma(\\alpha(\\theta_1))} x_i^{\\alpha(\\theta_1)-1}e^{-\\beta(\\theta_2)x_i}\\] onde \\(\\alpha(\\theta_1)=e^{\\theta_1}\\), \\(\\beta(\\theta_2)=e^{\\theta_2}\\). Além disso ,considere ad prioris independentes \\(\\theta_i\\sim\\hbox{Normal}(0,100)\\). Então, devemos simular do modelo\n\\[\\pi(\\theta|\\boldsymbol{x})\\propto \\left[\\frac{\\beta(\\theta_2)^{\\alpha(\\theta_1)}}{\\Gamma(\\alpha(\\theta_1))}\\right]^n \\left[\\prod_{i=1}^n x_i\\right]^{\\alpha(\\theta_1)}e^{-\\beta(\\theta_2)\\sum_{i=1}^{n}x_i}e^{-\\frac{1}{200}(\\theta_1^2 + \\theta_2^2)}\\]\nA posteriori aproximada, que encontramos no exemplo anterior é \\[\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx N \\left[ \\left(\\begin{array}{c}1,24\\\\1,56 \\end{array}\\right),\\left(\\begin{array}{cc}0,09 & 0,09\\\\0,09 &0,11\\end{array}\\right)\\right]\\]\nVamos aproveitar a estrutura de covariâncias acima para usar a proposta\n\\[\\boldsymbol{\\theta}^*|\\boldsymbol{x}\\sim N \\left[ \\boldsymbol{\\theta}^{(j-1)},\\tau\\left(\\begin{array}{cc}0,09 & 0,09\\\\0,09 &0,11\\end{array}\\right)\\right]\\] onde \\(\\boldsymbol{\\theta}^*\\) é o candidato gerado e \\(\\boldsymbol{\\theta}^{(j)}\\) é o estado atual da cadeia e \\(\\tau\\) é o tunning da cadeia.\n\nB &lt;- 10000 # número de iterações\ntheta &lt;- array(NA_real_, c(B,2))\n\ntheta[1,] &lt;- opt$par # valor inicial da cadeia é a emv\ntau &lt;- 1             # tunning\ncont &lt;- 0            # contador de aceites\n\nfor(j in 2:B){\n  #simule um candidato\n  theta_cand &lt;- rmvnorm(1, theta[j-1,], tau*Sigma)\n  \n  # calcule a probabilidade do salto\n  lnum &lt;- logveross(theta_cand) +\n    sum(dnorm(theta_cand[1,],0,10, log = T))\n  \n  lden &lt;- logveross(theta[j-1,]) +\n    sum(dnorm(theta[j-1,],0,10, log = T))\n  \n  prob &lt;- exp( lnum - lden)\n  \n  # verifique o salto\n  u &lt;- runif(1)\n  if( u &lt; prob){\n    theta[j, ] &lt;- theta_cand\n    cont &lt;- cont+1\n  } else {\n    theta[j,] &lt;- theta[j-1,]\n  }\n}\n\ncont/B\n\n[1] 0.5628\n\ntheta_sim &lt;- theta[ seq(B/2, B, 15),]\nacf(theta_sim)\n\n\n\n\n\n\n\n\nPor fim, as estimativas intervalares para \\((\\alpha,\\beta)\\) são\n\nquantile(exp(theta_sim[,1]), c(.025,.975))\n\n    2.5%    97.5% \n1.699256 5.644593 \n\n# intervalos de credibilidade para beta\nquantile(exp(theta_sim[,2]), c(.025,.975))\n\n    2.5%    97.5% \n2.087772 7.675778",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "misturas.html",
    "href": "misturas.html",
    "title": "11  Misturas de distribuições",
    "section": "",
    "text": "11.1 Modelos com inflação de zeros\nQuando são observados mais zeros do que o esperado pelo modelo de contagem assumido para a verossimilhança, é usual considerar um modelo com inflação de zeros. Nesse tipo de modelo, assumimos que existe uma variável \\(Z|p\\sim\\hbox{Bernoulli}(\\rho)\\) tal que:\n\\[X=\\left\\{\\begin{array}{ll}0, & \\hbox{se }Z=1\\ \\\\ Y,&\\hbox{se }Z=0\\end{array}\\right.\\] onde \\(Y\\sim h(.|\\theta)\\) é o modelo de contagem. Apenas \\(X\\) é observado e, como\n\\[\\begin{align}P(X=0|\\theta,p)&=P(X=0|Z=0,\\theta)P(Z=0|\\rho)+P(X=0|Z=1,\\theta)P(Z=1|\\rho)\\\\&=(1-\\rho)h(0|\\theta)+\\rho\\end{align}\\] a probabilidade de observar um zero está entre \\(h(0|\\theta)\\) e 1, o que caracteriza a inflação.\nAgora, considere um modelo inflacionado de zeros aumentado:\n\\[f(x,z|\\theta,\\rho)=f(x|z,\\theta)f(z|\\rho)=f(x|z,\\theta)\\rho^z(1-\\rho)^{1-z}.\\] Note que\n\\[f(x|z,\\theta)=\\left\\{\n\\begin{array}{ll}\nh(x|\\theta),&\\hbox{ se }z=0,\\\\\nI(x=0),&\\hbox{ se }z=1\\\\\n\\end{array}\\right.\\] logo, a distribuição conjunta \\(f(x,z|\\theta,\\rho)\\) é dada por\n\\[\\begin{array}{c|cc}\\hline & x=0 & \\hbox{qualquer }x&gt; 0 \\\\ \\hline\nz=0 & h(0|\\theta)(1-\\rho) & h(x|\\theta)(1-\\rho) \\\\\nz=1 & \\rho & 0 \\\\ \\hline\n\\end{array}\n\\] Então,\n\\[\\begin{align}\n\\prod_{i=1}^n f(x_i,z_i|\\theta,\\rho)&=\\prod_{i=1}^n [h(0|\\theta)(1-\\rho)]^{I(x_i=0,z_i=0)}[h(x_i|\\theta)(1-\\rho)]^{I(x_i&gt;0,z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\\\\n&=\\prod_{i=1}^n [h(x_i|\\theta)(1-\\rho)]^{I(z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\\\\n&=\\prod_{i=1}^n(1-\\rho)^{I(z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\prod_{i=1}^n [h(x_i|\\theta)]^{I(z_i=0)}\\end{align}\\] e, notando que \\(I(z_i=0)=1-z_i,\\)\n\\[\\begin{align}\n\\prod_{i=1}^n f(x_i,z_i|\\theta,\\rho)&=\n(1-\\rho)^{n-\\sum_{i=1}^n z_i}\\rho^{\\sum_{i=1}^n z_iI(x_i=0)}\\prod_{i=1}^n [h(x_i|\\theta)]^{1-z_i}\\end{align}\\]\nConsidere, a priori, que \\(\\theta\\) e \\(\\rho\\) são independentes. Seja \\(\\pi(\\theta)\\) a priori para \\(\\theta\\) e considere que \\(\\rho\\sim\\hbox{Beta}(a,b)\\). Então, as condicionais completas para \\(\\theta\\) e \\(\\rho\\) são\n\\[\\begin{align}\n\\pi(\\theta|\\rho,\\boldsymbol{z},\\boldsymbol{x})&\\propto \\prod_{i=1}^n h(x_i|\\theta)^{1-z_i}\\pi(\\theta),\\\\\n\\pi(\\rho|\\theta,\\boldsymbol{z},\\boldsymbol{x})&\\propto \\rho^{\\sum_{i=1}^n z_iI(x_i=0)+a-1}(1-\\rho)^{n-\\sum_{i=1}^n z_i+b-1},\\\\\n\\end{align}\\]\nPara a condicional completa de \\(z_i\\), notemos que \\[P(Z_i=1|x_i&gt;0)=\\frac{P(Z_i=1,X_i&gt;0)}{P(X_i&gt;0)}=0,\\] e que\n\\[P(Z_i=z|x_i=0)= \\left\\{\\begin{array}{ll}\\frac{P(Z_i=0,X_i=0)}{P(X_i=0)}=\\frac{h(0|\\theta)(1-\\rho)}{\\rho+(1-\\rho)h(0|\\theta)},&,z=0\\\\\n\\frac{P(Z_i=1,X_i=0)}{P(X_i=0)}=\\frac{\\rho}{\\rho+(1-\\rho)h(0|\\theta)},&z=1\\end{array}\\right.,\\] logo \\[\\pi(z_i|\\theta,\\rho,\\boldsymbol{x},\\boldsymbol{z}_{(-i)})=\\left\\{\\begin{array}{ll}\\hbox{Bernoulli}\\left( \\frac{\\rho}{\\rho+(1-\\rho)h(0|\\theta)}\\right),&\\hbox{ se }x_i=0\\\\\nI(z_i=0),&\\hbox{ se } x_i&gt;0\\\\ \\end{array}\\right.\\]\nPortanto, um amostrador de Gibbs para um modelo inflacionado de zeros é",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#modelos-com-inflação-de-zeros",
    "href": "misturas.html#modelos-com-inflação-de-zeros",
    "title": "11  Misturas de distribuições",
    "section": "",
    "text": "Amostrador de Gibbs para o modelo inflado de zeros\nFaça \\(j=0\\) e dê os valores iniciais \\(\\theta^{(0)}\\) e \\(\\rho^{(0)}\\).\nNo \\(j\\)-ésimo passo:\n\nPara \\(i\\in\\{1,\\ldots,n\\}\\), se \\(x_i&gt;0\\) faça \\(z_i=0\\). Senão, simule \\[z_i^{(j)}\\sim \\hbox{Bernoulli}\\left(\\frac{\\rho^{(j-1)}}{\\rho^{(j-1)}+(1-\\rho^{(j-1)})h(x_i|\\theta^{(j-1)})}\\right)\\]\nSimule \\(\\rho^{(j)}\\sim\\hbox{Beta}(a+\\sum_{i=1}^n z_i^{(j)}I(x_i=0),b+n-\\sum_{i=1}^n z_i^{(j)})\\)\nSimule \\(\\theta^{(j)}\\) de \\[\\pi(\\theta|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x})\\propto \\prod_{i=1}^n h(x_i|\\theta^{(j)})^{1-z_i^{(j)}}\\pi(\\theta^{(j)}).\\]\n\n\n\nExemplo - A Poisson inflada de zeros \nNeste exemplo, vamos considerar que a distribuição da contagem é Poisson(\\(\\theta\\)) e que \\(\\theta\\sim\\hbox{Gama}(r,s)\\). Então,\n\\[\\begin{align}\n\\pi(\\theta|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x})&\\propto \\prod_{i=1}^{n} h(x_{i} | \\theta )^{ 1-z_{i}^{(j)} }\\pi(\\theta)=\n\\prod_{i=1}^{n} \\left[\\frac{ e^{-\\theta}\\theta^{x_i} }{x_i!}\\right]^{1-z_{i}^{(j)}}\\frac{s^r}{\\Gamma(r)}\\theta^{r-1} e^{-s\\theta}\\\\&\\propto \\theta^{\\sum_{i=1}^n x_i(1-z_i^{(j)})+r-1}e^{-(n-\\sum_{i=1}^n z_i^{(j)}+s)\\theta}\n\\end{align},\\]\nou seja, \\(\\theta^{(j)}|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x}\\sim\\hbox{Gama}(\\sum_{i=1}^n x_i(1-z_i^{(j)})+r,n-\\sum_{i=1}^n z_i^{(j)}+s)\\)\n\n\nOs dados abaixo representam o número anual de furacões atlânticos grandes (categoria 4 ou 5) entre 1987 e 2012, nos Estados Unidos.\n\nfur &lt;-  c(0, 0 ,1,\n0, 0, 1, 0, 0, 1, 0, 0, 2, 2,\n0, 0, 1, 1, 3, 4, 0, 0, 2, 0,\n0, 0, 0)\n\nA frequência relativa de zeros é 0,58. Considerando o modelo Poisson\\((\\theta)\\) com \\(\\pi(\\theta)\\propto \\theta^{-1}\\), temos que\n\nr1 &lt;- sum(fur)\ns1 &lt;- length(fur)\nplot(table(fur)/s1, type= 'p', xlab='No. anual de mortes pod fur', ylab = 'Probabilidade', col = 'cyan3', pch=16)\nlines(0:4,table(fur)/s1, col = 'cyan3')\npoints(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), pch=16, col = 'brown')\nlines(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), col = 'brown')\n\nlegend('bottomleft',c('Freq. relativa','Pred. post. Poisson'), fill=c('cyan3','brown'), bty='n')\n\n\n\n\n\n\n\n\n\n# hiperparâmetros para rho\na = b = 1\n\n# hiperparâmetros para theta\nr=.1\ns=.1\n\n# tamanho da amostra\nn &lt;- length(fur) \n\n# valores iniciais da cadeia\ntheta &lt;- mean(fur)\nrho &lt;- mean(fur == 0)\n\n# amostrador de Gibbs\nB &lt;- 50000\nfor(i in 1:B){\n  # simulando z\n  z &lt;- NULL\n  prob &lt;- rho[i]/ ( (1-rho[i])*dpois(0,theta[i]) + rho[i])\n  for(j in 1:n){\n    if(fur[j] &gt;0){ z[j] &lt;- 0} else{\n      z[j] &lt;- rbinom(1,1,prob)\n    }\n  }\n\n  # simulando rho\n  rho[i+1] &lt;- rbeta( 1, a + sum( z * (fur == 0)) , n- sum(z)+ b )\n  \n  # simulando theta\n  theta[i+1] &lt;- rgamma(1, sum( fur*(1-z) ) + r,  n - sum(z) + s)\n}\n\nVamos descartar a metade das simulações e usar um thinning igual a 15:\n\ntheta_sim &lt;- theta[seq(B/2,B,15)]\nrho_sim &lt;- rho[seq(B/2,B,15)]\n\noo &lt;- par(mfrow=c(2,2))\nts.plot(theta_sim, lwd = 2)\nts.plot(rho_sim, lwd = 2)\nacf(theta_sim)\nacf(rho_sim)\n\n\n\n\n\n\n\n\nVamos estimar as probabilidade de ocorrerem \\(k\\) mortes via preditiva posteriori:\n\n# tamanho do vetor simulado\nBs &lt;- length(theta_sim)\n\nx_til &lt;- array( NA_real_, c(Bs,n))\nfor(j in 1:Bs){\n  z &lt;- rbinom( n, 1, rho_sim[j])\n  x_til[j,] &lt;- (1-z)*rpois(n, theta_sim[j])\n}\n\n# probabilidades estimadas via ZIP\np_zip &lt;- prop.table(table(x_til))\n\np_zip\n\nx_til\n           0            1            2            3            4            5 \n6.073093e-01 2.012828e-01 1.165382e-01 5.011305e-02 1.746574e-02 5.421993e-03 \n           6            7            8            9 \n1.453555e-03 3.230123e-04 6.921693e-05 2.307231e-05 \n\n\nAbaixo mostramos as probabilidades preditas do modelo ZIP, do modelo Poisson a e frequência relativa.\n\nr1 &lt;- sum(fur)\ns1 &lt;- length(fur)\nplot(table(fur)/s1, type= 'p', xlab='No. anual de mortes pod fur', ylab = 'Probabilidade', col = 'cyan3', pch=16)\nlines(0:4,table(fur)/s1, col = 'cyan3')\npoints(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), pch=16, col = 'brown')\nlines(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), col = 'brown')\npoints(names(p_zip),p_zip, pch=16,col = 'magenta')\nlines(names(p_zip),p_zip,col = 'magenta')\n\nlegend('bottomleft',c('Freq. relativa','Pred. post. Poisson', 'Pred. post. ZIP'), fill=c('cyan3','brown', 'magenta'), bty='n')\n\n\n\n\n\n\n\n\n\n\n11.1.1 Exercício\n\nAbaixo, segue o número anual de tornados em Lafayette Parish, Louisiana, entre 1950 e 2012.\n\ntor &lt;- c(0, 0,0, 1, 0, 0, 0, 1, 0, 0,\n1, 0, 0, 0, 1, 1, 0, 0, 0, 2,\n0, 0, 0, 0, 1, 3, 0, 2, 1, 0,\n1, 0, 0, 1, 0, 1, 0, 0, 2, 1,\n0, 1, 2, 0, 0, 1, 0, 1, 2, 0,\n0, 0, 3, 0, 2, 0, 1, 1, 3, 0,\n1, 1, 1)\n\n\nAjuste o modelo Poisson.\nAjuste o modelo Poisson inflado de zeros.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#mistura-escalonada-de-normais",
    "href": "misturas.html#mistura-escalonada-de-normais",
    "title": "11  Misturas de distribuições",
    "section": "11.2 Mistura escalonada de normais",
    "text": "11.2 Mistura escalonada de normais",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#misturas-finitas-com-número",
    "href": "misturas.html#misturas-finitas-com-número",
    "title": "11  Misturas de distribuições",
    "section": "11.3 Misturas finitas com número",
    "text": "11.3 Misturas finitas com número\nDizemos que \\(X|\\boldsymbol{\\theta},\\boldsymbol{p},\\kappa\\) é um modelo de mistura finito se sua função de densidade/probabilidade é dada por\n\\[f(x| \\boldsymbol{\\theta},\\boldsymbol{p} ,\\kappa )=\\sum_{k=1}^\\kappa p_k f_k(x|\\boldsymbol{\\theta}_k).\\]\nCada função \\(f(.|\\boldsymbol{\\theta}_k)\\) é denominada componente da mistura e o número de componentes pode ser desconhecido.\nAssim como o modelo com zeros inflacionados, podemos utilizar uma variável latente \\(\\textbf{z}_i|\\kappa=(z_{i,1},\\ldots,z_{i,\\kappa})\\sim\\hbox{Multinomial}(p_1\\ldots,p_\\kappa|\\sum_{k=1}^\\kappa z_{ik}=1)\\), obtendo o seguinte modelo aumentado\n\\[f(x_i|\\boldsymbol{\\theta},\\textbf{z}_i,\\kappa)=\\prod_{k=1}^\\kappa \\left[f\\left(x_i|\\boldsymbol{\\theta}_k\\right)\\right]^{z_{i,k}}\\]\nA função de verossimilhança aumentada para este modelo é\n\\[\\prod_{i=1}^n f(x_i|\\boldsymbol{\\theta},\\textbf{z}_i,\\kappa)=\\prod_{i=1}^n\\prod_{k=1}^\\kappa \\left[f\\left(x_i|\\boldsymbol{\\theta}_k\\right)\\right]^{z_{i,k}}.\\]\nConsidere as prioris \\(\\pi(\\boldsymbol{\\theta}|\\kappa)=\\prod_{k=1}^\\kappa \\pi(\\boldsymbol{\\theta}_k)\\) e \\(\\textbf{p}|\\kappa\\sim\\hbox{Dirichlet}(a_1,\\ldots,a_\\kappa)\\), onde \\[f(\\textbf{p}|\\kappa)\\propto \\prod_{k=1}^\\kappa p_k^{a_k-1}\\] com \\(\\sum_{k=1}^\\kappa p_k=1\\). As condicionais completas para este problema são\n\n\\(\\begin{align}f(\\boldsymbol{\\theta}_k|resto)\\propto \\prod_{i:z_{i,k}=1}f(x_i|\\boldsymbol{\\theta}_k)\\pi(\\boldsymbol{\\theta}_k)\\end{align}\\)\n\\(\\begin{align}f(\\textbf{z}_i|resto)\\propto \\prod_{k=1}^\\kappa \\left[p_kf(x_i|\\boldsymbol{\\theta}_k)\\right]^{z_{i,k}}\\end{align}\\) ou seja, \\(\\textbf{z}_i|rest\\sim\\hbox{Multinomial}(\\tilde{p}_1,\\ldots,\\tilde{p}_\\kappa)\\), onde\n\n\\[\\tilde{p}_k=\\frac{p_kf(x_i|\\boldsymbol{\\theta}_k)}{\\sum_{k=1}^\\kappa p_kf(x_i|\\boldsymbol{\\theta}_k)}\\] * \\(f(\\textbf{p}|resto)\\propto \\prod_{k=1}^\\kappa p_k^{\\sum_{i=1}^n z_{i,k}+a_k-1}\\), ou seja \\(\\textbf{p}|resto\\sim\\hbox{Dirichlet}(a_1+\\sum_{i=1}^n z_{i,1},\\ldots,a_\\kappa+\\sum_{i=1}^n z_{i,\\kappa})\\)\nSe necessário, podemos atrbuir a priori \\[\\pi(\\kappa)=\\frac{1}{M},\\kappa=1,2,\\ldots,M\\] para obter a condicional completa \\[\\pi(\\kappa|resto)=\\frac{\\prod_{i=1}^n\\prod_{k=1}^\\kappa f(x_i|\\boldsymbol{\\theta}_k)^{z_{i,k}}\\pi(\\boldsymbol{\\theta}_k)\\pi(\\textbf{p}|\\kappa)\\pi(\\textbf{z}_i|\\kappa)}{\\sum_{\\kappa=1}^M \\prod_{i=1}^n\\prod_{k=1}^\\kappa f(x_i|\\boldsymbol{\\theta}_k)^{z_{i,k}}\\pi(\\boldsymbol{\\theta}_k)\\pi(\\textbf{p}|\\kappa)\\pi(\\textbf{z}_i|\\kappa)},\\kappa=1,\\ldots,M.\\]\n\n11.3.1 O velho fiel\nO banco de dados faithful mostra a duração e o tempo até a próxima erupção do geiser Velho Fiel, no parque Yellowstone. Abaixo mostramos o diagrama do tempo de espera entre erupções\n\nhist(faithful$waiting)\n\n\n\n\n\n\n\n\nÉ possível notar classes, uma com tempo e entre erupções menor que 70 com tempo maior. Temos as seguintes estimativas iniciais:\n\n## elementos na classe 1\nx &lt;- faithful$waiting\nz &lt;- x &lt; 70\n# proporção na classe 1\nmean(z)\n\n[1] 0.3786765\n\n# média e desvio padrão na classe 1\nmean( x[z])\n\n[1] 55.15534\n\nsd( x[z])\n\n[1] 6.266558\n\n\n\n## elementos na classe 2\n# proporção na classe 2\nmean(z==F)\n\n[1] 0.6213235\n\n# média e desvio padrão na classe 2\nmean( x[z==F])\n\n[1] 80.49112\n\nsd( x[z==F])\n\n[1] 5.456667\n\n\nVamos considerar que as duas componentes possuem distribuição normal. Para cada componente, teremos as seguintes prioris:\n\\[\\pi(\\mu_i,\\phi_i)=\\frac{\\phi^{1/2}_i}{\\sqrt{2\\pi C}}e^{-\\frac{\\phi_i}{2C}(\\mu_i-m_i)^2}\\frac{b^a}{\\Gamma(a)}\\phi_i^{a-1}e^{b\\phi_i},\\]\n\\[p\\sim\\hbox{Beta}(r,s)\\]\n\\[z_i\\sim\\hbox{Bernoulli}(p)\\]\nO modelo aumentado é \\[f(x_i|\\mu,\\phi,z_{i})=\\left[\\frac{\\phi_1^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_1}{2}(x_i-\\mu_1)}\\right]^{z_i}\\left[\\frac{\\phi_2^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_2}{2}(x_i-\\mu_2)}\\right]^{1-z_i}\\] As condicionais completas são:\n\\[\\begin{align}f(\\mu_1|resto) &\\propto \\exp\\left\\{-\\frac{\\phi_1}{2}\\sum_{i=1}^n z_i(x_i-\\mu_1)^2\\right\\}\\exp\\left\\{-\\frac{\\phi_1}{2C} z_i(\\mu_1-m_1)^2\\right\\}\\\\&\\propto \\exp\\left\\{-\\frac{\\phi_1}{2}\\left(\\sum_{i=1}^n z_i+C^{-1}\\right) \\left(\\mu_1-\\frac{\\sum_{i=1}^{n}x_iz_i+m_1C^{-1}}{\\sum_{i=1}^n z_i+C^{-1}}\\right)^2\\right\\}\\end{align}\\]\n\\[\\begin{align}f(\\mu_2|resto) &\\propto \\exp\\left\\{-\\frac{\\phi_2}{2}\\sum_{i=1}^n (1-z_i)(x_i-\\mu_2)^2\\right\\}\\exp\\left\\{-\\frac{\\phi_2}{2C} (1-z_i)(\\mu_2-m_2)^2\\right\\}\\\\&\\propto \\exp\\left\\{-\\frac{\\phi_2}{2}\\left(\\sum_{i=1}^n (1-z_i)+C^{-1}\\right) \\left(\\mu_2-\\frac{\\sum_{i=1}^{n}x_i(1-z_i)+m_1C^{-1}}{\\sum_{i=1}^n (1-z_i)+C^{-1}}\\right)^2\\right\\}\\end{align}\\]\n\\[\\begin{align}f(\\phi_2|resto)&\\propto \\phi_2^{-\\frac{1}{2}\\sum_{i=1}^{n}z_i}\ne^{-\\frac{\\phi_2}{2}\\sum_{i=1}^n (1-z_i)(x_i-\\mu_2)^2}\\phi^{-1/2}_2e^{-\\frac{\\phi_2}{2}(\\mu_2-m_2)^2}\\phi_2^{a/2-1}e^{-\\phi_2 b/2}\\\\ &\\propto \\phi_2^{\\frac{1}{2}(1+a+\\sum_{i=1}^{n}(1-z_i)-1}e^{-\\frac{\\phi_2}{2}[\\sum_{i=1}^n(1-z_i)(x_i-\\mu_2)^2 +(\\mu_2-m_2)^2 + b]}\\end{align}\\] \\[\\begin{align}f(\\phi_1|resto)&\\propto \\phi^{-\\frac{1}{2}\\sum_{i=1}^{n}z_i}\ne^{-\\frac{\\phi_1}{2}\\sum_{i=1}^n z_i(x_i-\\mu_1)^2}\\phi^{-1/2}e^{-\\frac{\\phi_1}{2}(\\mu_1-m_1)^2}\\phi_1^{a/2-1}e^{-\\phi_1 b/2}\\\\ &\\propto \\phi_1^{\\frac{1}{2}(1+a+\\sum_{i=1}^{n}z_i)-1}e^{-\\frac{\\phi_1}{2}[\\sum_{i=1}^nz_i(x_i-\\mu_1)^2 +(\\mu_1-m_1)^2 + b]}\\end{align}\\]\n\\[\\begin{align}f(p|resto)\\propto \\prod_{i=1}^n p^{z_i}(1-p)^{1-z_i}p^{r-1}(1-p)^{s-1}\\propto p^{r+\\sum_{i=1}^n z_i-1}(1-p)^{s+\\sum_{i=1}^n (1-z_i)-1}\\end{align}\\]\n\\[f(z_i|resto)\\propto\\left[ p\\frac{\\phi_1^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_1}{2}(x_i-\\mu_1)^2}\\right]^{z_i}\\left[ (1-p)\\frac{\\phi_2^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_2}{2}(x_i-\\mu_2)^2}\\right]^{1-z_i}\\]\nAbaixo implementamos o amostrador de Gibbs\n\nB &lt;- 50000\n\n# hiperparmametros\nm1 &lt;- 65\nm2 &lt;- 80\nC &lt;- 1000\nr= 4; s = 6\na = 1; b = .1\n\n# valores iniciais\nz &lt;- x &lt; 70\nphi1 &lt;- 1/36\nphi2 &lt;- 1/25\nmu1 = mu2 =  p = NULL\n\nfor(i in 1:B){\n  # mu dado o resto\n  m1_post &lt;- ( sum(x*z) + m1/C) / ( sum(z) + 1/C )\n  m2_post &lt;- ( sum(x*(1-z)) + m1/C) / ( sum(1-z) + 1/C )\n  s1_post &lt;- 1 / ( ( sum(z) + 1/C )*phi1[i] )\n  s2_post &lt;- 1 / ( ( sum(1-z) + 1/C )*phi2[i] )\n  \n  mu1[i+1] &lt;- rnorm(1, m1_post, sqrt( s1_post) )\n  mu2[i+1] &lt;- rnorm(1, m2_post, sqrt( s2_post) )\n  \n  # phi dado resto\n  phi1[i+1] &lt;- rgamma(1, 1 + a + sum(z), sum( z*(x - mu1[i+1])^2 ) + (mu1[i+1]-m1)^2 + b)\n  phi2[i+1] &lt;- rgamma(1, 1 + a + sum(1-z), sum( (1-z)*(x - mu2[i+1])^2 ) + (mu2[i+1]-m2)^2 + b)\n  \n  # p dado resto\n  p[i+1] &lt;- rbeta(1, r + sum(z), s + sum(1-z) )\n  \n  # z dado resto\n  aux1 &lt;- p[i+1]*dnorm(x,mu1[i+1], 1/sqrt(phi1[i+1]))\n  aux2 &lt;- (1-p[i+1])*dnorm(x,mu2[i+1], 1/sqrt(phi2[i+1]))\n  \n  z &lt;- rbinom(length(x), 1, aux1/( aux1 + aux2))\n}\n# \n\n\nhist(mu1[seq(B/2,B,30)])\n\n\n\n\n\n\n\nhist(mu2[seq(B/2,B,30)])",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "mcmc.html",
    "href": "mcmc.html",
    "title": "13  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "",
    "text": "13.1 Cadeias de Markov\nA coleção \\({\\X(t),t\\inT\\}\\) é um processo estocástico se \\(X(t)\\) é uma variável aleatória para cada \\(t\\in T\\).\nA variável \\(X(t)\\) é denominada estado. O processo é dito ser a tempo discreto se \\(T\\subseteq \\mathbb{Z}\\).\nEm um processo a tempo discreto, é usual utilizar a notação \\(X(t)\\equiv X_t\\).\nO processo estocástico \\(X_0,X_1,X_2,\\ldots\\) é uma cadeia de Markov de ordem \\(d\\) se\n\\[P(X_n\\in A|X_{n−1}=x_{n−1},…,X_0=x_0)=P(X_n\\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d}).\\]\nUma cadeia de Markov de ordem \\(d\\) é dita ser homogênea se, para qualquer \\(m&gt;0\\) natural,\n\\[P(X_n\\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d})=P(X_{n+m}\\in A|X_{n+m−1}=x_{n−1},…,X_{n+m−d}=_{xn−d}).\\]\nEstamos interessados nas cadeias homogêneas de ordem \\(d=1\\), que doravante serão denominadas simplesmente por cadeias de Markov.\nA evolução da cadeia de \\(X_n\\) até \\(X_{n+1}\\) é denominada transição em 1 passo. A densidade \\(k(.|y)\\) que satisfaz\n\\[P(X_{n+1}\\in A|X_n=y)=\\int_A k(x|y)dx\\]\né denominada núcleo de transição (ou núcleo de transição em 1 passo. Se os estados forem variáveis discretas, \\(k(.|y)\\) será uma função de probabilidade e a discussão é análoga.\nA seguir, vamos discutir em quais situações esta distribuição exsite.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "mcmc.html#cadeias-de-markov",
    "href": "mcmc.html#cadeias-de-markov",
    "title": "13  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "",
    "text": "Uma cadeia de Markov\nConsidere a seguinte cadeia de Markov:\n\\[X_n|X_{n−1}=y∼\\hbox{Uniforme}(1−y,1).\\]\nAbaixo, simulamos duas trajetórias de tamanho 200 deste processo, cada uma com um valor diferente para \\(x_0\\).\n\nset.seed(123)\n\ncadeia1 &lt;- .1\ncadeia2 &lt;- .5\n\nfor(i in 2:200){\n  cadeia1[i] &lt;- runif(1, 1 - cadeia1 [i - 1] , 1)\n  cadeia2[i] &lt;- runif(1, 1 - cadeia2 [i - 1] , 1)\n}\n\n# gráfico das duas trajetórias\nplot(cadeia1,cadeia2, type = \"l\", col =1)\npoints(cadeia1[1] , cadeia2[1] , pch=16) # ponto inicial\n\n\n\n\n\n\n\n\nPelo gráfico acima observamos que, independente de onde a cadeia começou, as duas simulações se concentraram na mesma região do gráfico após algumas iterações. A figura abaixo apresenta a função densidade estimada via método do núcleo para as duas trajetórias simuladas, excluindo os 10 primeiros pontos, de onde pode-se inferir que as distribuições são as mesmas.\n\nplot(density(cadeia1[-(1:10)]), lwd = 2, main = \"\")\nlines(density(cadeia2[-(1:10)]), lty = 2, lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n13.1.1 A distribuição estacionária\nDizemos que \\(\\pi(.)\\) é a densidade da distribuição estacionária de uma cadeia de Markov se\n\\[\\pi(y)=\\int \\pi(x)k(y|x)dx.\\] Note que isto implica que \\(X_i∼\\pi()\\), ou seja, a distribuição marginal da cadeia é a mesma.\nPortanto, ao simular uma trajetória de uma cadeia de Markov com distribuição estacionária, os valores simulados são identicamente distribuídos segundo \\(\\pi(.)\\).\nSe o valor inicial \\(x_0\\) utilizado para gerar a amostra estiver dentro da região de alta densidade de \\(\\pi(.)\\), os próximos valores que serão gerados já são da distribuição estacionária. Caso contrário, defina \\(k^{(d)}(.|y)\\) como o núcleo de transição em \\(d\\) passos. Observe que tal núcleo sempre pode ser obtido do núcleo em 1 passos pois:\n\\[k^{(2)}(x|x_0)=\\int k(x|z)k(z|x_0)dz\\]\n\\[k^{(3)}(x|x_0)=\\int k^{(2)}(x|z)k(z|x_0)dz\\] e assim por diante. Contudo, se há distribuição estacionária, então \\[\\pi(x)=\\lim_{n\\rightarrow\\infty} k^{(n)}(x|x_0).\\] Isto implica que a cadeia eventualmente vai construir uma trajetória até a região de alta densidade de \\(\\pi(.)\\).\nAs condições para existência da distribuição estacionária são:\n\nExiste \\(n&gt;0\\) tal que \\(P(X_n\\in A|X_0=x_0)\\) para quaisquer \\(A\\) e \\(x_0\\), sendo que o número médio de passos para realizar a transição é finito.\n\\(P(X_n\\in A|X_0=x_0)\\) não é uma função periódica em \\(n\\)\n\n\nSimulando de uma distribuição estacionária\nConsidere novamente a seguinte cadeia de Markov:\n\\[X_n|X_{n−1}=y∼\\hbox{Uniforme}(1−y,1).\\]\nVamos simular uma trajetória de tamanho 500 começando em \\(x_0=.5\\)\n\nset.seed(123)\nx &lt;- .5\n\nfor(i in 2:500){\n  x[i] &lt;- runif(1, 1 - x [i - 1] , 1)\n}\n\n\nts.plot(x)\nabline(h=.5,lty=2)\n\n\n\n\n\n\n\n\nAbaixo, apresentamos o histograma da distribuição estacionária simulada pela cadeia.\n\nhist(x, freq = F, main = '')\n\n\n\n\n\n\n\n\nAgora, note que \\(\\pi(y)=2y\\) é distribuição estacionária, uma vez que\n\\[2y=\\pi(y)=\\int \\pi(u)k(y|u)du=\\int 2u\\frac{I(1−u&lt;y&lt;1)}{u}du=2∫^{1}_{1−y}du=2y\\] Vamos adicionar essa densidade no histograma obtido:\n\nhist(x, freq = F, main =\"\")\nabline(0,2, lwd = 2, col =4)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "mcmc.html#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov",
    "href": "mcmc.html#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov",
    "title": "13  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "13.2 Introdução aos métodos de Monte Carlo via Cadeias de Markov",
    "text": "13.2 Introdução aos métodos de Monte Carlo via Cadeias de Markov\nOs métodos para simular a distribuição \\(f(x)\\) gerando variáveis aleatórias utilizando uma cadeia de Markov são denominados métodos de Monte Carlo via Cadeias de Markov (MCMC).\nDiferente dos outros métodos de simulação, os MCMCs exigem alguns cuidados para garantir que estamos simulando variáveis independentes e identicamente distribuídas.\nAo longo desta aula, vamos utilizar a cadeia do exemplo abaixo.\n\nUma cadeia como exemplo\nConsidere uma cadeia de Markov com o seguinte núcleo de transição,\n\\[X_t|X_{t−1}=y\\sim N(\\alpha y,1)\\] com \\(\\alpha\\in(−1,1)\\). Este núcleo tem a seguinte representação estocástica:\n\\[X_t=\\alpha X_{t−1}+e_t,\\] onde \\(e_t\\simN(0,1)\\). Note que \\[\\begin{align}X_{t+2}&=\\alpha X_{t+1}+e_{t+1}=\\alpha(\\alpha X_t+e_t)+e_{t+1}\\\\&=\\alpha^2X_t+\\alpha e_{t+1}+e_t\\end{align}\\] ou seja \\[X_{t+2}|X_t=y\\sim N(\\alpha^2y,\\alpha^2+\\alpha)\\]. É fácil induzir que \\[X_{t+n}|X_t∼N\\left(\\alpha^n y,\\sum_{j=0}^n \\alpha^j\\right).\\]\nLogo \\[\\pi(x)=\\lim_{n\\rightarrow \\infty} k^{(n)}(x|y)=\\phi\\left(x|0,\\frac{1}{1-\\alpha}\\right),\\] onde \\(\\phi(x|\\mu,\\sigma^2)\\) é a funçãon densidade da normal. Para os nossos exemplo, utilizaremos \\(\\alpha=0,7\\).\n\nO objetivo dos métodos do tipo MCMC é desenvolver uma cadeia de Markov, com certo núcleo de transição \\(k(x_i|x_{i−1})\\), que tenha como distribuição estacionária a distribuição de interesse, doravante denotada por \\(f(x)\\).\nEm um mundo ideal, a simulação da cadeia deveria começar em um ponto \\(x_0\\) com alta probabilidade sob a distribuição estacionária. Como isto em geral não é possível, só podemos garantir que existe uma iteração \\(n\\) tal que a partir dela os valores simulados são da distribuição estacionária. Para nos auxiliar na escolha deste valor \\(n\\) podemos utilizar um traceplot\n\nTraceplot O gráfico com linhas unindo os pontos \\((i,x_i)\\) é denominado traceplot. Um de seus objetivos é auxiliar a detectar em qual momento a cadeia começou a amostrar pontos de f(.) (ou equivalentemente, em que momento a cadeia entrou em equilíbrio).\n\nO traceplot de um processo estacionário com variância finita tem um comportamento típico de pontos em torno da média da distribuição estacionária. Deste modo, ele é uma ferramenta exploratória que nos auxilia a detectar se a cadeia não está em equilíbrio ao perceber um padrão fora do que se esperaria de uma distribuição estacionária.\n\nExplicando o traceplot\nAbaixo, ilustramos o traceplot de duas cadeias simuladas, sendo que a única diferença entre elas é o valor de \\(x_0\\)\nA distribuição estacionária está representada ao longo do eixo das ordenadas com as linhas tracejadas em azul representando os quantis 99,5% e 0,05%. Mostramos dois traceplots (linhas pretas) com valores distintos de x0\nNo primeiro, escolhemos \\(x_0=0\\) que é a moda da distribuição estacionária e na segunda \\(x0=−10\\), um valor extremo.\n\nset.seed(123)\n\ncadeia1 = 0\ncadeia2 = -10\n\nfor(n in 1:50){\n  cadeia1[n+1] = .7*cadeia1[n]+rnorm(1)\n  cadeia2[n+1] = .7*cadeia2[n]+rnorm(1)\n}\n\nts.plot(cadeia1, ylim=c(-10,10))\nabline(h = qnorm(.995,0,sqrt(1/.3)), lty = 2)\nabline(h = qnorm(.005,0,sqrt(1/.3)), lty = 2)\n\n\n\n\n\n\n\nts.plot(cadeia2, ylim=c(-10,10))\nabline(h = qnorm(.995,0,sqrt(1/.3)), lty = 2)\nabline(h = qnorm(.005,0,sqrt(1/.3)), lty = 2)\n\n\n\n\n\n\n\n\nCom \\(x_0=0\\), o traceplot não dá evidências contra a hipótese de equilíbrio, pois os pontos simulados condizem com o que é esperado para a distribuição estacionária. Já com \\(x_0=−10\\), temos que o traceplot dá evidências de que a convergência ocorreu após 3 ou 4 iterações.\nPodemos utilizar os dois conjuntos simulados, desde que as 4 primeiras simulações da segunda cadeia sejam descartadas. Tal descarte é denominado burn-in.\nLembremos que nosso objetivo é simular variáveis independentes e identicamente distribuídas de uma distribuição alvo. Já o objetivo de um método MCMC é gerar variáveis dependentes e identicamente distribuídas segundo a distribuição alvo.\nConsiderando as variáveis simuladas (após o burn-in) \\(x_1,x_2,\\ldots,x_n\\), a dependência (linear) das variáveis obtidas via MCMC é estimada pela função de autocorrelação.\n\\[r(h)=\\sum_{i=1}^{n−h}\\frac{(x_i−\\bar{x})(x_{i+h}−\\bar{x})}{\\sum_{i=1}^n (x_i−\\bar{x})^2}.\\]\nPara termos uma amostra de variáveis aproximadamente independentes, podemos remover o efeito da autocorrelação encontrando o valor \\(h′\\) tal que \\(r(h′)≈0\\) e ficar somente com as variáveis \\(x1,x1+h′,x1+2h′,\\ldots\\). O traceplot desta subamostra deve apresentar os pontos em torno da média mas sem um padrão.\n\nVoltemos ao Exemplo 9.2, com \\(x_0=0\\). Vamos simular uma trajetória desta cadeia de tamanho \\(n=400\\) (lembre-se que neste caso o burn-in não é necessário).\n\nset.seed(123)\nn &lt;- 400\nx &lt;- 0 \nfor(i in 2:n) x[i] &lt;- .7*x[i-1] + rnorm(1)\n\n# autocorrelações (valores e gráfico)\n(acf(x))\n\n\n\n\n\n\n\n\n\nAutocorrelations of series 'x', by lag\n\n     0      1      2      3      4      5      6      7      8      9     10 \n 1.000  0.627  0.375  0.225  0.101  0.039 -0.011  0.017  0.022  0.001 -0.027 \n    11     12     13     14     15     16     17     18     19     20     21 \n-0.057 -0.088 -0.062 -0.050 -0.046 -0.106 -0.097 -0.085 -0.058 -0.023  0.008 \n    22     23     24     25     26 \n 0.049  0.006 -0.031 -0.037 -0.054 \n\n# note o efeito indesejado da dependência, ao fazer o gráfico de dispersão entre (x_i, x_{i+1})\nplot(x[-1],x[-n])\n\n\n\n\n\n\n\n\nNote que a autocorrelação estimada em h=5 é \\(r(5)=0,039\\). Podemos então retirar a subamostra \\(x1,x6,x11,...\\) para representar a nossa amostra de variáveis independentes e identicamente distribuídas. Abaixos, mostramos que o efeito indesejado da dependência desaparece.\n\ni &lt;- seq(1, n, 5)\n\n# subamostra das variáveis iid\nx_h &lt;- x[i]\n\n# autocorrelação da subamostra\nacf(x_h)\n\n\n\n\n\n\n\n# o efeito da dependência some. Veja, por exemplo\nn_h &lt;- length( x_h )\nplot( x_h[ -1 ], x_h[ -n_h ] )",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Polack, Fernando P, Stephen J Thomas, Nicholas Kitchin, Judith Absalon,\nAlejandra Gurtman, Stephen Lockhart, John L Perez, et al. 2020.\n“Safety and Efficacy of the BNT162b2 mRNA Covid-19\nVaccine.” New England Journal of Medicine 383 (27):\n2603–15.",
    "crumbs": [
      "References"
    ]
  }
]