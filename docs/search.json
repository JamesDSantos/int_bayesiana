[
  {
    "objectID": "misturas.html",
    "href": "misturas.html",
    "title": "16  Misturas de distribuições",
    "section": "",
    "text": "16.1 O modelo t-Student como uma mistura normal-gama\nA função densidade do modelo t-Student é dada por \\[f(x|\\mu,\\phi,\\nu)=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})}\\sqrt{\\frac{\\phi}{\\pi\\nu}}\\left[1+\\frac{\\phi}{\\nu}\\left(x-\\mu\\right)^2\\right]^{-\\frac{\\nu+1}{2}},\\] onde \\(x,\\mu\\in\\mathbb{R}\\) e \\(\\phi,\\nu&gt;0\\). Se \\(\\nu&gt;1\\), então \\(E(X)=\\mu\\) e se \\(\\nu&gt;2\\), \\(Var(X)=\\nu/(\\phi(\\nu-2))\\).\nConsidere que \\(X|Z,\\mu,\\phi\\sim\\hbox{Normal}(\\mu,(z\\phi)^{-1})\\) e \\(Z\\sim\\hbox{Gama}(\\nu/2,\\nu/2)\\). Então\n\\[\\begin{align}\nf(x|\\mu,\\phi,\\nu)&=\\int_0^\\infty f(x|z,\\mu,\\phi)f(z|\\nu)dz=\\int_0^\\infty \\sqrt{\\frac{\\phi z}{2\\pi}}e^{-\\frac{z\\phi}{2}(x-\\mu)^2}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}z^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}z}dz\\\\\n&=\\sqrt{\\frac{\\phi}{2\\pi}}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}\\int_0^\\infty z^{\\frac{\\nu+1}{2}-1} \\exp\\left\\{-z\\frac{\\nu}{2}\\left[1+\\frac{\\phi}{\\nu}(x-\\mu)^2\\right]\\right\\}dz\\\\\n&=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})}\\sqrt{\\frac{\\phi}{\\pi\\nu}}\\left[1+\\frac{\\phi}{\\nu}\\left(x-\\mu\\right)^2\\right]^{-\\frac{\\nu+1}{2}}.\n\\end{align}\\]\nPortanto, a distribuição normal-gama é uma mistura para a \\(t\\)-Student e a verossimilhança aumentada para este modelo é\n\\[\\begin{align}L(\\mu,\\phi,\\nu)&=\\prod_{i=1}^n f(x_i|z_i,\\mu,\\phi)f(z|\\nu)= \\prod_{i=1}^n \\sqrt{\\frac{\\phi z_i}{2\\pi}}e^{-\\frac{z_i\\phi}{2}(x_i-\\mu)^2}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}z_i^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}z_i}\\\\\n\\end{align}\\]\nConsiderando que \\(\\mu|\\phi \\sim\\hbox{Normal}(m,(\\lambda\\phi)^{-1})\\), \\(\\phi\\sim\\hbox{Gama}(n_0/2,s_0/2)\\) temos a seguinte posteriori baseada no modelo aumentado:\n\\[f(\\mu,\\phi,\\nu|\\boldsymbol{x})\\propto \\left[\\prod_{i=1}^n \\sqrt{\\frac{\\phi z_i}{2\\pi}}e^{-\\frac{z_i\\phi}{2}(x_i-\\mu)^2}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}z_i^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}z_i}\\right]\\times \\phi^{1/2}e^{-\\frac{\\lambda}{2} \\phi(\\mu-m)^2}\\times\\phi^{\\frac{n_0}{2}-1}e^{-\\frac{s_0}{2}\\phi}\\times f(\\nu)\\] Pode-se mostrar que\n\\[\\begin{align}\\mu|\\hbox{resto}&\\sim\\hbox{Normal}\\left(\\frac{\\sum_{i=1}^n z_i x_i+\\lambda m}{\\lambda+\\sum_{i=1}^n z_i},\\left[\\phi\\left(\\lambda+\\sum_{i=1}^{n}z_i\\right)\\right]^{-1}\\right)\\\\\n\\phi|\\hbox{resto}&\\sim\\hbox{Gama}\\left(\\frac{n+n_0+1}{2},\\frac{1}{2}\\left[s_0+\\lambda(\\mu-m)^2+\\sum_{i=1}^n z_i(x_i-\\mu)^2\\right]\\right)\\\\\nz_i|\\hbox{resto}&\\sim\\hbox{Gama}\\left(\\frac{\\nu+1}{2},\\frac{\\phi(x_i-\\mu)^2+\\nu}{2}\\right)\\end{align}\\]\nA condicional completa para \\(\\nu\\) é dada por \\[f(\\nu|\\hbox{resto})\\propto \\frac{(\\nu/2)^{n\\nu/2}}{\\Gamma(\\nu/2)^n}\\left(\\prod_{i=1}^n z_i\\right)^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}\\sum_{i=1}^nz_i}f(\\nu)\\]\nObserve que a condicional completa para \\(\\nu\\) não possui um núcleo conhecido. Para facilitar a simulação, podemos considerar que o espaço paramétrico de \\(\\nu\\) é uma coleção com \\(M&lt;\\infty\\) pontos. Então, teremos que \\[f(\\nu_0|\\hbox{resto})\\approx P(\\nu=\\nu_0|\\hbox{resto})\\propto \\frac{(\\nu_0/2)^{n\\nu_0/2}}{\\Gamma(\\nu_0/2)^n}\\left(\\prod_{i=1}^n z_i\\right)^{\\frac{\\nu_0}{2}-1}e^{-\\frac{\\nu}{2}\\sum_{i=1}^nz_i}f(\\nu_0)\\] e podemos utilizar o simulador sample do R. Estudos sugerem que a priori escolhida deve favorecer valores baixos para \\(\\nu\\). Vamos utilizar a priori \\(\\nu\\sim\\hbox{Exponencial}(r_0)\\)",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#o-modelo-t-student-como-uma-mistura-normal-gama",
    "href": "misturas.html#o-modelo-t-student-como-uma-mistura-normal-gama",
    "title": "16  Misturas de distribuições",
    "section": "",
    "text": "Volatilidade no mercado financeiro\nConsidere que você tem uma empresa e deseja atrair investimento. Um modo bastante tradicional é encontrar um sócio para injetar dinheiro. Por sua vez, o sócio passa a ser dono de parte da empresa. Essa é a ideia por trás das ações. Parte da empresa é fatiada em partes denominadas ações, que são negociadas na bolsa de valores. Qualquer indivíduo com uma ação é dono de uma fração da empresa. Se a empresa cresce, seu valor cresce e aquela fração correspondente à ação passa a valer mais. Se a empresa entre em crise, ação passa a valer menos.\nContudo, o preço não está baseado apenas no quanto a empresa vale no momento, mas como os milhares de donos estão se sentindo no momento com relação à ela. Caso os acionistas acreditem que a empresa vai perder valor, eles podem começar a vender suas ações. Com o aumento oferta, o preço cai. Se por outro lado o mercado acredita que a empresa vai aumentar seu lucro, os pedidos por compra no mercado aumentam e os donos das ações evitam negociá-las, criando uma demanada maior que a oferta e aumentando o preço do ativo.\nPortanto, o preço das ações está associado às oscilações de humor do mercado. Neste sentido, a variabilidade do preço é uma medida fundamental e é denominada volatilidade.\nExistem várias maneiras de medir a volatilidade. Para o nosso exemplo, seja \\(p_t\\) o preço de fechamento da ação no dia \\(t\\). Calculamos o log retorno da ação no dia \\(t\\) como\n\\[x_t=\\log(p_t)-\\log(p_{t-1}).\\] O cálculo do log-retorno é útil para remover a tendência do preço. Isso ocorre porque a tendência de \\(\\log(p_t)\\) tende a ser localmente linear. Desse modo, é esperado que \\(E(x_t)\\) esteja próximo de zero. É importante saber que, embora \\(x_1,\\ldots,x_n\\) sejam não correlacionados, em geral eles são dependentes e não são identicamente distribuídos. Contudo, mesmo que \\(x_1,\\ldots,x_n\\) sejam dependentes e não identicamente distribuídos, o modelo t-Student costuma apresentar um bom ajuste, especialmente devido à sua capacidade de capturar caudas pesadas.\nPara o mercado financeiro, o desvio padrão do log retorno é denominado volatidade (ou volatilidade total), ou seja,\n\\[\\hbox{volatidade}=\\sigma\\sqrt{\\frac{\\nu}{\\nu-2}}\\] O parâmetro \\(\\sigma=1/\\sqrt{\\phi}\\) da distribuição \\(t\\)-Student é interpretado como volatilidade basal ou o fator de escala da dispersão dos retornos. Ele representa a magnitude “típica” das flutuações, enquanto o parâmetro \\(\\nu\\) informa sobre a frequência e a intensidade dos eventos de cauda (denominados “shocks”, no jargão do mercado).\nUm \\(\\sigma\\) maior significa que, mesmo sem considerar as caudas, os retornos tendem a se espalhar mais. Quando combinado com um \\(\\nu\\) baixo, isso indica um ativo que não só tem flutuações grandes, mas também é propenso a flutuações muito grandes e muito pequenas com maior frequência.\nVamos analisar os log-retornos diários da Magazine Luiza (MGLU) entre 06/06/2024 e 04/06/2025\n\nrequire(gsheet)\n\nCarregando pacotes exigidos: gsheet\n\nurl_mglu &lt;- 'https://docs.google.com/spreadsheets/d/1dnxASqmPoOPo0MTeY_NoYmkhK8yZDlWPaACGrLhLgHI/edit?usp=sharing'\n\ndados &lt;- gsheet2tbl(url_mglu)\nhead(dados)\n\n# A tibble: 6 × 7\n  Data       Último Abertura Máxima Mínima Vol.   `Var%`\n  &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; \n1 04.06.2025 10.04  10.34    10.44  9.41   55.98M -2.05%\n2 03.06.2025 10.25  9.52     10.29  9.43   39.05M 7.44% \n3 02.06.2025 9.54   9.45     9.89   9.37   28.12M 3.47% \n4 30.05.2025 9.22   9.2      9.33   09.02  27.72M 1.54% \n5 29.05.2025 09.08  9.56     9.65   09.08  30.46M -4.92%\n6 28.05.2025 9.55   9.26     9.77   9.23   40.27M 2.25% \n\n\nObserve que os dados estão organizados com os fechamentos mais recentes aparecendo primeiro. Vamos calcular os log-retornos.\n\nfechamento = as.numeric(dados$Último)\nn = length(fechamento)\nfechamento = fechamento[n:1]\n\nmagalu &lt;- diff(log(fechamento))\nhist(magalu, freq= FALSE, main='Log-retorno MGLU3')\nlines(density(magalu), lwd = 2)\n\n\n\n\n\n\n\nts.plot(magalu,main ='Log-retornos por dia')\n\n\n\n\n\n\n\n\nVamos estimar a volatilidade basal e os graus de liberdade para estes dados. Vamos considerar \\(\\lambda=n_0=s_0=0,01\\), \\(r_0=1\\) e \\(m=0\\). Para os valores possíveis dos graus de liberdade, vamos considerar os conjunto \\(\\{0.5, 0.75, 1, 1.25,\\ldots,40\\}\\).\n\nx = magalu\nn = length(x)\nB = 5000\n# valores possiveis para nu\nnu_seq = seq(.5,40,.25)\n\n# hiperparâmetros\nl = .01\nm = 0 \nn0 = 0.01\ns0 = 0.01\nr0 = 1\n\n# valores iniciais\nnu = .5\nmu = 0\nz = rep(1,n) \nphi = 1\n\nfor(i in 1:B){\n  \n  # mu dado o resto\n  media = (sum(z*x)+l*m)/( l + sum(z))\n  desvio = 1/sqrt(phi[i]*( l + sum(z)))\n  mu[i+1] = rnorm(1, media, desvio )\n  \n  # phi dado o resto\n  alfa = (n+n0+1)/2\n  beta = .5*( s0 + l*(mu[i+1] - m)^2 + sum( (x-mu[i+1])^2 ) )\n  phi[i+1] = rgamma(1, alfa, beta)\n  \n  # z_i dado o resto\n  alfa = .5*(nu[i]+1)\n  beta = .5*(phi[i+1]*(x-mu[i+1])^2 + nu[i]) \n  z = rgamma(n, alfa, beta )\n  \n  # nu dado o resto\n  log_p = .5*n*nu_seq*log(nu_seq/2) - n*lgamma(nu_seq/2)+.5*nu_seq*sum(log(z))-.5*nu_seq*sum(z)- nu_seq*r0\n  nu[i+1] = sample(nu_seq,1,T,exp(log_p-max(log_p)))\n}\n\nmu_magalu  = mu[seq(B/2,B,15)]\nnu_magalu  = nu[seq(B/2,B,15)]\nvol_magalu = 1/sqrt(phi[seq(B/2,B,15)])\n\nAbaixo, apresentamos os traços e a autocorrelação para as amostros da posteriori para \\(\\nu\\) e \\(\\sigma=1/\\sqrt{\\phi}\\), após o burn-in e o \\(thinning\\).\n\noo = par( mfrow=c(2,2))\nts.plot(nu_magalu, main='Traço para os graus de liberdade')\nacf(nu_magalu, main='Autocorrelação para os graus de liberdade')\nts.plot(vol_magalu, main='Traço para a volatilidade')\nacf(vol_magalu, main='Autocorrelação para a volatilidade')\n\n\n\n\n\n\n\npar(oo)\n\nCom a amostra a posteriori simulada, podemos simular amostras da preditiva a posteriori. Podemos então construir um intervalo de predição para a função de distribuição empírica da preditiva a posteriori e compará-lo com a distribuição empírica dos dados. O gráfico abaixo mostra que o modelo é adequado.\n\ny_pred &lt;- array(NA_real_, c(length((nu_magalu)), n))\nfor(i in 1:length((nu_magalu))){\n  y_pred[i,] &lt;- mu_magalu[i] + rt(n, nu_magalu[i])*vol_magalu[i]\n}\n\nFd_sim = apply(y_pred,1, function(y){\n  Fd = ecdf(y)\n  Fd(sort(x))\n})\n\nqq = apply(Fd_sim,1, function(x) quantile(x,c(.025,.977)))\n\nplot(ecdf(x), main = '')\nlines(sort(x),qq[1,], col =2)\nlines(sort(x),qq[2,], col =2)\n\n\n\n\n\n\n\n\nPortanto, temos que a volatilidade basal estimada para o log-retorno diário da Magazine Luiza durente o intervalo de estudo foi 0,04 (ou 4%), o que é considerado elevado. Os graus de liberdade foram estimados em 7,3. Este resultado era esperado, pois o setor varejista de e-commerce está sujeito as oscilações de taxas de juros, inflação, poder de compra do consumidor. Além disso, pode-se somar a forte concorrência e o endividamento atual da empresa\n\nmean(vol_magalu)\n\n[1] 0.04378573\n\n\nPara ilustrar melhor estes conceitos, vamos repetir a análise para a empresa Engie Brasil Energia (EGIE3). Espera-se menos volatilidade, uma vez que empresas do setor elétrico geralmente têm receitas mais previsíveis, regulamentação estável e são consideradas “defensivas”.\n\nurl_egie &lt;- 'https://docs.google.com/spreadsheets/d/1qvv5RC5U5L-5snoz_QyzXB2v_etOMChBViypnl4XYMk/edit?usp=sharing'\ndados2 &lt;- gsheet2tbl(url_egie)\nfechamento2 = as.numeric(dados2$Último)\nn = length(fechamento2)\nfechamento2 = fechamento2[n:1]\n\negie &lt;- diff(log(fechamento2))\nplot(density(egie), main = 'Log-retornos diários',xlim=c(-.2,.2))\nlines(density(magalu),col =2)\nlegend('topleft',c('Magalu','Egie'), col=2:1, lwd = 1, bty = 'n')\n\n\n\n\n\n\n\n\nA volatilidade basal estimada para a EGIE no período foi de 1,2%. A probabilidade de que esta volatilidade seja menor que a da MGLU é de 0,999, o que corrobora com o esperado. Os graus de liberdade foram estimados em 8,07.\n\n\nA distribuição t-Student multivariada e o estudo de portifólios\nUm portfólio, no contexto financeiro, é um conjunto de investimentos que um indivíduo ou uma instituição possui. Alguns investimentos tendem a reagir de forma semelhante aos humeores do mercado. Por exemplo, considerando os log-retornos diários do Banco do Brasil (BBSA3) e Itaú Unibanco (ITUB4) no ano de 2024, temos uma correlação de 0,18. Portanto, se dois ativos dentro do portifólio são correlacionados, o risco deveria aumentar.\nPodemos relacionar a distribuição t-Student\\(_{\\nu}(\\boldsymbol{\\mu},\\Phi^{-1})\\) (\\(p\\) multivariada) como a seguinte mistura:\n\\[\\begin{align}\\boldsymbol{x}|z,\\boldsymbol{\\mu},\\Phi&\\sim \\hbox{Normal}_p(\\boldsymbol{\\mu},z^{-1}\\Phi^{-1})\\\\z&\\sim\\hbox{Gama}\\left(\\frac{\\nu}{2},\\frac{\\nu}{2}\\right)\\end{align}\\] Considerando uma amostra \\(\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_n\\) eas prioris \\(\\boldsymbol{\\mu}|\\Phi\\sim\\hbox{Normal}_p(\\boldsymbol{m}_0,\\lambda^{-1}\\Phi^{-1})\\), \\(\\Phi\\sim\\hbox{Wishart}(n_0,S_0)\\) e \\(\\nu\\sim\\hbox{Exponencial}(r_0)\\), temos as seguintes condicionais completas:\n\\[\\begin{align}\\boldsymbol{\\mu}|\\hbox{resto}&\\sim\\hbox{Normal}_p\\left(\\frac{\\sum_{i=1}^n z_i\\boldsymbol{x}_i+\\lambda\\boldsymbol{m}_0}{\\lambda+\\sum_{i=1}^n z_i},\\Phi^{-1}/(\\lambda + \\sum_{i=1}^n z_i)\\right)\\\\\\Phi|\\hbox{resto}&\\sim\\hbox{Gama}\\left(n+n_0+1,[S_0^{-1}+\\lambda(\\boldsymbol{\\mu}-\\boldsymbol{m}_0)(\\boldsymbol{\\mu}-\\boldsymbol{m}_0)'+\\sum_{i=1}^n z_i(\\boldsymbol{x}_i-\\boldsymbol{\\mu})(\\boldsymbol{x}_i-\\boldsymbol{\\mu})']^{-1}\\right)\\\\\nz_i|\\hbox{resto}&\\sim\\hbox{Gama}\\left(\\frac{\\nu+p}{2},\\frac{\\nu+(\\boldsymbol{x}_i-\\boldsymbol{\\mu})'\\Phi(\\boldsymbol{x}_i-\\boldsymbol{\\mu})}{2}\\right)\\\\\nf(\\nu|\\hbox{resto})&\\propto \\left(\\frac{\\nu}{2}\\right)^{\\frac{n\\nu}{2}}\\frac{1}{\\Gamma(\\nu/2)^n}\\left(\\prod_{i=1}^n z_i\\right)^{\\frac{\\nu}{2}}e^{-\\nu(r_0+\\frac{1}{2}\\sum_{i=1}^n z_i)}\n\\end{align}\\]\nSeja \\(p\\) o número de ações dentro do portifólio e seja \\(w_i\\) a proporção da \\(i\\)-ésima ação dentro do portifólio. Então \\(\\Phi\\) pode ser utilizada para os seguintes fins:\n\nCálculo da volatilidade do portifólio:\n\n\\[\\sigma_p=\\sqrt{\\boldsymbol{w}'\\Phi^{-1}\\boldsymbol{w}}\\]\n\nCálculo do portifólio ótimo: a melhor composição da proporção das ações dentro do portifólio é dada por\n\n\\[\\boldsymbol{w}=\\Phi\\boldsymbol{1}_p\\] e a respectiva volatilidade por portifólio é dada por \\[\\sigma_p=\\sqrt{\\textbf{1}_p'\\Phi \\textbf{1}_p}\\]\n\nRelação entre ações: uma estratégia protetiva é a diversificação de ativos. Isto porque ativos diversos tendem a se comportar de modo diferente com os humores do mercado, protegendo o capital de eventuais crises. um grafo de dependências condicionais utilizando \\(\\Phi\\) pode ser contruído para verificar a denpendência entre as ações. Isto é útil para proteção de capital.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#modelos-com-inflação-de-zeros",
    "href": "misturas.html#modelos-com-inflação-de-zeros",
    "title": "16  Misturas de distribuições",
    "section": "16.2 Modelos com inflação de zeros",
    "text": "16.2 Modelos com inflação de zeros\nQuando são observados mais zeros do que o esperado pelo modelo de contagem assumido para a verossimilhança, é usual considerar um modelo com inflação de zeros. Nesse tipo de modelo, assumimos que existe uma variável latente \\(Z|p\\sim\\hbox{Bernoulli}(\\rho)\\) tal que:\n\\[X=\\left\\{\\begin{array}{ll}0, & \\hbox{se }Z=1\\ \\\\ Y,&\\hbox{se }Z=0\\end{array}\\right.\\] onde \\(Y\\sim h(.|\\theta)\\) é o modelo de contagem. Seja \\(f(.|\\theta,\\rho)\\) a função de probabilidade de \\(X\\). Então\n\\[\\begin{align}f(0|\\theta,\\rho)&=\\sum_{z=0}^1 P(X=0|Z=z,\\theta)P(Z=z|\\rho)\\\\&=(1-\\rho)h(0|\\theta)+\\rho\\end{align}\\] a probabilidade de observar um zero está entre \\(h(0|\\theta)\\) e 1, o que caracteriza a inflação.\nAgora, considere um modelo inflacionado de zeros aumentado:\n\\[f(x,z|\\theta,\\rho)=f(x|z,\\theta)f(z|\\rho)=f(x|z,\\theta)\\rho^z(1-\\rho)^{1-z}.\\] Note que\n\\[f(x|z,\\theta)=\\left\\{\n\\begin{array}{ll}\nh(x|\\theta),&\\hbox{ se }z=0,\\\\\nI(x=0),&\\hbox{ se }z=1\\\\\n\\end{array}\\right.\\] logo, a distribuição conjunta \\(f(x,z|\\theta,\\rho)\\) é dada por\n\\[\\begin{array}{c|cc}\\hline & x=0 & x&gt; 0 \\\\ \\hline\nz=0 & h(0|\\theta)(1-\\rho) & h(x|\\theta)(1-\\rho) \\\\\nz=1 & \\rho & 0 \\\\ \\hline\n\\end{array}\n\\] Então,\n\\[\\begin{align}\n\\prod_{i=1}^n f(x_i,z_i|\\theta,\\rho)&=\\prod_{i=1}^n [h(0|\\theta)(1-\\rho)]^{I(x_i=0,z_i=0)}[h(x_i|\\theta)(1-\\rho)]^{I(x_i&gt;0,z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\\\\n&=\\prod_{i=1}^n [h(x_i|\\theta)(1-\\rho)]^{I(z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\\\\n&=\\prod_{i=1}^n(1-\\rho)^{I(z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\prod_{i=1}^n [h(x_i|\\theta)]^{I(z_i=0)}\\end{align}\\] e, notando que \\(I(z_i=0)=1-z_i,\\)\n\\[\\begin{align}\n\\prod_{i=1}^n f(x_i,z_i|\\theta,\\rho)&=\n(1-\\rho)^{n-\\sum_{i=1}^n z_i}\\rho^{\\sum_{i=1}^n z_iI(x_i=0)}\\prod_{i=1}^n [h(x_i|\\theta)]^{1-z_i}\\end{align}\\]\nConsidere, a priori, que \\(\\theta\\) e \\(\\rho\\) são independentes. Seja \\(\\pi(\\theta)\\) a função de densidade/probabilidade a priori para \\(\\theta\\) e considere que \\(\\rho\\sim\\hbox{Beta}(a,b)\\). Então, as condicionais completas para \\(\\theta\\) e \\(\\rho\\) são\n\\[\\begin{align}\nf(\\theta|\\rho,\\boldsymbol{z},\\boldsymbol{x})&\\propto \\prod_{i=1}^n h(x_i|\\theta)^{1-z_i}\\pi(\\theta),\\\\\nf(\\rho|\\theta,\\boldsymbol{z},\\boldsymbol{x})&\\propto \\rho^{\\sum_{i=1}^n z_iI(x_i=0)+a-1}(1-\\rho)^{n-\\sum_{i=1}^n z_i+b-1},\\\\\n\\end{align}\\]\nPara a condicional completa de \\(z_i\\), notemos que \\[P(Z_i=1|x_i&gt;0)=\\frac{P(Z_i=1,X_i&gt;0)}{P(X_i&gt;0)}=0,\\] e que\n\\[P(Z_i=z|x_i=0)= \\left\\{\\begin{array}{ll}\\frac{P(Z_i=0,X_i=0)}{P(X_i=0)}=\\frac{h(0|\\theta)(1-\\rho)}{\\rho+(1-\\rho)h(0|\\theta)},&,z=0\\\\\n\\frac{P(Z_i=1,X_i=0)}{P(X_i=0)}=\\frac{\\rho}{\\rho+(1-\\rho)h(0|\\theta)},&z=1\\end{array}\\right.,\\] logo \\[f(z_i|\\theta,\\rho,\\boldsymbol{x},\\boldsymbol{z}_{(-i)})=\\left\\{\\begin{array}{ll}\\hbox{Bernoulli}\\left( \\frac{\\rho}{\\rho+(1-\\rho)h(0|\\theta)}\\right),&\\hbox{ se }x_i=0\\\\\nI(z_i=0),&\\hbox{ se } x_i&gt;0\\\\ \\end{array}\\right.\\]\nPortanto, um amostrador de Gibbs para um modelo inflacionado de zeros é\n\nAmostrador de Gibbs para o modelo inflado de zeros\nFaça \\(j=0\\) e dê os valores iniciais \\(\\theta^{(0)}\\) e \\(\\rho^{(0)}\\).\nNo \\(j\\)-ésimo passo:\n\nPara \\(i\\in\\{1,\\ldots,n\\}\\), se \\(x_i&gt;0\\) faça \\(z_i=0\\). Senão, simule \\[z_i^{(j)}\\sim \\hbox{Bernoulli}\\left(\\frac{\\rho^{(j-1)}}{\\rho^{(j-1)}+(1-\\rho^{(j-1)})h(0|\\theta^{(j-1)})}\\right)\\]\nSimule \\[\\rho^{(j)}\\sim\\hbox{Beta}(a+\\sum_{i=1}^n z_i^{(j)}I(x_i=0),b+n-\\sum_{i=1}^n z_i^{(j)})\\]\nSimule \\(\\theta^{(j)}\\) de \\[f(\\theta|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x})\\propto \\prod_{i=1}^n h(x_i|\\theta)^{1-z_i^{(j)}}\\pi(\\theta).\\]\n\n\n\nExemplo - O modelo Poisson inflado de zeros \nNeste exemplo, vamos considerar que a distribuição da contagem é Poisson(\\(\\theta\\)) e que \\(\\theta\\sim\\hbox{Gama}(r,s)\\). Então,\n\\[\\begin{align}\nf(\\theta|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x})&\\propto \\prod_{i=1}^{n} h(x_{i} | \\theta )^{ 1-z_{i}^{(j)} }\\pi(\\theta)\\\\&=\n\\prod_{i=1}^{n} \\left[\\frac{ e^{-\\theta}\\theta^{x_i} }{x_i!}\\right]^{1-z_{i}^{(j)}}\\frac{s^r}{\\Gamma(r)}\\theta^{r-1} e^{-s\\theta}\\\\&\\propto \\theta^{\\sum_{i=1}^n x_i(1-z_i^{(j)})+r-1}e^{-(n-\\sum_{i=1}^n z_i^{(j)}+s)\\theta}\n\\end{align},\\]\nou seja, \\[\\theta^{(j)}|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x}\\sim\\hbox{Gama}(\\sum_{i=1}^n x_i(1-z_i^{(j)})+r,n-\\sum_{i=1}^n z_i^{(j)}+s)\\]\n\n\nExemplo. Número anual de furacões grandes\nOs dados abaixo representam o número anual de furacões atlânticos grandes (categoria 4 ou 5) entre 1987 e 2012, nos Estados Unidos.\n\nfur &lt;-  c(0, 0 ,1,\n0, 0, 1, 0, 0, 1, 0, 0, 2, 2,\n0, 0, 1, 1, 3, 4, 0, 0, 2, 0,\n0, 0, 0)\n\nA frequência relativa de zeros é 0,58. Considerando o modelo Poisson\\((\\theta)\\) com \\(f(\\theta)\\propto \\theta^{-1}\\), apresentamos abaixo o gráfico da frequência relativa com a respectiva probabilidade preditiva a posteriori. Observe que o modelo falha em capturar a probabilidade de zero, indicando que o modelo Poisson é inadequado para estes conjunto de dados.\n\n\n\n\n\n\n\n\n\nAbaixo, implementamos o amostrador de Gibbs para o modelo Poisson Inflado de zeros. Consideramos as densidades a priori \\(\\rho\\hbox{Beta}(1,1)\\) e \\(\\theta\\sim\\hbox{Gama}(.1,.1)\\).\n\n# hiperparâmetros para rho\na = b = 1\n\n# hiperparâmetros para theta\nr=.1\ns=.1\n\n# tamanho da amostra\nn &lt;- length(fur) \n\n# valores iniciais da cadeia\ntheta &lt;- mean(fur)\nrho &lt;- mean(fur == 0)\n\n# amostrador de Gibbs\nB &lt;- 50000\nfor(i in 1:B){\n  # simulando z\n  z &lt;- NULL\n  prob &lt;- rho[i]/ ( (1-rho[i])*dpois(0,theta[i]) + rho[i])\n  for(j in 1:n){\n    if(fur[j] &gt;0){ z[j] &lt;- 0} else{\n      z[j] &lt;- rbinom(1,1,prob)\n    }\n  }\n\n  # simulando rho\n  rho[i+1] &lt;- rbeta( 1, a + sum( z * (fur == 0)) , n- sum(z)+ b )\n  \n  # simulando theta\n  theta[i+1] &lt;- rgamma(1, sum( fur*(1-z) ) + r,  n - sum(z) + s)\n}\n\nVamos descartar a metade das simulações e usar um thinning igual a 15:\n\ntheta_sim &lt;- theta[seq(B/2,B,15)]\nrho_sim &lt;- rho[seq(B/2,B,15)]\n\noo &lt;- par(mfrow=c(2,2))\nts.plot(theta_sim, lwd = 2)\nts.plot(rho_sim, lwd = 2)\nacf(theta_sim)\nacf(rho_sim)\n\n\n\n\n\n\n\n\nPor último, realizamos algumas simulações da preditiva a posteriori e esstimamos as probabilidades para os pontos mais frequentes. Em seguida, comparamos estes valores com frequência relativa observada. Note que o ajuste deste modelo é adequado para o conjunto de dados.\n\n# tamanho do vetor simulado\nBs &lt;- length(theta_sim)\n\nx_til &lt;- array( NA_real_, c(Bs,n))\nfor(j in 1:Bs){\n  z &lt;- rbinom( n, 1, rho_sim[j])\n  x_til[j,] &lt;- (1-z)*rpois(n, theta_sim[j])\n}\n\n# probabilidades estimadas via ZIP\np_zip &lt;- prop.table(table(x_til))\n\nplot(table(fur)/n, type= 'p', xlab='No. anual furacões atlânticos', ylab = 'Probabilidade', col = 'cyan3', pch=16)\nlines(0:4,table(fur)/n, col = 'cyan3')\npoints(names(p_zip),p_zip, pch=16,col = 'magenta')\nlines(names(p_zip),p_zip,col = 'magenta')\n\nlegend('bottomleft',c('Freq. relativa','Pred. post. do modelo ZIP'), fill=c('cyan3','brown', 'magenta'), bty='n')\n\n\n\n\n\n\n\n\n\n\n16.2.1 Exercício\n\nAbaixo, segue o número anual de tornados em Lafayette Parish, Louisiana, entre 1950 e 2012.\n\ntor &lt;- c(0, 0,0, 1, 0, 0, 0, 1, 0, 0,\n1, 0, 0, 0, 1, 1, 0, 0, 0, 2,\n0, 0, 0, 0, 1, 3, 0, 2, 1, 0,\n1, 0, 0, 1, 0, 1, 0, 0, 2, 1,\n0, 1, 2, 0, 0, 1, 0, 1, 2, 0,\n0, 0, 3, 0, 2, 0, 1, 1, 3, 0,\n1, 1, 1)\n\n\nAjuste o modelo Poisson.\nAjuste o modelo Poisson inflado de zeros.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#mistura-escalonada-de-normais",
    "href": "misturas.html#mistura-escalonada-de-normais",
    "title": "16  Misturas de distribuições",
    "section": "16.3 Mistura escalonada de normais",
    "text": "16.3 Mistura escalonada de normais",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#misturas-finitas-com-número",
    "href": "misturas.html#misturas-finitas-com-número",
    "title": "16  Misturas de distribuições",
    "section": "16.4 Misturas finitas com número",
    "text": "16.4 Misturas finitas com número\nDizemos que \\(X|\\boldsymbol{\\theta},\\boldsymbol{p},\\kappa\\) é um modelo de mistura finito se sua função de densidade/probabilidade é dada por\n\\[f(x| \\boldsymbol{\\theta},\\boldsymbol{p} ,\\kappa )=\\sum_{k=1}^\\kappa p_k f_k(x|\\boldsymbol{\\theta}_k).\\]\nCada função \\(f(.|\\boldsymbol{\\theta}_k)\\) é denominada componente da mistura e o número de componentes pode ser desconhecido.\nAssim como o modelo com zeros inflacionados, podemos utilizar uma variável latente \\(\\textbf{z}_i|\\kappa=(z_{i,1},\\ldots,z_{i,\\kappa})\\sim\\hbox{Multinomial}(p_1\\ldots,p_\\kappa|\\sum_{k=1}^\\kappa z_{ik}=1)\\), obtendo o seguinte modelo aumentado\n\\[f(x_i|\\boldsymbol{\\theta},\\textbf{z}_i,\\kappa)=\\prod_{k=1}^\\kappa \\left[f\\left(x_i|\\boldsymbol{\\theta}_k\\right)\\right]^{z_{i,k}}\\]\nA função de verossimilhança aumentada para este modelo é\n\\[\\prod_{i=1}^n f(x_i|\\boldsymbol{\\theta},\\textbf{z}_i,\\kappa)=\\prod_{i=1}^n\\prod_{k=1}^\\kappa \\left[f\\left(x_i|\\boldsymbol{\\theta}_k\\right)\\right]^{z_{i,k}}.\\]\nConsidere as prioris \\(\\pi(\\boldsymbol{\\theta}|\\kappa)=\\prod_{k=1}^\\kappa \\pi(\\boldsymbol{\\theta}_k)\\) e \\(\\textbf{p}|\\kappa\\sim\\hbox{Dirichlet}(a_1,\\ldots,a_\\kappa)\\), onde \\[f(\\textbf{p}|\\kappa)\\propto \\prod_{k=1}^\\kappa p_k^{a_k-1}\\] com \\(\\sum_{k=1}^\\kappa p_k=1\\). As condicionais completas para este problema são\n\n\\(\\begin{align}f(\\boldsymbol{\\theta}_k|resto)\\propto \\prod_{i:z_{i,k}=1}f(x_i|\\boldsymbol{\\theta}_k)\\pi(\\boldsymbol{\\theta}_k)\\end{align}\\)\n\\(\\begin{align}f(\\textbf{z}_i|resto)\\propto \\prod_{k=1}^\\kappa \\left[p_kf(x_i|\\boldsymbol{\\theta}_k)\\right]^{z_{i,k}}\\end{align}\\) ou seja, \\(\\textbf{z}_i|rest\\sim\\hbox{Multinomial}(\\tilde{p}_1,\\ldots,\\tilde{p}_\\kappa)\\), onde\n\n\\[\\tilde{p}_k=\\frac{p_kf(x_i|\\boldsymbol{\\theta}_k)}{\\sum_{k=1}^\\kappa p_kf(x_i|\\boldsymbol{\\theta}_k)}\\] * \\(f(\\textbf{p}|resto)\\propto \\prod_{k=1}^\\kappa p_k^{\\sum_{i=1}^n z_{i,k}+a_k-1}\\), ou seja \\(\\textbf{p}|resto\\sim\\hbox{Dirichlet}(a_1+\\sum_{i=1}^n z_{i,1},\\ldots,a_\\kappa+\\sum_{i=1}^n z_{i,\\kappa})\\)\nSe necessário, podemos atrbuir a priori \\[\\pi(\\kappa)=\\frac{1}{M},\\kappa=1,2,\\ldots,M\\] para obter a condicional completa \\[\\pi(\\kappa|resto)=\\frac{\\prod_{i=1}^n\\prod_{k=1}^\\kappa f(x_i|\\boldsymbol{\\theta}_k)^{z_{i,k}}\\pi(\\boldsymbol{\\theta}_k)\\pi(\\textbf{p}|\\kappa)\\pi(\\textbf{z}_i|\\kappa)}{\\sum_{\\kappa=1}^M \\prod_{i=1}^n\\prod_{k=1}^\\kappa f(x_i|\\boldsymbol{\\theta}_k)^{z_{i,k}}\\pi(\\boldsymbol{\\theta}_k)\\pi(\\textbf{p}|\\kappa)\\pi(\\textbf{z}_i|\\kappa)},\\kappa=1,\\ldots,M.\\]\n\n16.4.1 O velho fiel\nO banco de dados faithful mostra a duração e o tempo até a próxima erupção do geiser Velho Fiel, no parque Yellowstone. Abaixo mostramos o diagrama do tempo de espera entre erupções\n\nhist(faithful$waiting)\n\n\n\n\n\n\n\n\nÉ possível notar classes, uma com tempo e entre erupções menor que 70 com tempo maior. Temos as seguintes estimativas iniciais:\n\n## elementos na classe 1\nx &lt;- faithful$waiting\nz &lt;- x &lt; 70\n# proporção na classe 1\nmean(z)\n\n[1] 0.3786765\n\n# média e desvio padrão na classe 1\nmean( x[z])\n\n[1] 55.15534\n\nsd( x[z])\n\n[1] 6.266558\n\n\n\n## elementos na classe 2\n# proporção na classe 2\nmean(z==F)\n\n[1] 0.6213235\n\n# média e desvio padrão na classe 2\nmean( x[z==F])\n\n[1] 80.49112\n\nsd( x[z==F])\n\n[1] 5.456667\n\n\nVamos considerar que as duas componentes possuem distribuição normal. Para cada componente, teremos as seguintes prioris:\n\\[\\pi(\\mu_i,\\phi_i)=\\frac{\\phi^{1/2}_i}{\\sqrt{2\\pi C}}e^{-\\frac{\\phi_i}{2C}(\\mu_i-m_i)^2}\\frac{b^a}{\\Gamma(a)}\\phi_i^{a-1}e^{b\\phi_i},\\]\n\\[p\\sim\\hbox{Beta}(r,s)\\]\n\\[z_i\\sim\\hbox{Bernoulli}(p)\\]\nO modelo aumentado é \\[f(x_i|\\mu,\\phi,z_{i})=\\left[\\frac{\\phi_1^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_1}{2}(x_i-\\mu_1)}\\right]^{z_i}\\left[\\frac{\\phi_2^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_2}{2}(x_i-\\mu_2)}\\right]^{1-z_i}\\] As condicionais completas são:\n\\[\\begin{align}f(\\mu_1|resto) &\\propto \\exp\\left\\{-\\frac{\\phi_1}{2}\\sum_{i=1}^n z_i(x_i-\\mu_1)^2\\right\\}\\exp\\left\\{-\\frac{\\phi_1}{2C} z_i(\\mu_1-m_1)^2\\right\\}\\\\&\\propto \\exp\\left\\{-\\frac{\\phi_1}{2}\\left(\\sum_{i=1}^n z_i+C^{-1}\\right) \\left(\\mu_1-\\frac{\\sum_{i=1}^{n}x_iz_i+m_1C^{-1}}{\\sum_{i=1}^n z_i+C^{-1}}\\right)^2\\right\\}\\end{align}\\]\n\\[\\begin{align}f(\\mu_2|resto) &\\propto \\exp\\left\\{-\\frac{\\phi_2}{2}\\sum_{i=1}^n (1-z_i)(x_i-\\mu_2)^2\\right\\}\\exp\\left\\{-\\frac{\\phi_2}{2C} (1-z_i)(\\mu_2-m_2)^2\\right\\}\\\\&\\propto \\exp\\left\\{-\\frac{\\phi_2}{2}\\left(\\sum_{i=1}^n (1-z_i)+C^{-1}\\right) \\left(\\mu_2-\\frac{\\sum_{i=1}^{n}x_i(1-z_i)+m_1C^{-1}}{\\sum_{i=1}^n (1-z_i)+C^{-1}}\\right)^2\\right\\}\\end{align}\\]\n\\[\\begin{align}f(\\phi_2|resto)&\\propto \\phi_2^{-\\frac{1}{2}\\sum_{i=1}^{n}z_i}\ne^{-\\frac{\\phi_2}{2}\\sum_{i=1}^n (1-z_i)(x_i-\\mu_2)^2}\\phi^{-1/2}_2e^{-\\frac{\\phi_2}{2}(\\mu_2-m_2)^2}\\phi_2^{a/2-1}e^{-\\phi_2 b/2}\\\\ &\\propto \\phi_2^{\\frac{1}{2}(1+a+\\sum_{i=1}^{n}(1-z_i)-1}e^{-\\frac{\\phi_2}{2}[\\sum_{i=1}^n(1-z_i)(x_i-\\mu_2)^2 +(\\mu_2-m_2)^2 + b]}\\end{align}\\] \\[\\begin{align}f(\\phi_1|resto)&\\propto \\phi^{-\\frac{1}{2}\\sum_{i=1}^{n}z_i}\ne^{-\\frac{\\phi_1}{2}\\sum_{i=1}^n z_i(x_i-\\mu_1)^2}\\phi^{-1/2}e^{-\\frac{\\phi_1}{2}(\\mu_1-m_1)^2}\\phi_1^{a/2-1}e^{-\\phi_1 b/2}\\\\ &\\propto \\phi_1^{\\frac{1}{2}(1+a+\\sum_{i=1}^{n}z_i)-1}e^{-\\frac{\\phi_1}{2}[\\sum_{i=1}^nz_i(x_i-\\mu_1)^2 +(\\mu_1-m_1)^2 + b]}\\end{align}\\]\n\\[\\begin{align}f(p|resto)\\propto \\prod_{i=1}^n p^{z_i}(1-p)^{1-z_i}p^{r-1}(1-p)^{s-1}\\propto p^{r+\\sum_{i=1}^n z_i-1}(1-p)^{s+\\sum_{i=1}^n (1-z_i)-1}\\end{align}\\]\n\\[f(z_i|resto)\\propto\\left[ p\\frac{\\phi_1^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_1}{2}(x_i-\\mu_1)^2}\\right]^{z_i}\\left[ (1-p)\\frac{\\phi_2^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_2}{2}(x_i-\\mu_2)^2}\\right]^{1-z_i}\\]\nAbaixo implementamos o amostrador de Gibbs\n\nB &lt;- 50000\n\n# hiperparmametros\nm1 &lt;- 65\nm2 &lt;- 80\nC &lt;- 1000\nr= 4; s = 6\na = 1; b = .1\n\n# valores iniciais\nz &lt;- x &lt; 70\nphi1 &lt;- 1/36\nphi2 &lt;- 1/25\nmu1 = mu2 =  p = NULL\n\nfor(i in 1:B){\n  # mu dado o resto\n  m1_post &lt;- ( sum(x*z) + m1/C) / ( sum(z) + 1/C )\n  m2_post &lt;- ( sum(x*(1-z)) + m1/C) / ( sum(1-z) + 1/C )\n  s1_post &lt;- 1 / ( ( sum(z) + 1/C )*phi1[i] )\n  s2_post &lt;- 1 / ( ( sum(1-z) + 1/C )*phi2[i] )\n  \n  mu1[i+1] &lt;- rnorm(1, m1_post, sqrt( s1_post) )\n  mu2[i+1] &lt;- rnorm(1, m2_post, sqrt( s2_post) )\n  \n  # phi dado resto\n  phi1[i+1] &lt;- rgamma(1, 1 + a + sum(z), sum( z*(x - mu1[i+1])^2 ) + (mu1[i+1]-m1)^2 + b)\n  phi2[i+1] &lt;- rgamma(1, 1 + a + sum(1-z), sum( (1-z)*(x - mu2[i+1])^2 ) + (mu2[i+1]-m2)^2 + b)\n  \n  # p dado resto\n  p[i+1] &lt;- rbeta(1, r + sum(z), s + sum(1-z) )\n  \n  # z dado resto\n  aux1 &lt;- p[i+1]*dnorm(x,mu1[i+1], 1/sqrt(phi1[i+1]))\n  aux2 &lt;- (1-p[i+1])*dnorm(x,mu2[i+1], 1/sqrt(phi2[i+1]))\n  \n  z &lt;- rbinom(length(x), 1, aux1/( aux1 + aux2))\n}\n# \n\n\nhist(mu1[seq(B/2,B,30)])\n\n\n\n\n\n\n\nhist(mu2[seq(B/2,B,30)])",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#exercícios",
    "href": "misturas.html#exercícios",
    "title": "16  Misturas de distribuições",
    "section": "16.5 Exercícios",
    "text": "16.5 Exercícios\n\n16.5.1 Volatilidade individual das ações da B3\nAs ações são divididas por segmentos. Abaixo mostramos os segmentos e suas principais ações na bolsa brasileira.\n\n\n\nAnexando pacote: 'dplyr'\n\n\nOs seguintes objetos são mascarados por 'package:stats':\n\n    filter, lag\n\n\nOs seguintes objetos são mascarados por 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nAnexando pacote: 'kableExtra'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    group_rows\n\n\n\nPrincipais Ações da B3 por Setor\n\n\nSetor\nAção\nTicker\n\n\n\n\nBens Industriais\n\n\nBens Industriais\nCCR\nCCRO3\n\n\nBens Industriais\nGrupo Vamos\nVAMO3\n\n\nBens Industriais\nIndústrias Romi\nROMI3\n\n\nBens Industriais\nRumo\nRAIL3\n\n\nBens Industriais\nWeg\nWEGE3\n\n\nComunicações\n\n\nComunicações\nBrisanet\nBRIT3\n\n\nComunicações\nOi\nOIBR3\n\n\nComunicações\nTelefônica Brasil\nVIVT3\n\n\nComunicações\nTim\nTIMS3\n\n\nComunicações\nUnifique\nFIQE3\n\n\nConsumo Cíclico\n\n\nConsumo Cíclico\nCVC Brasil\nCVCB3\n\n\nConsumo Cíclico\nEmbraer\nEMBR3\n\n\nConsumo Cíclico\nLocaliza\nRENT3\n\n\nConsumo Cíclico\nLojas Renner\nLREN3\n\n\nConsumo Cíclico\nMagazine Luiza\nMGLU3\n\n\nConsumo Não Cíclico\n\n\nConsumo Não Cíclico\nAmbev\nABEV3\n\n\nConsumo Não Cíclico\nAssaí\nASAI3\n\n\nConsumo Não Cíclico\nHypera Pharma\nHYPE3\n\n\nConsumo Não Cíclico\nJBS\nJBS3\n\n\nConsumo Não Cíclico\nRaia Drogasil\nRADL3\n\n\nFinanceiro\n\n\nFinanceiro\nB3\nB3SA3\n\n\nFinanceiro\nBanco do Brasil\nBBAS3\n\n\nFinanceiro\nBradesco\nBBDC4\n\n\nFinanceiro\nItaú Unibanco\nITUB4\n\n\nFinanceiro\nItaúsa\nITSA4\n\n\nMateriais Básicos\n\n\nMateriais Básicos\nCSN\nCSNA3\n\n\nMateriais Básicos\nGerdau\nGGBR4\n\n\nMateriais Básicos\nKlabin\nKLBN11\n\n\nMateriais Básicos\nSuzano\nSUZB3\n\n\nMateriais Básicos\nVale\nVALE3\n\n\nPetróleo, Gás e Biocombustíveis\n\n\nPetróleo, Gás e Biocombustíveis\nCosan\nCSAN3\n\n\nPetróleo, Gás e Biocombustíveis\nPetrobras ON\nPETR3\n\n\nPetróleo, Gás e Biocombustíveis\nPetrobras PN\nPETR4\n\n\nPetróleo, Gás e Biocombustíveis\nPrio\nPRIO3\n\n\nPetróleo, Gás e Biocombustíveis\nVibra Energia\nVBBR3\n\n\nSaúde\n\n\nSaúde\nFleury\nFLRY3\n\n\nSaúde\nHapvida\nHAPV3\n\n\nSaúde\nHermes Pardini\nPARD3\n\n\nSaúde\nQualicorp\nQUAL3\n\n\nSaúde\nRede D'Or\nRDOR3\n\n\nTecnologia\n\n\nTecnologia\nInfracommerce\nIFCM3\n\n\nTecnologia\nIntelbras\nINTB3\n\n\nTecnologia\nLocaweb\nLWSA3\n\n\nTecnologia\nMéliuz\nCASH3\n\n\nTecnologia\nTotvs\nTOTS3\n\n\nUtilidade Pública\n\n\nUtilidade Pública\nCemig\nCMIG4\n\n\nUtilidade Pública\nEletrobras ON\nELET3\n\n\nUtilidade Pública\nEngie Brasil\nEGIE3\n\n\nUtilidade Pública\nSabesp\nSBSP3\n\n\nUtilidade Pública\nTaesa\nTAEE11\n\n\n\n\n\n\n\nNeste exercício vamos explorar a volatilidadde basal dos log-retornos das ações da B3 utilizando a distribuição \\(t\\)-Student. O pacote rb3 é útil para obter os preços das ações brasileiras O comando abaixo faz o download de todos os dados do ano de 2024.\n\nlibrary('rb3')\n# coletando os dados da B3 de 2024\ndf_2024 &lt;- cotahist_get(\"2024-01-01\", \"yearly\")\ndados &lt;- data.frame(df_2024$HistoricalPrices)\n\nO ticker da empresa está na coluna cod_negociacao e o preço de fechamento na coluna preco_ult. Para obter os dados de uma ação específica, basta fazer o filtro na coluna. Por exemplo, a série de preços da Vale pode ser obtida do seguinte modo:\n\nvale3 &lt;- dados$preco_ult[ dados$cod_negociacao == 'VALE3' ]\nts.plot(vale3, xlab='Dia',ylab='Preço de fechamento')\n\n\n\n\n\n\n\n\nObtenha estimativas pontuais e intervalares para a volatilidade basal e para os graus de liberdade de cada ação. Crie um diagrama de dispersão, identificando por esquemas de cores ou símbolos o segmento das ações. Discua quais ações e quais seguimentos são menos arriscados. Faça intervalos de credibilidade ou testes de hipóteses para corroborar sua discussão.\n\n\n16.5.2 Análise de um portifólio\nUtilizando as ações dadas no exemplo anterior.\n\nPara cada setor, calcule a volatilidade do portifólio ótimo.\nCalcule a volatlidade do portifólio ótimo utilizando todos os setores.\nAinda utilizando todo os setores, faça um grafo de dependências condicionais\nProcure por ações com baixa volatilidade e sem relações diretas. Contrua seu próprio portifólio, misturando ações de diferentes segmentos.\nCalcule a volatilidade do seu portifólio e compare com a volatilidade geral e a volatlidade por segmentos.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "mcmc.html",
    "href": "mcmc.html",
    "title": "17  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "",
    "text": "17.1 Cadeias de Markov\nA coleção \\({\\X(t),t\\inT\\}\\) é um processo estocástico se \\(X(t)\\) é uma variável aleatória para cada \\(t\\in T\\).\nA variável \\(X(t)\\) é denominada estado. O processo é dito ser a tempo discreto se \\(T\\subseteq \\mathbb{Z}\\).\nEm um processo a tempo discreto, é usual utilizar a notação \\(X(t)\\equiv X_t\\).\nO processo estocástico \\(X_0,X_1,X_2,\\ldots\\) é uma cadeia de Markov de ordem \\(d\\) se\n\\[P(X_n\\in A|X_{n−1}=x_{n−1},…,X_0=x_0)=P(X_n\\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d}).\\]\nUma cadeia de Markov de ordem \\(d\\) é dita ser homogênea se, para qualquer \\(m&gt;0\\) natural,\n\\[P(X_n\\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d})=P(X_{n+m}\\in A|X_{n+m−1}=x_{n−1},…,X_{n+m−d}=_{xn−d}).\\]\nEstamos interessados nas cadeias homogêneas de ordem \\(d=1\\), que doravante serão denominadas simplesmente por cadeias de Markov.\nA evolução da cadeia de \\(X_n\\) até \\(X_{n+1}\\) é denominada transição em 1 passo. A densidade \\(k(.|y)\\) que satisfaz\n\\[P(X_{n+1}\\in A|X_n=y)=\\int_A k(x|y)dx\\]\né denominada núcleo de transição (ou núcleo de transição em 1 passo. Se os estados forem variáveis discretas, \\(k(.|y)\\) será uma função de probabilidade e a discussão é análoga.\nA seguir, vamos discutir em quais situações esta distribuição exsite.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "mcmc.html#cadeias-de-markov",
    "href": "mcmc.html#cadeias-de-markov",
    "title": "17  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "",
    "text": "Uma cadeia de Markov\nConsidere a seguinte cadeia de Markov:\n\\[X_n|X_{n−1}=y∼\\hbox{Uniforme}(1−y,1).\\]\nAbaixo, simulamos duas trajetórias de tamanho 200 deste processo, cada uma com um valor diferente para \\(x_0\\).\n\nset.seed(123)\n\ncadeia1 &lt;- .1\ncadeia2 &lt;- .5\n\nfor(i in 2:200){\n  cadeia1[i] &lt;- runif(1, 1 - cadeia1 [i - 1] , 1)\n  cadeia2[i] &lt;- runif(1, 1 - cadeia2 [i - 1] , 1)\n}\n\n# gráfico das duas trajetórias\nplot(cadeia1,cadeia2, type = \"l\", col =1)\npoints(cadeia1[1] , cadeia2[1] , pch=16) # ponto inicial\n\n\n\n\n\n\n\n\nPelo gráfico acima observamos que, independente de onde a cadeia começou, as duas simulações se concentraram na mesma região do gráfico após algumas iterações. A figura abaixo apresenta a função densidade estimada via método do núcleo para as duas trajetórias simuladas, excluindo os 10 primeiros pontos, de onde pode-se inferir que as distribuições são as mesmas.\n\nplot(density(cadeia1[-(1:10)]), lwd = 2, main = \"\")\nlines(density(cadeia2[-(1:10)]), lty = 2, lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n17.1.1 A distribuição estacionária\nDizemos que \\(\\pi(.)\\) é a densidade da distribuição estacionária de uma cadeia de Markov se\n\\[\\pi(y)=\\int \\pi(x)k(y|x)dx.\\] Note que isto implica que \\(X_i∼\\pi()\\), ou seja, a distribuição marginal da cadeia é a mesma.\nPortanto, ao simular uma trajetória de uma cadeia de Markov com distribuição estacionária, os valores simulados são identicamente distribuídos segundo \\(\\pi(.)\\).\nSe o valor inicial \\(x_0\\) utilizado para gerar a amostra estiver dentro da região de alta densidade de \\(\\pi(.)\\), os próximos valores que serão gerados já são da distribuição estacionária. Caso contrário, defina \\(k^{(d)}(.|y)\\) como o núcleo de transição em \\(d\\) passos. Observe que tal núcleo sempre pode ser obtido do núcleo em 1 passos pois:\n\\[k^{(2)}(x|x_0)=\\int k(x|z)k(z|x_0)dz\\]\n\\[k^{(3)}(x|x_0)=\\int k^{(2)}(x|z)k(z|x_0)dz\\] e assim por diante. Contudo, se há distribuição estacionária, então \\[\\pi(x)=\\lim_{n\\rightarrow\\infty} k^{(n)}(x|x_0).\\] Isto implica que a cadeia eventualmente vai construir uma trajetória até a região de alta densidade de \\(\\pi(.)\\).\nAs condições para existência da distribuição estacionária são:\n\nExiste \\(n&gt;0\\) tal que \\(P(X_n\\in A|X_0=x_0)\\) para quaisquer \\(A\\) e \\(x_0\\), sendo que o número médio de passos para realizar a transição é finito.\n\\(P(X_n\\in A|X_0=x_0)\\) não é uma função periódica em \\(n\\)\n\n\nSimulando de uma distribuição estacionária\nConsidere novamente a seguinte cadeia de Markov:\n\\[X_n|X_{n−1}=y∼\\hbox{Uniforme}(1−y,1).\\]\nVamos simular uma trajetória de tamanho 500 começando em \\(x_0=.5\\)\n\nset.seed(123)\nx &lt;- .5\n\nfor(i in 2:500){\n  x[i] &lt;- runif(1, 1 - x [i - 1] , 1)\n}\n\n\nts.plot(x)\nabline(h=.5,lty=2)\n\n\n\n\n\n\n\n\nAbaixo, apresentamos o histograma da distribuição estacionária simulada pela cadeia.\n\nhist(x, freq = F, main = '')\n\n\n\n\n\n\n\n\nAgora, note que \\(\\pi(y)=2y\\) é distribuição estacionária, uma vez que\n\\[2y=\\pi(y)=\\int \\pi(u)k(y|u)du=\\int 2u\\frac{I(1−u&lt;y&lt;1)}{u}du=2∫^{1}_{1−y}du=2y\\] Vamos adicionar essa densidade no histograma obtido:\n\nhist(x, freq = F, main =\"\")\nabline(0,2, lwd = 2, col =4)",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "mcmc.html#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov",
    "href": "mcmc.html#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov",
    "title": "17  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "17.2 Introdução aos métodos de Monte Carlo via Cadeias de Markov",
    "text": "17.2 Introdução aos métodos de Monte Carlo via Cadeias de Markov\nOs métodos para simular a distribuição \\(f(x)\\) gerando variáveis aleatórias utilizando uma cadeia de Markov são denominados métodos de Monte Carlo via Cadeias de Markov (MCMC).\nDiferente dos outros métodos de simulação, os MCMCs exigem alguns cuidados para garantir que estamos simulando variáveis independentes e identicamente distribuídas.\nAo longo desta aula, vamos utilizar a cadeia do exemplo abaixo.\n\nUma cadeia como exemplo\nConsidere uma cadeia de Markov com o seguinte núcleo de transição,\n\\[X_t|X_{t−1}=y\\sim N(\\alpha y,1)\\] com \\(\\alpha\\in(−1,1)\\). Este núcleo tem a seguinte representação estocástica:\n\\[X_t=\\alpha X_{t−1}+e_t,\\] onde \\(e_t\\simN(0,1)\\). Note que \\[\\begin{align}X_{t+2}&=\\alpha X_{t+1}+e_{t+1}=\\alpha(\\alpha X_t+e_t)+e_{t+1}\\\\&=\\alpha^2X_t+\\alpha e_{t+1}+e_t\\end{align}\\] ou seja \\[X_{t+2}|X_t=y\\sim N(\\alpha^2y,\\alpha^2+\\alpha)\\]. É fácil induzir que \\[X_{t+n}|X_t∼N\\left(\\alpha^n y,\\sum_{j=0}^n \\alpha^j\\right).\\]\nLogo \\[\\pi(x)=\\lim_{n\\rightarrow \\infty} k^{(n)}(x|y)=\\phi\\left(x|0,\\frac{1}{1-\\alpha}\\right),\\] onde \\(\\phi(x|\\mu,\\sigma^2)\\) é a funçãon densidade da normal. Para os nossos exemplo, utilizaremos \\(\\alpha=0,7\\).\n\nO objetivo dos métodos do tipo MCMC é desenvolver uma cadeia de Markov, com certo núcleo de transição \\(k(x_i|x_{i−1})\\), que tenha como distribuição estacionária a distribuição de interesse, doravante denotada por \\(f(x)\\).\nEm um mundo ideal, a simulação da cadeia deveria começar em um ponto \\(x_0\\) com alta probabilidade sob a distribuição estacionária. Como isto em geral não é possível, só podemos garantir que existe uma iteração \\(n\\) tal que a partir dela os valores simulados são da distribuição estacionária. Para nos auxiliar na escolha deste valor \\(n\\) podemos utilizar um traceplot\n\nTraceplot O gráfico com linhas unindo os pontos \\((i,x_i)\\) é denominado traceplot. Um de seus objetivos é auxiliar a detectar em qual momento a cadeia começou a amostrar pontos de f(.) (ou equivalentemente, em que momento a cadeia entrou em equilíbrio).\n\nO traceplot de um processo estacionário com variância finita tem um comportamento típico de pontos em torno da média da distribuição estacionária. Deste modo, ele é uma ferramenta exploratória que nos auxilia a detectar se a cadeia não está em equilíbrio ao perceber um padrão fora do que se esperaria de uma distribuição estacionária.\n\nExplicando o traceplot\nAbaixo, ilustramos o traceplot de duas cadeias simuladas, sendo que a única diferença entre elas é o valor de \\(x_0\\)\nA distribuição estacionária está representada ao longo do eixo das ordenadas com as linhas tracejadas em azul representando os quantis 99,5% e 0,05%. Mostramos dois traceplots (linhas pretas) com valores distintos de x0\nNo primeiro, escolhemos \\(x_0=0\\) que é a moda da distribuição estacionária e na segunda \\(x0=−10\\), um valor extremo.\n\nset.seed(123)\n\ncadeia1 = 0\ncadeia2 = -10\n\nfor(n in 1:50){\n  cadeia1[n+1] = .7*cadeia1[n]+rnorm(1)\n  cadeia2[n+1] = .7*cadeia2[n]+rnorm(1)\n}\n\nts.plot(cadeia1, ylim=c(-10,10))\nabline(h = qnorm(.995,0,sqrt(1/.3)), lty = 2)\nabline(h = qnorm(.005,0,sqrt(1/.3)), lty = 2)\n\n\n\n\n\n\n\nts.plot(cadeia2, ylim=c(-10,10))\nabline(h = qnorm(.995,0,sqrt(1/.3)), lty = 2)\nabline(h = qnorm(.005,0,sqrt(1/.3)), lty = 2)\n\n\n\n\n\n\n\n\nCom \\(x_0=0\\), o traceplot não dá evidências contra a hipótese de equilíbrio, pois os pontos simulados condizem com o que é esperado para a distribuição estacionária. Já com \\(x_0=−10\\), temos que o traceplot dá evidências de que a convergência ocorreu após 3 ou 4 iterações.\nPodemos utilizar os dois conjuntos simulados, desde que as 4 primeiras simulações da segunda cadeia sejam descartadas. Tal descarte é denominado burn-in.\nLembremos que nosso objetivo é simular variáveis independentes e identicamente distribuídas de uma distribuição alvo. Já o objetivo de um método MCMC é gerar variáveis dependentes e identicamente distribuídas segundo a distribuição alvo.\nConsiderando as variáveis simuladas (após o burn-in) \\(x_1,x_2,\\ldots,x_n\\), a dependência (linear) das variáveis obtidas via MCMC é estimada pela função de autocorrelação.\n\\[r(h)=\\sum_{i=1}^{n−h}\\frac{(x_i−\\bar{x})(x_{i+h}−\\bar{x})}{\\sum_{i=1}^n (x_i−\\bar{x})^2}.\\]\nPara termos uma amostra de variáveis aproximadamente independentes, podemos remover o efeito da autocorrelação encontrando o valor \\(h′\\) tal que \\(r(h′)≈0\\) e ficar somente com as variáveis \\(x1,x1+h′,x1+2h′,\\ldots\\). O traceplot desta subamostra deve apresentar os pontos em torno da média mas sem um padrão.\n\nVoltemos ao Exemplo 9.2, com \\(x_0=0\\). Vamos simular uma trajetória desta cadeia de tamanho \\(n=400\\) (lembre-se que neste caso o burn-in não é necessário).\n\nset.seed(123)\nn &lt;- 400\nx &lt;- 0 \nfor(i in 2:n) x[i] &lt;- .7*x[i-1] + rnorm(1)\n\n# autocorrelações (valores e gráfico)\n(acf(x))\n\n\n\n\n\n\n\n\n\nAutocorrelations of series 'x', by lag\n\n     0      1      2      3      4      5      6      7      8      9     10 \n 1.000  0.627  0.375  0.225  0.101  0.039 -0.011  0.017  0.022  0.001 -0.027 \n    11     12     13     14     15     16     17     18     19     20     21 \n-0.057 -0.088 -0.062 -0.050 -0.046 -0.106 -0.097 -0.085 -0.058 -0.023  0.008 \n    22     23     24     25     26 \n 0.049  0.006 -0.031 -0.037 -0.054 \n\n# note o efeito indesejado da dependência, ao fazer o gráfico de dispersão entre (x_i, x_{i+1})\nplot(x[-1],x[-n])\n\n\n\n\n\n\n\n\nNote que a autocorrelação estimada em h=5 é \\(r(5)=0,039\\). Podemos então retirar a subamostra \\(x1,x6,x11,...\\) para representar a nossa amostra de variáveis independentes e identicamente distribuídas. Abaixos, mostramos que o efeito indesejado da dependência desaparece.\n\ni &lt;- seq(1, n, 5)\n\n# subamostra das variáveis iid\nx_h &lt;- x[i]\n\n# autocorrelação da subamostra\nacf(x_h)\n\n\n\n\n\n\n\n# o efeito da dependência some. Veja, por exemplo\nn_h &lt;- length( x_h )\nplot( x_h[ -1 ], x_h[ -n_h ] )",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Brockmann, H Jane. 1996. “Satellite Male Groups in Horseshoe\nCrabs, Limulus Polyphemus.” Ethology 102 (1): 1–21.\n\n\nPolack, Fernando P, Stephen J Thomas, Nicholas Kitchin, Judith Absalon,\nAlejandra Gurtman, Stephen Lockhart, John L Perez, et al. 2020.\n“Safety and Efficacy of the BNT162b2 mRNA Covid-19\nVaccine.” New England Journal of Medicine 383 (27):\n2603–15.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "negativeBinomial.html",
    "href": "negativeBinomial.html",
    "title": "15  Binomial negativa",
    "section": "",
    "text": "15.1 O modelo binomial negativo\nA distribuição Poisson é muito comum em problemas de contagem. Como sua esperança e variância são iguais, o termo sobredispersão foi cunhado na literatura como uma variância maior que a média, o que seria indício de que o modelo Poisson não é adequado (de modo análogo, há o conceito de subdispersão, mas não é um fenômeno comum).\nDizemos que \\(X|\\rho,\\phi\\sim\\hbox{Binomial Negativa}\\) se\n\\[p(x|\\rho,\\phi)=\\frac{\\Gamma(\\phi+x)}{x!\\Gamma(\\phi)}\\rho^\\phi(1-\\rho)^x,\\] onde \\(x\\in\\mathbb{N}\\), \\(\\rho\\in(0,1)\\) e \\(\\phi&gt;0\\).\nExistem diversos motivos para considerar o modelo binomial negativo uma alternativa quando o modelo Poisson não parece ser adequado. Primeiro, temos que \\(E(X|\\rho,\\phi)=\\phi(1-\\rho)/\\rho\\) e \\(Var(X|\\rho,\\phi)=E(X|\\rho,\\phi)/\\rho\\), logo, a sobredispersão está presente no modelo. Além disso, se \\(X|\\lambda\\sim\\hbox{Poisson}(\\lambda)\\) e \\(\\lambda\\sim\\hbox{Gama}(\\phi, \\rho/(1-\\rho))\\), então \\(X|\\phi,\\rho\\sim\\hbox{Binomial Negativa}(\\phi,\\rho)\\) logo, este modelo é uma mistura do modelo Poisson. Por último, fazendo \\[\\mu=\\phi\\frac{1-\\rho}{\\rho}\\Rightarrow \\rho(\\phi)=\\frac{\\phi}{\\phi+\\mu},\\] pode-de mostrar que \\[\\lim_{\\phi\\rightarrow\\infty}p(x|\\phi)=\\frac{e^{-\\mu}\\mu^x}{x!}\\] ou seja, o modelo Poisson também pode ser vist como um caso limite do binomial negativo.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html#priori-para-phi-condicionado",
    "href": "negativeBinomial.html#priori-para-phi-condicionado",
    "title": "15  Binomial negativa",
    "section": "15.2 Priori para \\(\\phi\\) condicionado",
    "text": "15.2 Priori para \\(\\phi\\) condicionado\nQuando \\(\\phi\\) é conhecido, a verossimilhança do modelo se torna\n\\[L(\\rho|\\phi)\\propto \\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i},\\] logo, o modelo Beta\\((a,b)\\) é conjugado, com a posteriori dada por \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi+a,\\sum_{i=1}^n x_i+b\\right).\\]\nA priori de Jeffreys é dada por\n\\[\\pi(\\rho)\\propto \\frac{1}{\\rho(1-\\rho)^{1/2}},\\] o que implica na posteriori \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi,\\sum_{i=1}^n x_i+\\frac{1}{2}\\right).\\]",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html#priori-para-phi",
    "href": "negativeBinomial.html#priori-para-phi",
    "title": "15  Binomial negativa",
    "section": "15.3 Priori para \\(\\phi\\)",
    "text": "15.3 Priori para \\(\\phi\\)\nSeja \\(\\pi(\\phi)\\pi(\\rho)\\) a priori para \\((\\phi,\\rho)\\). Então, teremos que\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}\\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i}\\pi(\\phi)\\pi(\\rho).\\]\nAssumindo qualquer uma das prioris da seção anterior, teremos\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\pi(\\rho|\\phi,\\boldsymbol{x}),\\]\nlogo,\n\\[\\pi(\\phi|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\]\nComo a posteriori de \\(\\phi\\) não é uma distribuição conhecida, precisamos construir um simulador. O algoritmo Metropolis-Hastings é uma boa escolha, uma vez que a constante de proporcionalidade da densidade é desconhecida.\n\nAlgoritmo Metropolis-Hastings\nO Metropolis-Hastings simula se utiliza de uma distribuição que sabemos simular (denominada proposta) para gerar uma cadeia de Markov cuja distribuição estacionária é a distribuição de interesse.\nNa \\(j\\)-ésima itereção, a simulação do valor proposto \\(\\phi^*\\) é baseada no valor atual da cadeia, \\(\\phi^{(j-1)}\\). Como \\(\\phi&gt;0\\), a proposta \\(\\phi^*\\sim \\hbox{Gamma}(\\tau\\phi^{(j-1)},\\tau)\\) é adequada uma vez que \\[E(\\phi^*)=\\phi^{(j-1)}\\] e \\[\\sqrt{Var(\\phi^*)}=\\frac{\\phi^{(j-1)}}{\\tau}\\] Acima, \\(\\tau\\) é denominado tunning (afinação em tradução livre) e deve ser escolhido para que a cadeia tenha o número de aceites da proposta controlado (algo em torno de 23% ).\nAbaixo, segue o algoritmo\n\nFaça \\(j=0\\) e escolha um valor para \\(\\phi^{(0)}\\) (a estimativa de máxima verossimilhança, por exemplo). Faça um contador de aceites, começando com \\(k=0\\).\nPara o passo \\(j\\):\n\n\nSimule \\(\\phi^*\\sim\\hbox{Gama}(\\tau\\phi^{j-1},\\tau)\\)\nCalcule\n\n\\[prob = \\frac{\\pi(\\phi^*|\\boldsymbol{x})}{\\pi(\\phi^{(j-1)}|\\boldsymbol{x})}\\frac{g(\\phi^{(j-1)}|\\tau\\phi^*,\\tau)}{g(\\phi^*|\\tau\\phi^{(j-1)},\\tau)},\\] onde \\(g(.|a,b)\\) é a função densidade do modelo gama. + Simule \\(u\\sim\\hbox{Uniforme}(0,1)\\). Se \\(u&lt;prob\\), faça \\(\\phi^{(j)}=\\phi^*\\) e \\(k=k+1\\) (houve um aceite). Senão, faça \\(\\phi^{(j)}=\\phi^{(j-1)}\\).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  }
]