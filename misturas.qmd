# Misturas de distribuições

Dizemos que a função densidade/probabilidade de $X\sim f(.)$ é uma mistura de distribuições se existe uma variável $Z$ tal que

$$f(x)=\int f(x|z)f(z)dz.$$

A variável $Z$ é denominada latente e a função $f(x,z)$ é denominada modelo aumentado.

Seja $(X_1,Z_1),\ldots,(X_n,Z_n)$ uma amostra aleatória do modelo aumentado $f(x,z|\theta)$ e seja $f(\theta)$ a priori para $\theta$. Existem situações nas quais é mais fácil simular da distribuição do modelo
$$f(\theta,\boldsymbol{z}|\boldsymbol{x})\varpropto f(\boldsymbol{x},\boldsymbol{z}|\theta)f(\theta).$$

Em particular, se é fácil simular das condicionais completas, podemos utilizar o Amostrador de Gibbs, que consiste no seguinte algoritmo.

<div class='alert alert-success'>
<strong>Amostrador de Gibbs</strong>

Inicie a cadeia com fazendo $j=0$ e escolhendo $\theta^{(0)}$

No $j$-ésimo passo:

1. Simule $\boldsymbol{z^{(j)}}\sim f(\boldsymbol{z}|\boldsymbol{x},\theta^{(j-1)})$

2. Simule $\theta^{(j)}\sim f(\theta|\boldsymbol{z}^{(j)},\boldsymbol{x})$

</div>

O Amostrador de Gibbs é uma cadeia de Markov cuja distribuição estacionária é $f(\theta,\boldsymbol{z}|\boldsymbol{x})$


## O modelo t-Student como uma mistura normal-gama

A função densidade do modelo t-Student é dada por
$$f(x|\mu,\phi,\nu)=\frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})}\sqrt{\frac{\phi}{\pi\nu}}\left[1+\frac{\phi}{\nu}\left(x-\mu\right)^2\right]^{-\frac{\nu+1}{2}},$$
onde $x,\mu\in\mathbb{R}$ e $\phi,\nu>0$. Se $\nu>1$, então $E(X)=\mu$ e se $\nu>2$, $Var(X)=\nu/(\phi(\nu-2))$.

Considere que $X|Z,\mu,\phi\sim\hbox{Normal}(\mu,(z\phi)^{-1})$ e $Z\sim\hbox{Gama}(\nu/2,\nu/2)$. Então 

$$\begin{align}
f(x|\mu,\phi,\nu)&=\int_0^\infty f(x|z,\mu,\phi)f(z|\nu)dz=\int_0^\infty \sqrt{\frac{\phi z}{2\pi}}e^{-\frac{z\phi}{2}(x-\mu)^2}\frac{(\nu/2)^{\nu/2}}{\Gamma(\nu/2)}z^{\frac{\nu}{2}-1}e^{-\frac{\nu}{2}z}dz\\
&=\sqrt{\frac{\phi}{2\pi}}\frac{(\nu/2)^{\nu/2}}{\Gamma(\nu/2)}\int_0^\infty z^{\frac{\nu+1}{2}-1} \exp\left\{-z\frac{\nu}{2}\left[1+\frac{\phi}{\nu}(x-\mu)^2\right]\right\}dz\\
&=\frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})}\sqrt{\frac{\phi}{\pi\nu}}\left[1+\frac{\phi}{\nu}\left(x-\mu\right)^2\right]^{-\frac{\nu+1}{2}}.
\end{align}$$

Portanto, a distribuição normal-gama é uma mistura para a $t$-Student e a verossimilhança aumentada para este modelo é

$$\begin{align}L(\mu,\phi,\nu)&=\prod_{i=1}^n f(x_i|z_i,\mu,\phi)f(z|\nu)= \prod_{i=1}^n \sqrt{\frac{\phi z_i}{2\pi}}e^{-\frac{z_i\phi}{2}(x_i-\mu)^2}\frac{(\nu/2)^{\nu/2}}{\Gamma(\nu/2)}z_i^{\frac{\nu}{2}-1}e^{-\frac{\nu}{2}z_i}\\
\end{align}$$

Considerando que $\mu|\phi \sim\hbox{Normal}(m,(\lambda\phi)^{-1})$, $\phi\sim\hbox{Gama}(n_0/2,s_0/2)$ temos a seguinte posteriori baseada no modelo aumentado:

$$f(\mu,\phi,\nu|\boldsymbol{x})\propto \left[\prod_{i=1}^n \sqrt{\frac{\phi z_i}{2\pi}}e^{-\frac{z_i\phi}{2}(x_i-\mu)^2}\frac{(\nu/2)^{\nu/2}}{\Gamma(\nu/2)}z_i^{\frac{\nu}{2}-1}e^{-\frac{\nu}{2}z_i}\right]\times \phi^{1/2}e^{-\frac{\lambda}{2} \phi(\mu-m)^2}\times\phi^{\frac{n_0}{2}-1}e^{-\frac{s_0}{2}\phi}\times f(\nu)$$
Pode-se mostrar que

$$\begin{align}\mu|\hbox{resto}&\sim\hbox{Normal}\left(\frac{\sum_{i=1}^n z_i x_i+\lambda m}{\lambda+\sum_{i=1}^n z_i},\left[\phi\left(\lambda+\sum_{i=1}^{n}z_i\right)\right]^{-1}\right)\\
\phi|\hbox{resto}&\sim\hbox{Gama}\left(\frac{n+n_0+1}{2},\frac{1}{2}\left[s_0+\lambda(\mu-m)^2+\sum_{i=1}^n z_i(x_i-\mu)^2\right]\right)\\
z_i|\hbox{resto}&\sim\hbox{Gama}\left(\frac{\nu+1}{2},\frac{\phi(x_i-\mu)^2+\nu}{2}\right)\end{align}$$

A condicional completa para $\nu$ é dada por
$$f(\nu|\hbox{resto})\propto \frac{(\nu/2)^{n\nu/2}}{\Gamma(\nu/2)^n}\left(\prod_{i=1}^n z_i\right)^{\frac{\nu}{2}-1}e^{-\frac{\nu}{2}\sum_{i=1}^nz_i}f(\nu)$$

Observe que a condicional completa para $\nu$ não possui um núcleo conhecido. Para facilitar a simulação, podemos considerar que o espaço paramétrico de $\nu$ é uma coleção com $M<\infty$ pontos. Então, teremos que
$$f(\nu_0|\hbox{resto})\approx P(\nu=\nu_0|\hbox{resto})\propto \frac{(\nu_0/2)^{n\nu_0/2}}{\Gamma(\nu_0/2)^n}\left(\prod_{i=1}^n z_i\right)^{\frac{\nu_0}{2}-1}e^{-\frac{\nu}{2}\sum_{i=1}^nz_i}f(\nu_0)$$
e podemos utilizar o simulador `sample` do `R`. Estudos sugerem que a priori escolhida deve favorecer valores baixos para $\nu$. Vamos utilizar a priori $\nu\sim\hbox{Exponencial}(r_0)$


<div class='alert alert-info'>
**Volatilidade no mercado financeiro**

Considere que você tem uma empresa e deseja atrair investimento. Um modo bastante tradicional é encontrar um sócio para injetar dinheiro. Por sua vez, o sócio passa a ser dono de parte da empresa. Essa é a ideia por trás das ações. Parte da empresa é fatiada em partes denominadas ações, que são negociadas na bolsa de valores. Qualquer indivíduo com uma ação é dono de uma fração da empresa. Se a empresa cresce, seu valor cresce e aquela fração correspondente à ação passa a valer mais. Se a empresa entre em crise, ação passa a valer menos.

Contudo, o preço não está baseado apenas no quanto a empresa vale no momento, mas como os milhares de donos estão se sentindo no momento com relação à ela. Caso os acionistas acreditem que a empresa vai perder valor, eles podem começar a vender suas ações. Com o aumento oferta, o preço cai. Se por outro lado o mercado acredita que a empresa vai aumentar seu lucro, os pedidos por compra no mercado aumentam e os donos das ações evitam negociá-las, criando uma demanada maior que a oferta e aumentando o preço do ativo.

Portanto, o preço das ações está associado às oscilações de humor do mercado. Neste sentido, a variabilidade do preço é uma medida fundamental e é denominada volatilidade. 

Existem várias maneiras de medir a volatilidade. Para o nosso exemplo, seja $p_t$ o preço de fechamento da ação no dia $t$. Calculamos o log retorno da ação no dia $t$ como  

$$x_t=\log(p_t)-\log(p_{t-1}).$$
O cálculo do log-retorno é útil para remover a tendência do preço. Isso ocorre porque a tendência de $\log(p_t)$ tende a ser localmente linear. Desse modo, é esperado que $E(x_t)$ esteja próximo de zero. É importante saber que, embora $x_1,\ldots,x_n$ sejam não correlacionados, em geral eles são dependentes e não são identicamente distribuídos. Contudo, mesmo que $x_1,\ldots,x_n$ sejam dependentes e não identicamente distribuídos, o modelo t-Student costuma apresentar um bom ajuste, especialmente devido à sua capacidade de capturar caudas pesadas.

Para o mercado financeiro, o desvio padrão do log retorno é denominado volatidade (ou volatilidade total), ou seja,

$$\hbox{volatidade}=\sigma\sqrt{\frac{\nu}{\nu-2}}$$
O parâmetro $\sigma=1/\sqrt{\phi}$ da distribuição $t$-Student é interpretado como  volatilidade basal ou o fator de escala da dispersão dos retornos. Ele representa a magnitude "típica" das flutuações, enquanto o parâmetro $\nu$ informa sobre a frequência e a intensidade dos eventos de cauda (denominados "shocks", no jargão do mercado).

Um $\sigma$ maior significa que, mesmo sem considerar as caudas, os retornos tendem a se espalhar mais. Quando combinado com um $\nu$ baixo, isso indica um ativo que não só tem flutuações grandes, mas também é propenso a flutuações muito grandes e muito pequenas com maior frequência.

Vamos analisar os log-retornos diários da Magazine Luiza (MGLU) entre 06/06/2024 e  04/06/2025

```{r}
require(gsheet)
url_mglu <- 'https://docs.google.com/spreadsheets/d/1dnxASqmPoOPo0MTeY_NoYmkhK8yZDlWPaACGrLhLgHI/edit?usp=sharing'

dados <- gsheet2tbl(url_mglu)
head(dados)
```

Observe que os dados estão organizados com os fechamentos mais recentes aparecendo primeiro. Vamos calcular os log-retornos.

```{r}
fechamento = as.numeric(dados$Último)
n = length(fechamento)
fechamento = fechamento[n:1]

magalu <- diff(log(fechamento))
hist(magalu, freq= FALSE, main='Log-retorno MGLU3')
lines(density(magalu), lwd = 2)
ts.plot(magalu,main ='Log-retornos por dia')
```

Vamos estimar a volatilidade basal e os graus de liberdade para estes dados. Vamos considerar $\lambda=n_0=s_0=0,01$, $r_0=1$ e $m=0$. Para os valores possíveis dos graus de liberdade, vamos considerar os conjunto $\{0.5, 0.75, 1, 1.25,\ldots,40\}$.

```{r}
x = magalu
n = length(x)
B = 5000
# valores possiveis para nu
nu_seq = seq(.5,40,.25)

# hiperparâmetros
l = .01
m = 0 
n0 = 0.01
s0 = 0.01
r0 = 1

# valores iniciais
nu = .5
mu = 0
z = rep(1,n) 
phi = 1

for(i in 1:B){
  
  # mu dado o resto
  media = (sum(z*x)+l*m)/( l + sum(z))
  desvio = 1/sqrt(phi[i]*( l + sum(z)))
  mu[i+1] = rnorm(1, media, desvio )
  
  # phi dado o resto
  alfa = (n+n0+1)/2
  beta = .5*( s0 + l*(mu[i+1] - m)^2 + sum( (x-mu[i+1])^2 ) )
  phi[i+1] = rgamma(1, alfa, beta)
  
  # z_i dado o resto
  alfa = .5*(nu[i]+1)
  beta = .5*(phi[i+1]*(x-mu[i+1])^2 + nu[i]) 
  z = rgamma(n, alfa, beta )
  
  # nu dado o resto
  log_p = .5*n*nu_seq*log(nu_seq/2) - n*lgamma(nu_seq/2)+.5*nu_seq*sum(log(z))-.5*nu_seq*sum(z)- nu_seq*r0
  nu[i+1] = sample(nu_seq,1,T,exp(log_p-max(log_p)))
}

mu_magalu  = mu[seq(B/2,B,15)]
nu_magalu  = nu[seq(B/2,B,15)]
vol_magalu = 1/sqrt(phi[seq(B/2,B,15)])
```
Abaixo, apresentamos os traços e a autocorrelação para as amostros da posteriori para $\nu$ e $\sigma=1/\sqrt{\phi}$, após o *burn-in* e o $thinning$.

```{r}
oo = par( mfrow=c(2,2))
ts.plot(nu_magalu, main='Traço para os graus de liberdade')
acf(nu_magalu, main='Autocorrelação para os graus de liberdade')
ts.plot(vol_magalu, main='Traço para a volatilidade')
acf(vol_magalu, main='Autocorrelação para a volatilidade')
par(oo)
```

Com a amostra a posteriori simulada, podemos simular amostras da preditiva a posteriori. Podemos então construir um intervalo de predição para a função de distribuição empírica da preditiva a posteriori e compará-lo com a distribuição empírica dos dados. O gráfico abaixo mostra que o modelo é adequado.


```{r}
y_pred <- array(NA_real_, c(length((nu_magalu)), n))
for(i in 1:length((nu_magalu))){
  y_pred[i,] <- mu_magalu[i] + rt(n, nu_magalu[i])*vol_magalu[i]
}

Fd_sim = apply(y_pred,1, function(y){
  Fd = ecdf(y)
  Fd(sort(x))
})

qq = apply(Fd_sim,1, function(x) quantile(x,c(.025,.977)))

plot(ecdf(x), main = '')
lines(sort(x),qq[1,], col =2)
lines(sort(x),qq[2,], col =2)
```

Portanto, temos que a volatilidade basal estimada para o log-retorno diário da Magazine Luiza durente o intervalo de estudo foi  0,04 (ou 4%), o que é considerado elevado. Os graus de liberdade foram estimados em 7,3. Este resultado era esperado, pois o setor varejista de e-commerce está sujeito as oscilações de taxas de juros, inflação, poder de compra do consumidor. Além disso, pode-se somar a forte concorrência e o endividamento atual da empresa

```{r}
mean(vol_magalu)
```


Para ilustrar melhor estes  conceitos, vamos repetir a análise para a empresa Engie Brasil Energia (EGIE3). Espera-se menos volatilidade, uma vez que empresas do setor elétrico geralmente têm receitas mais previsíveis, regulamentação estável e são consideradas "defensivas".

```{r}
url_egie <- 'https://docs.google.com/spreadsheets/d/1qvv5RC5U5L-5snoz_QyzXB2v_etOMChBViypnl4XYMk/edit?usp=sharing'
dados2 <- gsheet2tbl(url_egie)
fechamento2 = as.numeric(dados2$Último)
n = length(fechamento2)
fechamento2 = fechamento2[n:1]

egie <- diff(log(fechamento2))
plot(density(egie), main = 'Log-retornos diários',xlim=c(-.2,.2))
lines(density(magalu),col =2)
legend('topleft',c('Magalu','Egie'), col=2:1, lwd = 1, bty = 'n')
``` 

```{r echo = FALSE}
x = egie
n = length(x)
B = 5000
# valores possiveis para nu
nu_seq = seq(.5,40,.25)

# hiperparâmetros
l = .01
m = 0 
n0 = 0.01
s0 = 0.01
r0 = 1

# valores iniciais
nu = .5
mu = 0
z = rep(1,n) 
phi = 1

for(i in 1:B){
  
  # mu dado o resto
  media = (sum(z*x)+l*m)/( l + sum(z))
  desvio = 1/sqrt(phi[i]*( l + sum(z)))
  mu[i+1] = rnorm(1, media, desvio )
  
  # phi dado o resto
  alfa = (n+n0+1)/2
  beta = .5*( s0 + l*(mu[i+1] - m)^2 + sum( (x-mu[i+1])^2 ) )
  phi[i+1] = rgamma(1, alfa, beta)
  
  # z_i dado o resto
  alfa = .5*(nu[i]+1)
  beta = .5*(phi[i+1]*(x-mu[i+1])^2 + nu[i]) 
  z = rgamma(n, alfa, beta )
  
  # nu dado o resto
  log_p = .5*n*nu_seq*log(nu_seq/2) - n*lgamma(nu_seq/2)+.5*nu_seq*sum(log(z))-.5*nu_seq*sum(z)-nu_seq*r0
  nu[i+1] = sample(nu_seq,1,T,exp(log_p-max(log_p)))
}

mu_egie  = mu[seq(B/2,B,15)]
nu_egie  = nu[seq(B/2,B,15)]
vol_egie = 1/sqrt(phi[seq(B/2,B,15)])
```


A volatilidade basal estimada para a EGIE no período foi de 1,2%. A probabilidade de que esta volatilidade seja menor que a da MGLU é de 0,999, o que corrobora com o esperado. Os graus de liberdade foram estimados em 8,07.

</div>

<div class=alert alert-success>
**A distribuição t-Student multivariada e o estudo de portifólios**

Um portfólio, no contexto financeiro, é um conjunto de investimentos que um indivíduo ou uma instituição possui. Alguns investimentos tendem a reagir de forma semelhante aos humeores do mercado. Por exemplo, considerando os log-retornos diários do Banco do Brasil (BBSA3) e Itaú Unibanco (ITUB4) no ano de 2024, temos uma correlação de 0,18. Portanto, se dois ativos dentro do portifólio são correlacionados, o risco deveria aumentar.

Podemos relacionar a distribuição t-Student$_{\nu}(\boldsymbol{\mu},\Phi^{-1})$ ($p$ multivariada) como a seguinte mistura:

$$\begin{align}\boldsymbol{x}|z,\boldsymbol{\mu},\Phi&\sim \hbox{Normal}_p(\boldsymbol{\mu},z^{-1}\Phi^{-1})\\z&\sim\hbox{Gama}\left(\frac{\nu}{2},\frac{\nu}{2}\right)\end{align}$$
Considerando uma amostra $\boldsymbol{x}_1,\ldots,\boldsymbol{x}_n$ eas prioris $\boldsymbol{\mu}|\Phi\sim\hbox{Normal}_p(\boldsymbol{m}_0,\lambda^{-1}\Phi^{-1})$, $\Phi\sim\hbox{Wishart}(n_0,S_0)$ e $\nu\sim\hbox{Exponencial}(r_0)$, temos as seguintes condicionais completas:

$$\begin{align}\boldsymbol{\mu}|\hbox{resto}&\sim\hbox{Normal}_p\left(\frac{\sum_{i=1}^n z_i\boldsymbol{x}_i+\lambda\boldsymbol{m}_0}{\lambda+\sum_{i=1}^n z_i},\Phi^{-1}/(\lambda + \sum_{i=1}^n z_i)\right)\\\Phi|\hbox{resto}&\sim\hbox{Gama}\left(n+n_0+1,[S_0^{-1}+\lambda(\boldsymbol{\mu}-\boldsymbol{m}_0)(\boldsymbol{\mu}-\boldsymbol{m}_0)'+\sum_{i=1}^n z_i(\boldsymbol{x}_i-\boldsymbol{\mu})(\boldsymbol{x}_i-\boldsymbol{\mu})']^{-1}\right)\\
z_i|\hbox{resto}&\sim\hbox{Gama}\left(\frac{\nu+p}{2},\frac{\nu+(\boldsymbol{x}_i-\boldsymbol{\mu})'\Phi(\boldsymbol{x}_i-\boldsymbol{\mu})}{2}\right)\\
f(\nu|\hbox{resto})&\propto \left(\frac{\nu}{2}\right)^{\frac{n\nu}{2}}\frac{1}{\Gamma(\nu/2)^n}\left(\prod_{i=1}^n z_i\right)^{\frac{\nu}{2}}e^{-\nu(r_0+\frac{1}{2}\sum_{i=1}^n z_i)}
\end{align}$$

Seja $p$ o número de ações dentro do portifólio e seja $w_i$ a proporção da $i$-ésima ação dentro do portifólio. Então $\Phi$ pode ser utilizada para os seguintes fins:

* Cálculo da volatilidade do portifólio:

$$\sigma_p=\sqrt{\boldsymbol{w}'\Phi^{-1}\boldsymbol{w}}$$

* Cálculo do portifólio ótimo: a melhor composição da proporção das ações dentro do portifólio é dada por

$$\boldsymbol{w}=\Phi\boldsymbol{1}_p$$
e a respectiva volatilidade por portifólio é dada por
$$\sigma_p=\sqrt{\textbf{1}_p'\Phi \textbf{1}_p}$$


* Relação entre ações: uma estratégia protetiva é a diversificação de ativos. Isto porque ativos diversos tendem a se comportar de modo diferente com os humores do mercado, protegendo o capital de eventuais crises. um grafo de dependências condicionais utilizando $\Phi$ pode ser contruído para verificar a denpendência entre as ações. Isto é útil para proteção de capital.

</div>

## Modelos com inflação de zeros

Quando são observados mais zeros do que o esperado pelo modelo de contagem assumido para a verossimilhança, é usual considerar um modelo com inflação de zeros. Nesse tipo de modelo, assumimos que existe uma variável latente $Z|p\sim\hbox{Bernoulli}(\rho)$ tal que:

$$X=\left\{\begin{array}{ll}0, & \hbox{se }Z=1\ \\ Y,&\hbox{se }Z=0\end{array}\right.$$
onde $Y\sim h(.|\theta)$ é o modelo de contagem. Seja $f(.|\theta,\rho)$ a função de probabilidade de $X$. Então 

$$\begin{align}f(0|\theta,\rho)&=\sum_{z=0}^1 P(X=0|Z=z,\theta)P(Z=z|\rho)\\&=(1-\rho)h(0|\theta)+\rho\end{align}$$
a probabilidade de observar um zero está entre $h(0|\theta)$ e 1, o que caracteriza a inflação.

Agora, considere um modelo inflacionado de zeros aumentado:

$$f(x,z|\theta,\rho)=f(x|z,\theta)f(z|\rho)=f(x|z,\theta)\rho^z(1-\rho)^{1-z}.$$
Note que 

$$f(x|z,\theta)=\left\{
\begin{array}{ll}
h(x|\theta),&\hbox{ se }z=0,\\
I(x=0),&\hbox{ se }z=1\\
\end{array}\right.$$
logo, a distribuição conjunta $f(x,z|\theta,\rho)$ é dada por 



$$\begin{array}{c|cc}\hline & x=0 & x> 0 \\ \hline
z=0 & h(0|\theta)(1-\rho) & h(x|\theta)(1-\rho) \\
z=1 & \rho & 0 \\ \hline
\end{array}
$$
Então,

$$\begin{align}
\prod_{i=1}^n f(x_i,z_i|\theta,\rho)&=\prod_{i=1}^n [h(0|\theta)(1-\rho)]^{I(x_i=0,z_i=0)}[h(x_i|\theta)(1-\rho)]^{I(x_i>0,z_i=0)}\rho^{I(x_i=0,z_i=1)}\\
&=\prod_{i=1}^n [h(x_i|\theta)(1-\rho)]^{I(z_i=0)}\rho^{I(x_i=0,z_i=1)}\\
&=\prod_{i=1}^n(1-\rho)^{I(z_i=0)}\rho^{I(x_i=0,z_i=1)}\prod_{i=1}^n [h(x_i|\theta)]^{I(z_i=0)}\end{align}$$
e, notando que $I(z_i=0)=1-z_i,$

$$\begin{align}
\prod_{i=1}^n f(x_i,z_i|\theta,\rho)&=
(1-\rho)^{n-\sum_{i=1}^n z_i}\rho^{\sum_{i=1}^n z_iI(x_i=0)}\prod_{i=1}^n [h(x_i|\theta)]^{1-z_i}\end{align}$$

Considere, a priori, que $\theta$ e $\rho$ são independentes. Seja $\pi(\theta)$ a função de densidade/probabilidade a priori para $\theta$ e considere que $\rho\sim\hbox{Beta}(a,b)$. Então, as condicionais completas para $\theta$ e $\rho$ são

$$\begin{align}
f(\theta|\rho,\boldsymbol{z},\boldsymbol{x})&\propto \prod_{i=1}^n h(x_i|\theta)^{1-z_i}\pi(\theta),\\
f(\rho|\theta,\boldsymbol{z},\boldsymbol{x})&\propto \rho^{\sum_{i=1}^n z_iI(x_i=0)+a-1}(1-\rho)^{n-\sum_{i=1}^n z_i+b-1},\\
\end{align}$$

Para a condicional completa de $z_i$, notemos que 
$$P(Z_i=1|x_i>0)=\frac{P(Z_i=1,X_i>0)}{P(X_i>0)}=0,$$
e que 

$$P(Z_i=z|x_i=0)= \left\{\begin{array}{ll}\frac{P(Z_i=0,X_i=0)}{P(X_i=0)}=\frac{h(0|\theta)(1-\rho)}{\rho+(1-\rho)h(0|\theta)},&,z=0\\
\frac{P(Z_i=1,X_i=0)}{P(X_i=0)}=\frac{\rho}{\rho+(1-\rho)h(0|\theta)},&z=1\end{array}\right.,$$
logo
$$f(z_i|\theta,\rho,\boldsymbol{x},\boldsymbol{z}_{(-i)})=\left\{\begin{array}{ll}\hbox{Bernoulli}\left( \frac{\rho}{\rho+(1-\rho)h(0|\theta)}\right),&\hbox{ se }x_i=0\\
I(z_i=0),&\hbox{ se } x_i>0\\ \end{array}\right.$$

Portanto, um amostrador de Gibbs para um modelo inflacionado de zeros é

<div class='alert alert-success'>
<strong>Amostrador de Gibbs para o modelo inflado de zeros</strong>

Faça $j=0$ e dê os valores iniciais $\theta^{(0)}$ e $\rho^{(0)}$. 

No $j$-ésimo passo:

1. Para $i\in\{1,\ldots,n\}$, se $x_i>0$ faça $z_i=0$. Senão, simule
$$z_i^{(j)}\sim \hbox{Bernoulli}\left(\frac{\rho^{(j-1)}}{\rho^{(j-1)}+(1-\rho^{(j-1)})h(0|\theta^{(j-1)})}\right)$$ 

2. Simule $$\rho^{(j)}\sim\hbox{Beta}(a+\sum_{i=1}^n z_i^{(j)}I(x_i=0),b+n-\sum_{i=1}^n z_i^{(j)})$$

3. Simule $\theta^{(j)}$ de 
$$f(\theta|\rho^{(j)},\boldsymbol{z}^{(j)},\boldsymbol{x})\propto \prod_{i=1}^n h(x_i|\theta)^{1-z_i^{(j)}}\pi(\theta).$$
</div>

<div class='alert alert-info'>
<strong>Exemplo - O modelo Poisson inflado de zeros </strong>


Neste exemplo, vamos considerar que a distribuição da contagem é Poisson($\theta$) e que $\theta\sim\hbox{Gama}(r,s)$. Então,

$$\begin{align}
f(\theta|\rho^{(j)},\boldsymbol{z}^{(j)},\boldsymbol{x})&\propto \prod_{i=1}^{n} h(x_{i} | \theta )^{ 1-z_{i}^{(j)} }\pi(\theta)\\&= 
 \prod_{i=1}^{n} \left[\frac{ e^{-\theta}\theta^{x_i} }{x_i!}\right]^{1-z_{i}^{(j)}}\frac{s^r}{\Gamma(r)}\theta^{r-1} e^{-s\theta}\\&\propto \theta^{\sum_{i=1}^n x_i(1-z_i^{(j)})+r-1}e^{-(n-\sum_{i=1}^n z_i^{(j)}+s)\theta}
 \end{align},$$

ou seja, $$\theta^{(j)}|\rho^{(j)},\boldsymbol{z}^{(j)},\boldsymbol{x}\sim\hbox{Gama}(\sum_{i=1}^n x_i(1-z_i^{(j)})+r,n-\sum_{i=1}^n z_i^{(j)}+s)$$
 
</div>

<div class='alert alert-info'>
**Exemplo. Número anual de furacões grandes**

Os dados abaixo representam o número anual de furacões atlânticos grandes (categoria 4 ou 5) entre 1987 e 2012, nos Estados Unidos.

```{r}

fur <-  c(0, 0 ,1,
0, 0, 1, 0, 0, 1, 0, 0, 2, 2,
0, 0, 1, 1, 3, 4, 0, 0, 2, 0,
0, 0, 0)
```

A frequência relativa de zeros é 0,58. Considerando o modelo Poisson$(\theta)$ com $f(\theta)\propto \theta^{-1}$, apresentamos abaixo o gráfico da frequência relativa com a respectiva probabilidade preditiva a posteriori. Observe que o modelo falha em capturar a probabilidade de zero, indicando que o modelo Poisson é inadequado para estes conjunto de dados.

```{r echo = F}
r1 <- sum(fur)
s1 <- n <- length(fur)
plot(table(fur)/s1, type= 'p', xlab='No. anual de furacões atlânticos nos Estados Unidos', ylab = 'Probabilidade', col = 'cyan3', pch=16)
lines(0:4,table(fur)/s1, col = 'cyan3')
points(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), pch=16, col = 'brown')
lines(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), col = 'brown')

legend('bottomleft',c('Freq. relativa','Pred. post. Poisson'), fill=c('cyan3','brown'), bty='n')
```

Abaixo, implementamos o amostrador de Gibbs para o modelo Poisson Inflado de zeros. Consideramos as densidades a priori $\rho\hbox{Beta}(1,1)$ e $\theta\sim\hbox{Gama}(.1,.1)$.

```{r}

# hiperparâmetros para rho
a = b = 1

# hiperparâmetros para theta
r=.1
s=.1

# tamanho da amostra
n <- length(fur) 

# valores iniciais da cadeia
theta <- mean(fur)
rho <- mean(fur == 0)

# amostrador de Gibbs
B <- 50000
for(i in 1:B){
  # simulando z
  z <- NULL
  prob <- rho[i]/ ( (1-rho[i])*dpois(0,theta[i]) + rho[i])
  for(j in 1:n){
    if(fur[j] >0){ z[j] <- 0} else{
      z[j] <- rbinom(1,1,prob)
    }
  }

  # simulando rho
  rho[i+1] <- rbeta( 1, a + sum( z * (fur == 0)) , n- sum(z)+ b )
  
  # simulando theta
  theta[i+1] <- rgamma(1, sum( fur*(1-z) ) + r,  n - sum(z) + s)
}
```


Vamos descartar a metade das simulações e usar um **thinning** igual a 15:

```{r}
theta_sim <- theta[seq(B/2,B,15)]
rho_sim <- rho[seq(B/2,B,15)]

oo <- par(mfrow=c(2,2))
ts.plot(theta_sim, lwd = 2)
ts.plot(rho_sim, lwd = 2)
acf(theta_sim)
acf(rho_sim)
```

Por último, realizamos algumas simulações da preditiva a posteriori e esstimamos as probabilidades para os pontos mais frequentes. Em seguida, comparamos estes valores com frequência relativa observada. Note que o ajuste deste modelo é adequado para o conjunto de dados.

```{r}
# tamanho do vetor simulado
Bs <- length(theta_sim)

x_til <- array( NA_real_, c(Bs,n))
for(j in 1:Bs){
  z <- rbinom( n, 1, rho_sim[j])
  x_til[j,] <- (1-z)*rpois(n, theta_sim[j])
}

# probabilidades estimadas via ZIP
p_zip <- prop.table(table(x_til))

plot(table(fur)/n, type= 'p', xlab='No. anual furacões atlânticos', ylab = 'Probabilidade', col = 'cyan3', pch=16)
lines(0:4,table(fur)/n, col = 'cyan3')
points(names(p_zip),p_zip, pch=16,col = 'magenta')
lines(names(p_zip),p_zip,col = 'magenta')

legend('bottomleft',c('Freq. relativa','Pred. post. do modelo ZIP'), fill=c('cyan3','brown', 'magenta'), bty='n')
```

</div>

### Exercício

<div class='alert alert-warning'>

Abaixo, segue o número anual de tornados em Lafayette Parish,
Louisiana, entre 1950 e 2012.

```{r}
tor <- c(0, 0,0, 1, 0, 0, 0, 1, 0, 0,
1, 0, 0, 0, 1, 1, 0, 0, 0, 2,
0, 0, 0, 0, 1, 3, 0, 2, 1, 0,
1, 0, 0, 1, 0, 1, 0, 0, 2, 1,
0, 1, 2, 0, 0, 1, 0, 1, 2, 0,
0, 0, 3, 0, 2, 0, 1, 1, 3, 0,
1, 1, 1)
```

* Ajuste o modelo Poisson.

* Ajuste o modelo Poisson inflado de zeros.
</div>

## Mistura escalonada de normais



## Misturas finitas com número


Dizemos que $X|\boldsymbol{\theta},\boldsymbol{p},\kappa$ é um modelo de mistura finito se sua função de densidade/probabilidade é dada por

$$f(x| \boldsymbol{\theta},\boldsymbol{p} ,\kappa )=\sum_{k=1}^\kappa p_k f_k(x|\boldsymbol{\theta}_k).$$

Cada função $f(.|\boldsymbol{\theta}_k)$ é denominada componente da mistura e o número de componentes pode ser desconhecido.

Assim como o modelo com zeros inflacionados, podemos utilizar uma variável latente $\textbf{z}_i|\kappa=(z_{i,1},\ldots,z_{i,\kappa})\sim\hbox{Multinomial}(p_1\ldots,p_\kappa|\sum_{k=1}^\kappa z_{ik}=1)$, obtendo o seguinte modelo aumentado

$$f(x_i|\boldsymbol{\theta},\textbf{z}_i,\kappa)=\prod_{k=1}^\kappa \left[f\left(x_i|\boldsymbol{\theta}_k\right)\right]^{z_{i,k}}$$

A função de verossimilhança aumentada para este modelo é

$$\prod_{i=1}^n f(x_i|\boldsymbol{\theta},\textbf{z}_i,\kappa)=\prod_{i=1}^n\prod_{k=1}^\kappa \left[f\left(x_i|\boldsymbol{\theta}_k\right)\right]^{z_{i,k}}.$$

Considere as prioris $\pi(\boldsymbol{\theta}|\kappa)=\prod_{k=1}^\kappa \pi(\boldsymbol{\theta}_k)$ e $\textbf{p}|\kappa\sim\hbox{Dirichlet}(a_1,\ldots,a_\kappa)$, onde
$$f(\textbf{p}|\kappa)\propto \prod_{k=1}^\kappa p_k^{a_k-1}$$
com $\sum_{k=1}^\kappa p_k=1$. As condicionais completas para este problema são

* $\begin{align}f(\boldsymbol{\theta}_k|resto)\propto \prod_{i:z_{i,k}=1}f(x_i|\boldsymbol{\theta}_k)\pi(\boldsymbol{\theta}_k)\end{align}$

* $\begin{align}f(\textbf{z}_i|resto)\propto \prod_{k=1}^\kappa \left[p_kf(x_i|\boldsymbol{\theta}_k)\right]^{z_{i,k}}\end{align}$
ou seja, $\textbf{z}_i|rest\sim\hbox{Multinomial}(\tilde{p}_1,\ldots,\tilde{p}_\kappa)$, onde

$$\tilde{p}_k=\frac{p_kf(x_i|\boldsymbol{\theta}_k)}{\sum_{k=1}^\kappa p_kf(x_i|\boldsymbol{\theta}_k)}$$
* $f(\textbf{p}|resto)\propto \prod_{k=1}^\kappa p_k^{\sum_{i=1}^n z_{i,k}+a_k-1}$, ou seja $\textbf{p}|resto\sim\hbox{Dirichlet}(a_1+\sum_{i=1}^n z_{i,1},\ldots,a_\kappa+\sum_{i=1}^n z_{i,\kappa})$

Se necessário, podemos atrbuir a priori $$\pi(\kappa)=\frac{1}{M},\kappa=1,2,\ldots,M$$
para obter a condicional completa
$$\pi(\kappa|resto)=\frac{\prod_{i=1}^n\prod_{k=1}^\kappa f(x_i|\boldsymbol{\theta}_k)^{z_{i,k}}\pi(\boldsymbol{\theta}_k)\pi(\textbf{p}|\kappa)\pi(\textbf{z}_i|\kappa)}{\sum_{\kappa=1}^M \prod_{i=1}^n\prod_{k=1}^\kappa f(x_i|\boldsymbol{\theta}_k)^{z_{i,k}}\pi(\boldsymbol{\theta}_k)\pi(\textbf{p}|\kappa)\pi(\textbf{z}_i|\kappa)},\kappa=1,\ldots,M.$$

### O velho fiel


O banco de dados `faithful` mostra a duração e o tempo até a próxima erupção do geiser Velho Fiel, no parque Yellowstone. Abaixo mostramos o diagrama do tempo de espera entre erupções

```{r}
hist(faithful$waiting)
```


É possível notar classes, uma com tempo e entre erupções menor que 70 com tempo maior. Temos as seguintes estimativas iniciais:


```{r}
## elementos na classe 1
x <- faithful$waiting
z <- x < 70
# proporção na classe 1
mean(z)
# média e desvio padrão na classe 1
mean( x[z])
sd( x[z])
```


```{r}
## elementos na classe 2
# proporção na classe 2
mean(z==F)
# média e desvio padrão na classe 2
mean( x[z==F])
sd( x[z==F])
```

Vamos considerar que as duas componentes possuem distribuição normal. Para cada componente, teremos as seguintes prioris:

$$\pi(\mu_i,\phi_i)=\frac{\phi^{1/2}_i}{\sqrt{2\pi C}}e^{-\frac{\phi_i}{2C}(\mu_i-m_i)^2}\frac{b^a}{\Gamma(a)}\phi_i^{a-1}e^{b\phi_i},$$

$$p\sim\hbox{Beta}(r,s)$$

$$z_i\sim\hbox{Bernoulli}(p)$$

O modelo aumentado é
$$f(x_i|\mu,\phi,z_{i})=\left[\frac{\phi_1^{1/2}}{\sqrt{2\pi}}e^{-\frac{\phi_1}{2}(x_i-\mu_1)}\right]^{z_i}\left[\frac{\phi_2^{1/2}}{\sqrt{2\pi}}e^{-\frac{\phi_2}{2}(x_i-\mu_2)}\right]^{1-z_i}$$
As condicionais completas são:



$$\begin{align}f(\mu_1|resto) &\propto \exp\left\{-\frac{\phi_1}{2}\sum_{i=1}^n z_i(x_i-\mu_1)^2\right\}\exp\left\{-\frac{\phi_1}{2C} z_i(\mu_1-m_1)^2\right\}\\&\propto \exp\left\{-\frac{\phi_1}{2}\left(\sum_{i=1}^n z_i+C^{-1}\right) \left(\mu_1-\frac{\sum_{i=1}^{n}x_iz_i+m_1C^{-1}}{\sum_{i=1}^n z_i+C^{-1}}\right)^2\right\}\end{align}$$

$$\begin{align}f(\mu_2|resto) &\propto \exp\left\{-\frac{\phi_2}{2}\sum_{i=1}^n (1-z_i)(x_i-\mu_2)^2\right\}\exp\left\{-\frac{\phi_2}{2C} (1-z_i)(\mu_2-m_2)^2\right\}\\&\propto \exp\left\{-\frac{\phi_2}{2}\left(\sum_{i=1}^n (1-z_i)+C^{-1}\right) \left(\mu_2-\frac{\sum_{i=1}^{n}x_i(1-z_i)+m_1C^{-1}}{\sum_{i=1}^n (1-z_i)+C^{-1}}\right)^2\right\}\end{align}$$


$$\begin{align}f(\phi_2|resto)&\propto \phi_2^{-\frac{1}{2}\sum_{i=1}^{n}z_i}
e^{-\frac{\phi_2}{2}\sum_{i=1}^n (1-z_i)(x_i-\mu_2)^2}\phi^{-1/2}_2e^{-\frac{\phi_2}{2}(\mu_2-m_2)^2}\phi_2^{a/2-1}e^{-\phi_2 b/2}\\ &\propto \phi_2^{\frac{1}{2}(1+a+\sum_{i=1}^{n}(1-z_i)-1}e^{-\frac{\phi_2}{2}[\sum_{i=1}^n(1-z_i)(x_i-\mu_2)^2 +(\mu_2-m_2)^2 + b]}\end{align}$$
$$\begin{align}f(\phi_1|resto)&\propto \phi^{-\frac{1}{2}\sum_{i=1}^{n}z_i}
e^{-\frac{\phi_1}{2}\sum_{i=1}^n z_i(x_i-\mu_1)^2}\phi^{-1/2}e^{-\frac{\phi_1}{2}(\mu_1-m_1)^2}\phi_1^{a/2-1}e^{-\phi_1 b/2}\\ &\propto \phi_1^{\frac{1}{2}(1+a+\sum_{i=1}^{n}z_i)-1}e^{-\frac{\phi_1}{2}[\sum_{i=1}^nz_i(x_i-\mu_1)^2 +(\mu_1-m_1)^2 + b]}\end{align}$$

$$\begin{align}f(p|resto)\propto \prod_{i=1}^n p^{z_i}(1-p)^{1-z_i}p^{r-1}(1-p)^{s-1}\propto p^{r+\sum_{i=1}^n z_i-1}(1-p)^{s+\sum_{i=1}^n (1-z_i)-1}\end{align}$$

$$f(z_i|resto)\propto\left[ p\frac{\phi_1^{1/2}}{\sqrt{2\pi}}e^{-\frac{\phi_1}{2}(x_i-\mu_1)^2}\right]^{z_i}\left[ (1-p)\frac{\phi_2^{1/2}}{\sqrt{2\pi}}e^{-\frac{\phi_2}{2}(x_i-\mu_2)^2}\right]^{1-z_i}$$


Abaixo implementamos o amostrador de Gibbs
```{r}
B <- 50000

# hiperparmametros
m1 <- 65
m2 <- 80
C <- 1000
r= 4; s = 6
a = 1; b = .1

# valores iniciais
z <- x < 70
phi1 <- 1/36
phi2 <- 1/25
mu1 = mu2 =  p = NULL

for(i in 1:B){
  # mu dado o resto
  m1_post <- ( sum(x*z) + m1/C) / ( sum(z) + 1/C )
  m2_post <- ( sum(x*(1-z)) + m1/C) / ( sum(1-z) + 1/C )
  s1_post <- 1 / ( ( sum(z) + 1/C )*phi1[i] )
  s2_post <- 1 / ( ( sum(1-z) + 1/C )*phi2[i] )
  
  mu1[i+1] <- rnorm(1, m1_post, sqrt( s1_post) )
  mu2[i+1] <- rnorm(1, m2_post, sqrt( s2_post) )
  
  # phi dado resto
  phi1[i+1] <- rgamma(1, 1 + a + sum(z), sum( z*(x - mu1[i+1])^2 ) + (mu1[i+1]-m1)^2 + b)
  phi2[i+1] <- rgamma(1, 1 + a + sum(1-z), sum( (1-z)*(x - mu2[i+1])^2 ) + (mu2[i+1]-m2)^2 + b)
  
  # p dado resto
  p[i+1] <- rbeta(1, r + sum(z), s + sum(1-z) )
  
  # z dado resto
  aux1 <- p[i+1]*dnorm(x,mu1[i+1], 1/sqrt(phi1[i+1]))
  aux2 <- (1-p[i+1])*dnorm(x,mu2[i+1], 1/sqrt(phi2[i+1]))
  
  z <- rbinom(length(x), 1, aux1/( aux1 + aux2))
}
# 
```


```{r}
hist(mu1[seq(B/2,B,30)])
hist(mu2[seq(B/2,B,30)])

```

## Exercícios

### Volatilidade individual das ações da B3

As ações são divididas por segmentos. Abaixo mostramos os segmentos e suas principais
ações na bolsa brasileira.

```{r echo = FALSE}
# Criando um data frame com as informações
dados_acoes <- data.frame(
  Setor = c(
    "Financeiro", "Financeiro", "Financeiro", "Financeiro", "Financeiro",
    "Materiais Básicos", "Materiais Básicos", "Materiais Básicos", "Materiais Básicos", "Materiais Básicos",
    "Petróleo, Gás e Biocombustíveis", "Petróleo, Gás e Biocombustíveis", "Petróleo, Gás e Biocombustíveis", "Petróleo, Gás e Biocombustíveis", "Petróleo, Gás e Biocombustíveis",
    "Utilidade Pública", "Utilidade Pública", "Utilidade Pública", "Utilidade Pública", "Utilidade Pública",
    "Consumo Cíclico", "Consumo Cíclico", "Consumo Cíclico", "Consumo Cíclico", "Consumo Cíclico",
    "Consumo Não Cíclico", "Consumo Não Cíclico", "Consumo Não Cíclico", "Consumo Não Cíclico", "Consumo Não Cíclico",
    "Bens Industriais", "Bens Industriais", "Bens Industriais", "Bens Industriais", "Bens Industriais",
    "Tecnologia", "Tecnologia", "Tecnologia", "Tecnologia", "Tecnologia",
    "Saúde", "Saúde", "Saúde", "Saúde", "Saúde",
    "Comunicações", "Comunicações", "Comunicações", "Comunicações", "Comunicações"
  ),
  Ação = c(
    "Itaú Unibanco", "Bradesco", "Banco do Brasil", "B3", "Itaúsa",
    "Vale", "Suzano", "Gerdau", "CSN", "Klabin",
    "Petrobras PN", "Prio", "Petrobras ON", "Vibra Energia", "Cosan",
    "Eletrobras ON", "Engie Brasil", "Cemig", "Taesa", "Sabesp",
    "Lojas Renner", "Magazine Luiza", "Localiza", "CVC Brasil", "Embraer",
    "Ambev", "Raia Drogasil", "JBS", "Assaí", "Hypera Pharma",
    "Weg", "Rumo", "CCR", "Grupo Vamos", "Indústrias Romi",
    "Totvs", "Locaweb", "Intelbras", "Méliuz", "Infracommerce",
    "Rede D'Or", "Hapvida", "Fleury", "Qualicorp", "Hermes Pardini",
    "Telefônica Brasil", "Tim", "Oi", "Unifique", "Brisanet"
  ),
  Ticker = c(
    "ITUB4", "BBDC4", "BBAS3", "B3SA3", "ITSA4",
    "VALE3", "SUZB3", "GGBR4", "CSNA3", "KLBN11",
    "PETR4", "PRIO3", "PETR3", "VBBR3", "CSAN3",
    "ELET3", "EGIE3", "CMIG4", "TAEE11", "SBSP3",
    "LREN3", "MGLU3", "RENT3", "CVCB3", "EMBR3",
    "ABEV3", "RADL3", "JBS3", "ASAI3", "HYPE3",
    "WEGE3", "RAIL3", "CCRO3", "VAMO3", "ROMI3",
    "TOTS3", "LWSA3", "INTB3", "CASH3", "IFCM3",
    "RDOR3", "HAPV3", "FLRY3", "QUAL3", "PARD3",
    "VIVT3", "TIMS3", "OIBR3", "FIQE3", "BRIT3"
  )
)
# # Carregue as bibliotecas necessárias para a visualização
 library(knitr)
 library(dplyr) # Para agrupar e ordenar se desejar

 dados_acoes <- dados_acoes %>%
   arrange(Setor, Ação)

# # Usar kable para renderizar a tabela diretamente no Quarto
# # O 'group_rows' é uma funcionalidade que o kableExtra adiciona para agrupar linhas.
# # Se não quiser o kableExtra, remova as linhas relacionadas a group_rows.

# # Instale kableExtra se não tiver: install.packages("kableExtra")
 library(kableExtra)

 dados_acoes %>%
   group_by(Setor) %>%
   kable("html", caption = "Principais Ações da B3 por Setor") %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
   group_rows(index = table(dados_acoes$Setor)) # Isso agrupa visualmente as linhas por setor
# ```

# Se você preferir uma saída simples em Markdown (sem a funcionalidade de group_rows tão elaborada):
# ```{r}
# library(knitr)
# library(dplyr)

# # ... (coloque o código do data frame dados_acoes que está acima) ...

# # Ordenar por Setor para melhor visualização
# dados_acoes <- dados_acoes %>%
#   arrange(Setor, Acao)

# kable(dados_acoes, format = "markdown", caption = "Principais Ações da B3 por Setor")
# ```

# Se você quiser testar a saída em markdown diretamente no console:
# cat(kable(dados_acoes, format = "markdown", caption = "Principais Ações da B3 por Setor"))
```

Neste exercício vamos explorar a volatilidadde basal dos log-retornos das
ações da B3 utilizando a distribuição $t$-Student. O pacote `rb3` é útil para obter os preços das ações brasileiras O comando abaixo faz o download de todos os dados do ano de 2024.



```{r}
library('rb3')
# coletando os dados da B3 de 2024
df_2024 <- cotahist_get("2024-01-01", "yearly")
dados <- data.frame(df_2024$HistoricalPrices)
```

O ticker da empresa está na coluna `cod_negociacao` e o preço de fechamento na coluna `preco_ult`. Para obter os dados de uma ação específica, basta fazer o filtro na coluna. Por exemplo, a série de preços da Vale pode ser obtida do seguinte modo:

```{r}
vale3 <- dados$preco_ult[ dados$cod_negociacao == 'VALE3' ]
ts.plot(vale3, xlab='Dia',ylab='Preço de fechamento')

```

Obtenha estimativas pontuais e intervalares para a volatilidade basal e para os 
graus de liberdade de cada ação. Crie um diagrama de dispersão, identificando por 
esquemas de cores ou símbolos o segmento das ações. Discua quais ações e quais seguimentos são menos arriscados. Faça intervalos de credibilidade ou testes de hipóteses para corroborar sua discussão.

### Análise de um portifólio

Utilizando as ações dadas no exemplo anterior.

1. Para cada setor, calcule a volatilidade do portifólio ótimo.

2. Calcule a volatlidade do portifólio ótimo utilizando todos os setores. 

3. Ainda utilizando todo os setores, faça um grafo de dependências condicionais

4. Procure por ações com baixa volatilidade e  sem relações diretas. Contrua seu próprio portifólio, misturando ações de diferentes segmentos.

5. Calcule a volatilidade do seu portifólio e compare com a volatilidade geral e a volatlidade por segmentos.
 
