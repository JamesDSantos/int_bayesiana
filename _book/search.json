[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "int_bayesiana",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html#notação",
    "href": "intro.html#notação",
    "title": "1  Aula 1 - Introdução",
    "section": "1.1 Notação",
    "text": "1.1 Notação\nVariáveis aleatórias cujo valor podem ser observados serão denotadas por letras maiúsculas. Exemplos:\n\n\\(X\\) é número de acidentes diários na Avenida Torquato Tapajós\n\\(Y\\) é o nível máximo diário do Rio Negro\n\nValores observados de variáveis aleatórias serão denotados pela respectiva letra minúscula.\nParâmetros serão considerados aleatórios, mas serão representados por letras gregas minúsculas, como \\(\\theta\\), \\(\\lambda\\), etc.\nVetores aleatórios serão representados por letras em negrito. Exemplos:\n\n\\(\\mathbf{X} = \\{X_1 , \\ldots , X_n \\}\\) é um vetor de variáveis aleatórias.\n\\(\\mathbf{x} = \\{x_1 ,\\ldots , x_n \\}\\) é um vetor observado de variáveis aleatórias.\n\\(\\theta=\\{\\alpha,\\beta\\}\\) é um vetor de parâmetros.\n\n\nDefinition 1.1 O suporte de uma variável aleatória é o conjunto de todos os seus possíveis valores. Quando necessário, o suporte de variáveis aleatórias são representada pela versão caligráfica de sua letra correspondente.\nExemplos: o suporte de \\(X\\) é \\(\\mathcal{X}\\) ; o suporte de Y é \\(\\mathcal{Y}\\) ; o suporte de \\(Z\\) é \\(\\mathcal{Z}\\).\n\n\nDefinition 1.2 O espaço paramétrico é o conjunto de todos os possíveis valores do parâmetro. Eles são representados pela versão maiúscula da letra grega utilizada para seu respectivo parâmetro.\nExemplo: o espaço paramétrico do parâmetro \\(\\theta\\) é representado por \\(\\Theta\\).\n\nTanto a função de densidade quanto a de probabilidade serão denotadas por funções começando com letras minúsculas. Por exemplo,\n\\[f(x|\\lambda)=\\lambda e^{-\\lambda x}\\] onde \\(x,\\lambda&gt;0\\) é a densidade da distribuição exponencial, enquanto que\n\\[p(x|\\lambda)=\\frac{e^{-\\lambda}\\lambda^x}{x!}\\] com \\(x\\in\\mathbb{N}\\) e \\(\\lambda &gt;0\\) é a é a função de probabilidade da distribuição Poisson."
  },
  {
    "objectID": "intro.html#fontes-de-informação",
    "href": "intro.html#fontes-de-informação",
    "title": "1  Aula 1 - Introdução",
    "section": "1.2 Fontes de informação",
    "text": "1.2 Fontes de informação\n\n1.2.1 A função de verossimilhança\nSeja \\(\\mathbf{x} = \\{x_1 , \\ldots , x_n \\}\\) uma amostra observada. Supomos que \\(\\mathbf{x}\\) é uma das possíveis amostras das variáveis aleatórias \\(\\mathbf{X} = \\{X_1 , \\ldots , X_n \\}\\). Supomos ainda que \\(X\\sim F (.|\\theta)\\). Assim, condicionada ao conhecimento de \\(\\theta\\), a distribuição da amostra está completamente especificada.\n::: {#def-Funcao de verossimilhanca} Para \\(\\mathbf{x}\\) fixado, a função \\[L:\\Theta\\Rightarrow [0,\\infty)\\] é denominada verossimilhança. :::\nSua interpretação é a seguinte: para \\(\\theta_1,\\theta_2\\in\\Theta\\), se\n\\[L(\\theta_1)&gt;L(\\theta_2),\\] dizemos que \\(\\theta_1\\) é mais verossímil que \\(\\theta_2\\). Isto porque a probabilidade de observar uma amostra na vizinhança de \\(\\mathbf{x}\\) é maior se considerarmos que \\(\\theta_1\\) é o valor do parâmetro. A verossimilhança é uma das fontes de informação utilizada na inferência bayesiana (e a única fonte da inferência frequentista).\n\nExample 1.1 Considere uma amostra de 30 variáveis aleatórias independentes com distribuição Poisson(\\(\\theta\\)). Neste caso, a função de verossimilhança será \\[L(\\theta)=\\frac{e^{-30\\theta}\\theta^{\\sum_{i=1}^{30}x_i}}{\\prod_{i=1}^{30}x_i!}.\\] Vamos simular uma amostra de tamanho 30 deste modelo (o valor de \\(\\theta\\) será omisso de propósito)\n\nx &lt;- rpois(30,theta)\nx\n\n [1] 2 4 2 5 6 0 3 5 3 3 6 3 4 3 1 5 2 0 2 6 5 4 3 8 4 4 3 3 2 1\n\n\nA próxima figura mostra os valores da função de verossimilhança para vários valores de \\(\\theta\\) para a amostra observada.\n\n# função de verossimilhança\nvero &lt;- function(q){\n  sapply ( q, function(q) prod(dpois(x, q)) ) \n} \n\n# gráfico da função de verossimilhança\noo &lt;- par( cex = 1.2)\ncurve( vero(x),2,4.5, xlab = expression(theta), ylab = expression( L(theta)) , lwd = 2)\n\n\n\npar(oo)\n\nPodemos notar que o valores mais verossímeis para \\(\\theta\\) estão entre 2 e 4. Podemos ainda procurar o valor mais verossímil, denominado estimativa de máxima verossimilhança (emv). Pode-se mostrar, utilizando cálculo diferencial, que este valor é equivalente à média amostral. Contudo, com o objetivo de utilizar ao máximo o poder computacional que temos disponível, vamos encontrar esse valor utilizando a função optimize.\n\n# menos o logaritmo da função de verossimilhança\nlvero &lt;- function(q) -log( vero(q))\n\n# encontrando a emv:\noptimise(lvero, c(2,4))\n\n$minimum\n[1] 3.399981\n\n$objective\n[1] 60.35731\n\n\nO valor 2,6 é a estimativa de verossimilhança (este é o valor exato da média amotral). Sob o ponto de vista frequentista, esta seria a nossa estiamtiva para o valor de \\(\\theta\\).\n\n\n\n1.2.2 A distribuição a priori\nSob o ponto de vista bayesiano, a informação existente sobre \\(\\theta\\) antes da observação da amostra deve ser levada em consideração. Isto é feito traduzindo tal informação em termos de probabilidades.\n\nDefinition 1.3 A distribuição de \\(\\theta\\) é denominada distribuição a priori.\n\n\nDefinition 1.4 Os parâmetros da distribuição a priori são denominados hiper parâmetros.\n\nAs distribuições a priori : * agregam o conhecimento sobre parâmetro antes da observação da amostra (tal conhecimento pode ter sido gerado de uma amostra prévia). * podem ser muito ou pouco informativas, dependendo do grau de crença sobre os valores em particular do espaço paramétrico. Em geral isto é feito alterando a variância da distribuição:\n\\[\\hbox{variância}=\\frac{1}{\\hbox{precisão}}\\]\n\n\n1.2.3 Reunindo as fontes de informação - distribuição a posteriori\nSejam \\(f(\\bm{\\theta})\\) a densidade/função para \\(\\bm{\\theta}\\) e \\(L(\\bm{\\theta})\\) a função de verossimilhança.\nComo \\(\\bm{\\theta}\\) é considerado aleatório, podemos analisar sua distribuição {} observar a amostra \\(\\bm{x}\\), ou seja \\[\\bm{\\theta}|\\bm{x}.\\]\nEsta distribuição é denominada \n::: {#thm-Teorema de Bayes}\nSeja \\(\\bm{x}\\) uma amostra observada. Considere a priori \\(\\theta\\sim f(\\theta)\\) e a verossimilhança \\(L(\\theta)\\). Então a função de densidade (ou probabilidade) de \\(\\theta|\\bm{x}\\) é dada por \\[f(\\theta|\\bm{x})=\\frac{L(\\theta)f(\\theta)}{f(\\bm{x})}.\\] O denominador é denominado distribuição preditiva, sendo igual a \\[f(\\bm{x})=\\sum_{\\theta\\in \\Theta}L(\\theta)f(\\theta),\\] se \\(\\theta\\) é v.a. discreta ou \\[f(\\bm{x})=\\int_{\\Theta}L(\\theta)f(\\theta)d\\theta\\] se \\(\\theta\\) é v.a. contínua. :::"
  },
  {
    "objectID": "intro.html#inferência-estatística",
    "href": "intro.html#inferência-estatística",
    "title": "1  Aula 1 - Introdução",
    "section": "1.3 Inferência estatística",
    "text": "1.3 Inferência estatística\nDenominamos por estatística qualquer função da amostra. Utilizamos estatísticas para fazer as seguintes inferências:\n\nEstimação pontual: trata-se de uma estatística com o objetivo de inferir o valor de \\(\\theta\\). Tal estatística é denominada .\nEstimação por região: trata-se de uma estatística, digamos \\(T(\\bm{X})\\), com o objetivo de cobrir o valor de \\(\\theta\\), ou seja, fazer a inferência \\(\\theta\\in T(\\bm{X})\\). As estimações intervalares são as mais comuns, nas quais \\(T(\\bm{X})=(L(\\bm{X}),U(\\bm{X}))\\).\nTestes de hipóteses: são estatísticas construídas para decidir se aceitamos a afirmação (hipótese) \\(H:\\theta\\in \\Theta_0\\), onde \\(\\Theta_0\\) é um subconjunto de \\(\\Theta\\) conhecido por hipótese.\n\nNote que a distribuição a posteriori é função da amostra. Assim, toda função desta distribuição é uma estatística. Assim:\n\nEstimação pontual: em geral é uma medida que representa a região de alta densidade (ou probabilidade) da posteriori. A média da posteriori, assim como a mediana ou a moda são escolhas comuns.\nEstimação por regiões: em geral procuramos por uma região \\(T\\) da posteriori que satisfaça \\(P(\\theta\\in T(\\bm{x})|\\bm{x})=\\gamma\\), onde \\(\\gamma\\) é denominado nível de credibilidade (não confundir com nível de confiança)\nTestes de hipóteses: em geral, aceitamos \\(H:\\theta\\in\\Theta_0\\) se \\(P(H|\\bm{x})\\) é elevada."
  },
  {
    "objectID": "intro.html#elicitação-de-prioris",
    "href": "intro.html#elicitação-de-prioris",
    "title": "1  Aula 1 - Introdução",
    "section": "1.4 Elicitação de prioris",
    "text": "1.4 Elicitação de prioris\nNote que o Teorema de Bayes deve unir as duas fontes de informação em uma nova fonte, sumarizada pela posteriori.\nNão é incomum escolhermos certas prioris que trazem pouca informação, de modo que a moda a posteriori estará concentrada ao redor do estimador de máxima verossimilhança. Contudo, se há informações disponíveis, é recomendável gastar um tempo imaginando como traduzir estas informações em probabilidades. Nestes casos, diremos que a priori será elicitada.\nO modo mais usual para a elicitação é encontrar os hiperparâmetros através de estatísticas da informação prévia.\n\nExample 1.2 Considere o problema de estimar o número médio de pessoas infectadas pelo vírus da AIDS em 2020 (os dados atuais são de 2018).\nO nosso parâmetro de interesse é a média \\(\\theta&gt;0\\).\nAbaixo, temos a informação do número de casos registrados nos últimos 10 anos:\n\nlibrary(knitr)\nAno &lt;- 2009:2018\nTotal &lt;-    c(40818,40409, 42355,42086 ,42934,41746,40506,38924,37999,37161)\nkable(data.frame(Ano,Total))\n\n\n\n\nAno\nTotal\n\n\n\n\n2009\n40818\n\n\n2010\n40409\n\n\n2011\n42355\n\n\n2012\n42086\n\n\n2013\n42934\n\n\n2014\n41746\n\n\n2015\n40506\n\n\n2016\n38924\n\n\n2017\n37999\n\n\n2018\n37161\n\n\n\n\n\nPodemos considerar a informação anterior para construir nossa priori. A média deve oscilar em torno do total de cada ano. Uma técnica simples e bastante útil é elicitar uma priori que tenha a mesma média e desvio padrão da informação disponível. Temos que\n\nMédias dos anos anteriores: 40.493,09\nDesvio padrão dos anos anteriores: 1.927,29\n\nComo \\(\\theta&gt;0\\), podemos pensar em utilizar \\(\\theta\\sim\\hbox{Gama}(a,b)\\), onde \\[E(\\theta)=\\frac{a}{b}=40.493,09\\] e \\[\\sqrt{Var(\\theta)}=\\sqrt{\\frac{a}{b^2}}=1.927,29.\\]\nUm pouco de álgebra revela que \\[a=441\\;,\\;b=0,011\\]\n\nplot.new()\nplot.window( ylim=c(0,.00025), xlim = c(30000,50000) )\ncurve(dgamma(x, 441, .011), lwd = 2 , add = T)\naxis(1)\ntitle( xlab = expression(theta))\n\n\n\n\nFigure 1.1: Densidade a priori elicitada a partir da média e do desvio padrão de informações passadas\n\n\n\n\n\nÉ importante notar que a priori depende de um fator subjetivo. No exemplo anterior, você poderia ter utilizado a moda e o desvio padrão para fazer a sua elicitação, ou mesmo alguns quartis. Ou ainda, utilizado uma Weibull ou outra distribuição contínua. Isto teria resultado em prioris diferentes.\nNaturalmente, isto nos conduziria a posterioris diferentes. Esta é a principal crítica ao método bayesiano: duas pesquisas com a mesma amostra podem ter resultados distintos, dependendo da priori.\nPara evitar resultados discrepantes, temos que garantir que não haja conflitos entre as fontes de informação. Em geral, vamos querer que a posteriori esteja mas próxima da verossimilhança que da priori."
  },
  {
    "objectID": "intro.html#o-problema-da-exposição",
    "href": "intro.html#o-problema-da-exposição",
    "title": "1  Aula 1 - Introdução",
    "section": "1.5 O problema da exposição}",
    "text": "1.5 O problema da exposição}\nUma exposição gratuita recebeu vários visitantes em um dia. Nesta exposição existe um livro de visitas, que o visitante pode optar por não assinar. Os organizadores da exposição dizem que\n\nEntre 60% e 80% dos visitantes assinam o livro.\nEm média, 100 pessoas visitam a exposição por dia.\n\nEm um dia foram registrados 96 visitantes no livro. O que podemos dizer sobre o número total de visitantes?\n*Tente fazer um palpite sobre este total.**\nVocê provavelmente chegou em uma solução razoável, utilizando seus conhecimentos matemáticos sobre grandezas proporcionais. Entretanto, para fazer isto, você se utilizou de duas informações que não vieram da amostra! A única informação proveniente da amostra é: 96 visitantes assinaram o livro. Para dificultar um pouco mais, a amostra é de tamanho 1. Este é um exemplo típico no qual a a informação da priori é relevante para fazer inferências.\n\nSolution. Seja \\(X\\) o número de pessoas que assinaram o livro por dia. Seja \\(\\tau\\) o número de pessoas que visitam a exposição. Seja \\(\\theta\\) a probabilidade de um visitante qualquer assinar o livro. Neste primeiro momento, assuma que \\(\\theta\\) é uma constante igual a \\(0,7\\) (em outra aula vamos trabalhar com \\(\\theta\\) desconhecido)\nO espaço paramétrico de \\(\\tau\\) é \\(T=\\{0,1,2,\\ldots\\}\\) * O facilitador deve procurar uma distribuição que seja adequada para o espaço \\(T\\). * Neste exemplo, escolheu-se trabalhar com \\(\\tau\\sim\\hbox{Poisson}(a)\\) * Lembrando que, em média (a priori) 100 pessoas visitam a exposição por dia, temos \\[E[\\tau]=a=100.\\]\nÉ natural supor que \\[f(x|\\tau)={\\tau \\choose x}\\left(\\frac{7}{10}\\right)^x\\left(\\frac{3}{10}\\right)^{\\tau-x},\\;\\; x=0,\\ldots,\\tau\\] Como observamos \\(x=96\\), a verossimilhança será\n\\[\\begin{align*}\n     L(\\tau)=\\left\\{ \\begin{array}{ll}{\\tau \\choose 96}\\left(\\frac{7}{10}\\right)^{96}\\left(\\frac{3}{10}\\right)^{\\tau-96},& \\;\\; \\tau\\geq 96\\\\0,& cc \\end{array}\\right.\n   \\end{align*}\\]\nPelo Teorema de Bayes,\n\\[\\begin{align*}\n   f(\\tau|x)&=\\frac{L(\\tau)f(\\tau)}{\\sum_{t=0}^{\\infty}L(t)f(t)}\\\\   &=\\frac{{\\tau \\choose 96}\\left(\\frac{7}{10}\\right)^{96} \\left(\\frac{3}{10}\\right)^{\\tau-96}\\frac{e^{-100} {100}^\\tau }{\\tau!}}{\\sum_{t=96}^{\\infty}{t \\choose 96}\\left(\\frac{7}{10}\\right)^{96} \\left(\\frac{3}{10}\\right)^{t-96}\\frac{e^{-100} {100}^t }{t!}}\\\\  &=\\frac{{\\tau \\choose 96}\\frac{30^\\tau}{\\tau!}}{\\sum_{t=96}^{\\infty}{t \\choose 96}\\frac{30^t}{t!}}=\\frac{\\frac{30^\\tau}{(\\tau-96)!}}{\\sum_{t=96}^{\\infty}\\frac{30^t}{(t-96)!}}=\\frac{e^{-30}30^{\\tau-96}}{(\\tau-96)!},\n   \\end{align*}\\]\npara \\(\\tau=96,97,\\ldots\\). Mas, fazendo \\(u=t-96\\),\n$$\\begin{align*}\n\\sum_{t=96}^{\\infty}\\frac{30^t}{(t-96)!}&=\\sum_{u=0}^\\infty \\frac{30^{u+96}}{u!}=30^{96}\\sum_{u=0}^\\infty \\frac{30^{u}}{u!}\\\\\n&=30^{96}e^{30}\\sum_{u=0}^\\infty \\frac{e^{-30}30^{u}}{u!}=30^{96}e^{30}\n\\end{align*}$$\n\nteremos,\n$$\\begin{align*}\nf(\\tau|x)&=\\frac{e^{-30}30^{\\tau-96}}{(\\tau-96)!},\n\\end{align*}$$\npara $\\tau=96,97,\\ldots$.\nPortanto, \\(\\tau|x\\) tem distribuição \\[f(\\tau|x)=\\frac{e^{-30}30^{\\tau-96}}{(\\tau-96)!}.\\] e \\[\\begin{align*}\n  E(\\tau|x)&=\\sum_{\\tau=96}^{\\infty}\\tau\\frac{e^{-30}30^{\\tau-96}}{(\\tau-96)!}=\\sum_{u=0}^{\\infty}(u+96)\\frac{e^{-30}30^{u}}{u!}\\\\\n&=\\sum_{u=0}^{\\infty}u\\frac{e^{-30}30^{u}}{u!}+96\\sum_{u=0}^{\\infty}\\frac{e^{-30}30^{u}}{u!}\\\\\n&=30+96=126\n  \\end{align*}\\]\nUma estimativa para o número médio de pessoas que visitaram a exposição naquele dia é \\[E[\\tau|x]=126.\\]\n\nplot(96:160,dpois(96:160 - 96, 30), type= 'h',lwd = 2, xlab='',ylab='')\n\ntitle( xlab = expression(tau), ylab = 'Posteriori para tau')\n\n\n\n\nFigure 1.2: Distribuição a posteriori para o número de pessoas participaram da exposição.\n\n\n\n\n\nResumo da aula 1\n\nExistem duas fontes de informação na inferência bayesiana: os dados (verossimilhança) e a informação anterior (priori)\nA informação a priori é subjetiva: pessoas diferentes tem prioris diferentes\nO Teorema de Bayes combina as duas fontes em uma nova informação, dada pela distribuição \nOs objetivos da inferência (estimação e testes) são feitos a partir da distribuição a posteriori"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "conjugada.html#família-de-distribuições-conjugadas",
    "href": "conjugada.html#família-de-distribuições-conjugadas",
    "title": "3  Famílias conjugadas",
    "section": "3.1 Família de distribuições conjugadas",
    "text": "3.1 Família de distribuições conjugadas\n\nDefinição  Dizemos que a priori $f(\\boldsymbol{\\theta})$ é conjugada para a verossimilhança $L(\\bm{\\theta})$ se \\textit{priori} e \\textit{posteriori} pertencem à mesma família de distribuições.\n\n\n    Sejam $X_1,\\ldots,X_n$ variáveis aleatórias independentes com $X|\\theta\\sim \\hbox{Bernoulli}(\\theta)$ e $\\theta\\sim\\hbox{Beta}(a,b)$. Então\n    \n    \\begin{align*}\n    f(\\theta|\\boldsymbol{x})&\\varpropto L(\\theta)f(\\theta) = \\underbrace{\\theta^{\\sum_{i=1}^{n}x_i} (1-\\theta)^{n-\\sum_{i=1}^{n}x_i}}_{L(\\theta)}\\underbrace{\\theta^{a-1}(1-\\theta)^{b-1}}_{f(\\theta)}\\\\\n    &=\\theta^{a+\\sum_{i=1}^n x_i-1}(1-\\theta)^{b+n-\\sum_{i=1}^{n}x_i-1},\n    \\end{align*}\n    logo $\\theta|\\bm{x}\\sim\\hbox{Beta}(a+\\sum_{i=1}^{n}x_i,b+n-\\sum_{i=1}^{n}x_i)$ e a \\textit{priori} beta é conjugada para a verossimilhança Bernoulli."
  },
  {
    "objectID": "conjugada.html#conjugada-para-a-família-exponencial",
    "href": "conjugada.html#conjugada-para-a-família-exponencial",
    "title": "3  Famílias conjugadas",
    "section": "3.2 Conjugada para a família exponencial",
    "text": "3.2 Conjugada para a família exponencial\nFamílias conjugadas são extremamente úteis tanto sob o ponto de vista algébrico quando computacional. Entretanto, note que a definição de família conjugada é ampla. Por exemplo, e sempre pertence à grande família de todas as distribuições de probabilidade, sendo esta a família conjugada trivial.\nFamílias conjugadas não triviais são raras, existindo principalmente quando a distribuição condicional dos dados pertence á família exponencial.\n\nDefinição Considere que \\(\\Theta\\) tem dimensão \\(k\\). Dizemos que \\(X|\\boldsymbol{\\theta}\\) pertence à família exponencial (natural) se \\[f(x|\\boldsymbol{\\theta})=h(x)a(\\boldsymbol{\\theta})\\exp\\left\\{\\sum_{j=1}^k t_j(x)\\theta_j\\right\\},\\] onde \\(\\mathcal{X}\\) não depende de \\(\\boldsymbol{\\theta}\\). Além disso, para a amostra (iid )\\(X_1,\\ldots,X_n|\\boldsymbol{\\theta}\\), \\[f(\\boldsymbol{x}|\\boldsymbol{\\theta})=h(\\boldsymbol{x})a(\\boldsymbol{\\theta})^n\\exp\\left\\{\\sum_{j=1}^k T_j\\theta_j\\right\\},\\] onde \\(T_j=\\sum_{i=1}^{n}t_j(x_i)\\)\n\n\nSe \\(X|\\boldsymbol{\\theta}\\) pertence à família exponencial, então \\[f(\\boldsymbol{\\theta})=c(\\boldsymbol{r},s)a(\\boldsymbol{\\theta})^s\\exp\\left\\{\\sum_{j=1}^k r_j\\theta_j\\right\\}\\] é uma conjugada (ver O’Hagan (2005) para a existência dessa distribuição). A será dada por \\[f(\\boldsymbol{\\theta}|\\boldsymbol{x})=c\\left(\\sum_{j=1}^k r_j+T_j,s+n\\right)a(\\boldsymbol{\\theta})^{s+n}\\exp\\left\\{\\sum_{j=1}^k(r_j+T_j)\\theta_j\\right\\}\\]\n\n\nProva\n\\[\\begin{align}\nf(\\boldsymbol{\\theta}|\\boldsymbol{x})&\\varpropto \\underbrace{a(\\boldsymbol{\\theta})^ne^{\\sum_{j=1}^kT_j\\theta_k}}_{L(\\boldsymbol{\\theta})}\\underbrace{a(\\boldsymbol{\\theta})^s e^{\\sum_{j=1}^k r_j\\theta_k}}_{f(\\boldsymbol{\\theta})}\\\\\n&a(\\boldsymbol{\\theta})^{n+s}e^{(\\sum_{j=1}^{k}T_j+r_j)\\theta_j}\n\\end{align}\\]\n\nConsidere que \\(\\bm{\\theta}\\sim C(\\bm{r},s)\\) é a distribuição conjugada da verossimilhança. Isto implica em \\(\\bm{\\theta}|\\bm{x}\\sim\\hbox{C}(\\bm{T}+\\bm{r},s+n)\\). Note que a atualiza a informação de \\(s\\) para \\(s+n\\) e de \\(r_j\\) para \\(T_j+r_j\\). Logo, se imaginarmos que a priori é um experimento hipotético, \\(s\\) seria o tamanho da amostra e \\(\\bm{r}\\) seriam as estatísticas suficientes deste modelo."
  },
  {
    "objectID": "conjugada.html#conflito-entre-fontes-de-informação",
    "href": "conjugada.html#conflito-entre-fontes-de-informação",
    "title": "3  Famílias conjugadas",
    "section": "3.3 Conflito entre fontes de informação",
    "text": "3.3 Conflito entre fontes de informação\nConsidere que uma fábrica produz lotes de certos componentes eletrônicos. O setor de qualidade faz inspeções periódicas através de amostragem de 100 peças dentro de um lote. Todas as peças são testadas e o número de falhas registrado. As últimas inspeções mostram que em torno de 3% das peças são defeituosas.\nUma nova amostra será selecionada. Sendo \\(X\\) o número de peças defeituosas, uma verossimilhança adequada seria \\[\\theta^x(1-\\theta)^{100-x}\\]\nSabemos que o modelo Beta\\((r,s)\\) é conjugado para esta verossimilhança. Comparando a \\[f(\\theta)\\varpropto \\theta^{r-1}(1-\\theta)^{s-1},\\] com a verossimilhança, podemos interpretar \\(r\\) como o número de componentes defeituosos e \\(s\\)\n Como temos as informações de vários lotes, podemos imaginar que um lote hipotético de tamanho $s=100$ foi selecionado e $r=3$ peças defeituosas foram encontradas.\nNote que, com estes valores, a exclui muitos valores do espaço paramétrico, uma vez que \\[\\sqrt{Var(\\theta)}=0,0167\\] Se a proporção amostral se manteve dentro dos 3% não há problemas com isso. Mas se ela aumentou (por causa de uma falha não detectada no processo), como essa escolha vai influenciar nossa análise?\nPara entender os efeitos da sobre a , vamos analisar dois cenários.\n\nCenário 1: Foram encontradas 4 componentes defeituosos\nCenário 2: Foram encontrados 11 componentes defeituosos\n\n\n\n\nFigura 1. Cenário 1. Gráficos da verossimilhança, priori e posteriori. \\(E(\\theta)\\), \\(\\hat{\\theta}\\) e \\(\\tilde{\\theta}\\) são média da priori, EMV e a média da posteriori..\n\n\n\n\n\nFigura 1. Cenário 2. Gráficos da verossimilhança, priori e posteriori. \\(E(\\theta)\\), \\(\\hat{\\theta}\\) e \\(\\tilde{\\theta}\\) são média da priori, EMV e a média da posteriori..\n\n\nDizemos que há conflitos entre as fontes de informação quando a região de maior densidade da é pouco provável e tem baixa verossimilhança. Isso aconteceu com o cenário 2. O motivo para isso é que os dados geraram um valor atípico e a era muito informativa (baixo desvio padrão), não tendo massa longe do suficiente de \\(E(\\theta)\\). Consideremos então a priori Beta(.3,9.7).\n\\[\\begin{align}f(\\mu,\\phi|\\boldsymbol{x})\\propto f(x|\\mu,\\phi)f(\\mu,\\phi)\\\\\n&\\propto \\phi^{\\frac{n}{2}}e^{-\\frac{\\phi}{2}[ns^2 + n(\\bar{x}-\\mu)^2]}\\times \\phi^{\\frac{1}{2}}e^{-\\frac{\\phi}{2C_0}(\\mu-m_0)^2}\\phi^{\\frac{n_0}{2}-1}e^{-\\frac{d_0}{2}\\phi}\\\\\n&= \\phi^{\\frac{1}{2}}e^{-\\frac{\\phi n}{2}(\\bar{x}-\\mu)^2 -\\frac{\\phi}{2C_0}(\\mu-m_0)^2}\\times \\phi^{\\frac{n+n_0}{2}-1}e^{-\\frac{\\phi}{2}\\left(ns^2+d_0\\right)}\n\\end{align}\\]"
  },
  {
    "objectID": "conjugada.html#prioris-conjugadas-fora-da-família-exponencial",
    "href": "conjugada.html#prioris-conjugadas-fora-da-família-exponencial",
    "title": "3  Famílias conjugadas",
    "section": "3.4 Prioris conjugadas fora da família exponencial",
    "text": "3.4 Prioris conjugadas fora da família exponencial\nFamílias conjugadas fora da família exponencial são raras. Seja \\(X_1,\\ldots,X_n\\) variáveis aleatória independentes com \\(X_1|\\phi,\\psi\\sim\\hbox{Binomial Negativa}(\\psi,\\phi)\\), onde \\[f(x|\\phi,\\psi)=\\frac{\\Gamma(x+\\psi)}{\\Gamma(\\psi)x!}\\phi^\\psi (1-\\phi)^x,\\] com \\(\\psi&gt;0\\), \\(\\phi\\in(0,1)\\) e \\(x\\in\\mathbb{N}\\). Se \\(\\psi\\) é conhecido, então \\[L(\\boldsymbol{\\theta})=\\underbrace{\\left[\\frac{\\prod_{i=1}^n\\Gamma(x_i+\\psi)}{\\Gamma(\\psi)^n\\prod_{i=1}^n x_i!}\\right]}_{h(\\boldsymbol{x})}\\underbrace{\\phi^{n\\psi}}_{a(\\phi)}\\exp\\left\\{ \\underbrace{\\sum_{i=1}^n x_i}_{t(\\boldsymbol{x})} \\underbrace{\\log(1-\\phi)}_{w(\\phi)}\\right\\} \\] Então, \\[\\begin{align}\nf(\\phi|\\psi)&=c(r,s)a(\\phi)^s e^{rw(\\phi)}\\\\\n&=c(r,s)\\phi^{s\\psi}(1-\\phi)^{r}\n\\end{align}\\] é uma conjugada. Da expressão acima segue que \\(\\phi|\\psi \\sim \\hbox{Beta}(s\\psi+1,r+1)\\). A (condicional) por sua vez é dada por \\[f(\\phi|\\boldsymbol{x},\\psi)\\varpropto \\phi^{\\psi(s+n)}(1-\\phi)^{r+\\sum_{i=1}^{n}x_i},\\] onde ainda \\(\\phi|\\psi,\\boldsymbol{x}\\sim\\hbox{Beta}(\\psi(s+n)+1,r+\\sum_{i=1}^{n}x_i+1)\\) Note que para fazer a inferência completa, ainda necessitamos de \\(\\psi|\\boldsymbol{x}\\), uma vez que \\[f(\\phi,\\psi|\\boldsymbol{x})=f(\\phi|\\psi,\\boldsymbol{x})f(\\psi|\\boldsymbol{x})\\] Outro método de obter a conjunta \\((\\phi,\\psi|\\boldsymbol{x})\\), sem a necessidade de calcular \\(\\psi|\\boldsymbol{x}\\) será discutido na próxima aula."
  },
  {
    "objectID": "estimacao.html",
    "href": "estimacao.html",
    "title": "4  O estimador de bayes",
    "section": "",
    "text": "Considere o problema de tomar alguma decisão sobre \\(\\theta\\) utilizando uma estatística \\(T(\\mathbf{x})\\).\nPodemos determinar o quão ruim é a nossa decisão definindo uma função de perda \\(\\mathcal{L}(\\theta,T)\\), com as seguintes características:\n\n\\(\\mathcal{L}(\\theta,T)=0\\) sempre que \\(T\\) for a decisão correta em relação à \\(\\theta\\)\n\\(\\mathcal{L}(\\theta,T)&gt;0\\) em caso contrário.\n\nPor exemplo, se \\(T\\) for um estimador para \\(\\theta\\), a decisão correta seria ter \\(T=\\theta\\). Além disso, quanto mais afastado \\(T\\) estiver de \\(\\theta\\), pior é a decisão e maior deveria ser a perda.\nNo problema de estimação pontual, é usual utilizar a perda quadrática: \\[\\mathcal{L}(\\theta,T)=(T-\\theta)^2,\\] cujo esboço do gráfico é dado abaixo:\n\nplot.new()\nplot.window(xlim=c(-2,2), ylim=c(0,4))\ncurve( x^2,-2,2, lwd = 2, add = T)\naxis(1, at = c(-2,-1,0,1,2), labels = c(expression(theta -2),expression(theta -1),expression(theta),expression(theta +1),expression(theta +2) ))\naxis(2)\ntitle( ylab = 'Perda quadrática',xlab = 'T')\n\n\n\n\nPara uma decisão \\(T\\) podemos calcular a perda média \\[R_T(\\theta)=E(L(\\theta,T))=\\int L(\\theta,T(\\mathbf{x}))f(\\mathbf{x}|\\theta)d\\mathbf{x}\\] A função acima é conhecida como risco da decisão \\(T\\) e é variável em \\(\\theta\\). Seu uso é simples: se \\(R_T(\\theta)&lt;R_U(\\theta)\\), então em média a decisão \\(T\\) tem menor perda que \\(U\\). Assim, a melhor escolha entre as duas decisão é \\(U\\).\nO risco associado à perda quadrática é denominado erro quadrático médio:\n\\[R_T(\\theta)=E(T-\\theta)^2= Var(T)+(E(T|\\theta)-\\theta)^2\\] Ele possui papel importante na inferência pontual frequentista, como por exemplo, para definir o melhor estimador não viciado de variância uniformemente mínima.\nO risco de Bayes da decisão \\(T\\) é o valor esperado do seu respectivo risco , \\[r_T=\\int R(\\theta)f(\\theta)d\\theta,\\] sendo portanto uma constante. Qualquer decisão com o menor risco para todo \\(\\theta\\) também tem o menor risco de Bayes. Dizemos que \\(T\\) é o estimador de Bayes se \\(r_T&lt;r_U\\) para qualquer decisão \\(U\\).\n\nTeorema\nO estimador \\(T\\) que minimiza \\[\\int \\mathcal{L}(\\theta,T(\\mathbf{x}))f(\\theta|\\mathbf{x})d\\theta\\] é o estimador de Bayes.\n\n\nExemplo\nVamos encontrar o estimador de Bayes para a perda quadrática. Temos que\n\\[\\begin{align*}\\int \\mathcal{L}(\\theta,T(\\mathbf{x}))f(\\theta|\\mathbf{x})d\\theta&=\\int (T(\\mathbf{x})-\\theta)^2f(\\theta|\\mathbf{x})d\\theta\\\\\n    &=T(\\mathbf{x})^2 +\\int \\theta^2f(\\theta|\\mathbf{x})d\\theta-2T(\\mathbf{x})\\int \\theta f(\\theta|\\mathbf{x})d\\theta\\\\\n    &= T(\\mathbf{x})^2 + E(\\theta^2|\\mathbf{x}) -2T(\\mathbf{x})E(\\theta|\\mathbf{x})\\\\\n    &= T(\\mathbf{x})^2 + E(\\theta^2|\\mathbf{x}) -2T(\\mathbf{x})E(\\theta|\\mathbf{x}) \\pm E(\\theta|\\mathbf{x})^2\\\\\n    &=\\left( T(\\mathbf{x}) - E(\\theta|\\mathbf{x})\\right)^2 +E(\\theta^2|\\mathbf{x})-E(\\theta|\\mathbf{x})^2\\\\\n    &=\\left( T(\\mathbf{x}) - E(\\theta|\\mathbf{x})\\right)^2 +Var(\\theta|\\mathbf{x})\n\\end{align*}\\] A função acima é minimizada em \\(T(\\mathbf{x})=E(\\theta|\\mathbf{x})\\). Disto, mostra-se que \\[r_T\\geq Var(\\theta|\\mathbf{x})\\] e a variância da posteriori pode ser utilizada como medida de erro. Como a unidade deste erro está ap quadrado, é usual utilizarmos o desvio padrão da posteriori como medida de erro."
  },
  {
    "objectID": "normal.html#a-distribuição-normal-gama",
    "href": "normal.html#a-distribuição-normal-gama",
    "title": "5  O modelo normal",
    "section": "5.1 A distribuição normal-gama",
    "text": "5.1 A distribuição normal-gama\nDizemos que \\((X,Y)\\sim NG(\\mu,n_0,\\nu,d^2)\\) (lê-se normal-gama) se sua função densidade conjunta é dada por\n\\[f(x,y)\\propto y^{\\frac{\\nu+1}{2}-1}\\exp\\left\\{-\\frac{y}{2}n_0\\left[(x-\\mu)^2 + d^2\\right]\\right\\}\\]\nonde \\(\\mu,x\\in\\mathbb{R}\\) e \\(d,y,c\\in\\mathbb{R}_+\\). Colocando os termos que não dependem de \\(x\\) junto com a constante de proporcionalidade, podemos mostrar que\n\\[f(x|y)\\propto \\exp\\left\\{-\\frac{y}{2}n_0(x-\\mu)^2\\right\\}\\] ou seja, \\(X|y\\sim\\hbox{Normal}(\\mu,y^{-1}/n_0)\\). Além disso, integrando \\(f(x,y)\\) em \\(x\\), mostramos que\n\\[f(y)\\propto y^{\\frac{\\nu+1}{2}-1}e^{-\\frac{yn_0d^2}{2}}\\int_{\\mathbb{R}}\\exp\\left\\{-\\frac{y}{2}\\left[n_0(x-\\mu)^2\\right]\\right\\}d\\mu\\propto y^{\\frac{\\nu}{2}-1}e^{-\\frac{n_0d^2}{2}y}\\] ou seja, \\(Y\\sim\\hbox{Gama}(\\nu/2, n_0d^2/2)\\). Por último, integrando \\(f(x,y)\\) em \\(y\\) teremos\n\\[\\begin{align}f(x)&\\propto \\int_0^\\infty y^{\\frac{\\nu+1}{2}-1}\\exp\\left\\{-\\frac{y}{2}n_0\\left[(x-\\mu)^2 + d^2\\right]\\right\\}dy \\\\&\\propto \\Gamma\\left(\\frac{\\nu+1}{2}\\right)\\left\\{1+\\frac{\\nu}{d^2}\\frac{(x-\\mu)^2}{\\nu}\\right\\}^{-\\frac{\\nu+1}{2}}\\end{align}\\] ou seja, \\(X\\sim t_{\\nu}(\\mu, d^2/\\nu)\\). Em especial, se \\(\\nu&gt;1\\) então \\(E(X)=\\mu\\) e, se \\(\\nu&gt;2\\) teremos que \\[Var(X)=\\frac{d^2}{\\nu-2}\\]"
  },
  {
    "objectID": "normal.html#a-função-de-verossimilhança",
    "href": "normal.html#a-função-de-verossimilhança",
    "title": "5  O modelo normal",
    "section": "5.2 A função de verossimilhança",
    "text": "5.2 A função de verossimilhança\nSeja \\(X_1,\\ldots,X_n\\) uma amostra aleatória do modelo \\(X|\\mu,\\phi\\sim\\hbox{Normal}(\\mu,\\phi^{-1})\\), onde \\(\\phi\\), denominado precisão, é o inverso da variância. A função de verossimilhança deste modelo pode ser escrita como\n\\[L(\\mu,\\phi)\\propto \\phi^{\\frac{n}{2}}\\exp\\left\\{-\\frac{n\\phi}{2}(\\bar{x}-\\mu)^2 -\\frac{ns^2\\phi}{2}\\right\\}\\] onde \\[s^2=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2\\] é a estimativa de máxima verossimilhança para \\(\\phi^{-1}\\)."
  },
  {
    "objectID": "normal.html#posteriori-com-prioris-impróprias",
    "href": "normal.html#posteriori-com-prioris-impróprias",
    "title": "5  O modelo normal",
    "section": "5.3 Posteriori com prioris impróprias",
    "text": "5.3 Posteriori com prioris impróprias\nConsiderando as prioris impróprias \\(\\pi(\\phi)\\propto \\phi^{-1}\\), \\(\\pi(\\mu)\\propto 1\\) e que \\(\\pi(\\mu,\\phi)=\\pi(\\mu)\\pi(\\phi)\\), teremos que\n\\[\\pi(\\mu,\\phi|\\boldsymbol{x})\\propto \\phi^{\\frac{n}{2}-1}\\left\\{-\\frac{\\phi}{2}n\\left[ (\\bar{x}-\\mu)^2 +s^2\\right]\\right\\}\\] ou seja, \\(\\mu,\\phi|\\boldsymbol{x}\\sim\\hbox{NG}(\\bar{x},n,n-1,s^2)\\), o que implica em:\n\\[\\begin{align}\n\\mu|\\phi,\\boldsymbol{x}&\\sim\\hbox{Normal}\\left(\\bar{x},\\frac{\\phi^{-1}}{n}\\right)\\\\\n\\phi|\\boldsymbol{x}&\\sim\\hbox{Gama}\\left(\\frac{n-1}{2},\\frac{ns^2}{2}\\right)\\\\\n\\mu|\\boldsymbol{x}&\\sim t_{n-1}\\left(\\bar{x},\\frac{s^2}{n-1}\\right)\n\\end{align}\\]\nDisto, teremos que\n\n\n\nParâmetro\nEstimativa\nErro\n\n\n\n\n\\(\\mu\\)\n\\(\\bar{x}\\)\n\\(\\frac{s}{\\sqrt{n-3}}\\)\n\n\n\\(\\phi\\)\n\\(\\frac{n-1}{ns^2}\\)\n\\(\\frac{\\sqrt{2(n-1)}}{s^2n}\\)"
  },
  {
    "objectID": "normal.html#posteriori-com-a-priori-de-jeffreys",
    "href": "normal.html#posteriori-com-a-priori-de-jeffreys",
    "title": "5  O modelo normal",
    "section": "5.4 Posteriori com a priori de Jeffreys",
    "text": "5.4 Posteriori com a priori de Jeffreys\nO logaritmo da função de verossimilhança é\n\\[l(\\mu,\\phi)=\\frac{n}{2}\\log\\phi -\\frac{n}{2}\\phi\\left[(\\bar{x}-\\mu)^2 + s^2\\right]\\]\nAs derivadas de primeira ordem em \\(\\mu\\) e \\(\\phi\\) são \\[\\begin{align}\n\\frac{\\partial}{\\partial \\mu}l(\\mu,\\phi)&=n\\phi(\\bar{x}-\\mu)\\\\\n\\frac{\\partial}{\\partial \\phi}l(\\mu,\\phi)&=\\frac{n}{2\\phi}-\\frac{n}{2}\\left[(\\bar{x}-\\mu)^2 + s^2\\right]\\\\\n\\end{align}\\]\ne as de segunda ordem são \\[\\begin{align}\n\\frac{\\partial^2}{\\partial \\mu^2}l(\\mu,\\phi)&=-n\\phi\\\\\n\\frac{\\partial^2}{\\partial \\phi^2}l(\\mu,\\phi)&=-\\frac{n}{2\\phi^2}\\\\\n\\frac{\\partial^2}{\\partial \\mu\\partial \\phi}l(\\mu,\\phi)&=0\\\\\n\\end{align}\n\\] logo, a matriz de informação de Fisher é \\[\\mathcal{I}_n(\\mu,\\phi)=n\\left[\\begin{array}{cc}\\phi & 0 \\\\0 & \\frac{1}{2\\phi^2}\\end{array}\\right],\\] e a priori de Jeffreys é \\[\\pi(\\mu,\\phi)\\propto \\sqrt{|\\mathcal{I}_n(\\mu,\\phi)|}=\\phi^{-1/2},\\] que implica na posteriori\n\\[\\pi(\\mu,\\phi|\\boldsymbol{x})\\propto \\phi^{\\frac{n+1}{2}-1}\\left\\{-\\frac{n\\phi}{2}\\left[(\\bar{x}-\\mu)^2 +s^2 \\right]\\right\\}\\] ou seja, \\(\\mu,\\phi|\\boldsymbol{x}\\sim\\hbox{NG}(\\bar{x},n,n,s^2)\\), o que implica em:\n\\[\\begin{align}\n\\mu|\\phi,\\boldsymbol{x}&\\sim\\hbox{Normal}\\left(\\bar{x},\\frac{\\phi^{-1}}{n}\\right)\\\\\n\\phi|\\boldsymbol{x}&\\sim\\hbox{Gama}\\left(\\frac{n}{2},\\frac{ns^2}{2}\\right)\\\\\n\\mu|\\boldsymbol{x}&\\sim t_{n}\\left(\\bar{x},\\frac{s^2}{n}\\right)\n\\end{align}\\]\nDisto, teremos que\n\n\n\nParâmetro\nEstimativa\nErro\n\n\n\n\n\\(\\mu\\)\n\\(\\bar{x}\\)\n\\(\\frac{s}{\\sqrt{n-2}}\\)\n\n\n\\(\\phi\\)\n\\(\\frac{1}{s^{2}}\\)\n\\(\\frac{\\sqrt{2}}{s^2\\sqrt{n}}\\)"
  },
  {
    "objectID": "normal.html#posteriori-para-a-priori-conjugada",
    "href": "normal.html#posteriori-para-a-priori-conjugada",
    "title": "5  O modelo normal",
    "section": "5.5 Posteriori para a priori conjugada",
    "text": "5.5 Posteriori para a priori conjugada\nConsidere que \\((\\mu,\\phi)\\sim \\hbox{NG}(m_0,n_0,\\nu_0,s^2_0)\\). Esta priori é conjugada para o modelo normal, uma vez que\n\\[\\begin{align}\n\\pi(\\mu,\\phi|\\boldsymbol{x})&\\propto \\phi^{\\frac{n}{2}}\\exp\\left\\{-\\frac{\\phi}{2}n\\left[(\\bar{x}-\\mu)^2+ s^2\\right]\\right\\}\\phi^{\\frac{\\nu_0+1}{2}-1}\\exp\\left\\{-\\frac{\\phi}{2}n_0\\left[(\\mu-m_0)^2 + s_0^2\\right]\\right\\}\\\\\n&\\phi^{\\frac{\\nu_0+n}{2}-1}\\exp\\left\\{-\\frac{\\phi}{2}\\left[n(\\bar{x}-\\mu)^2 + n_0(\\mu-m_0)^2+ns^2 + n_0s^2_0\\right]\\right\\}\\end{align}.\\] Como \\[n(\\bar{x}-\\mu)^2 +n_0(\\mu-m_0)^2 = (n+n_0)(\\mu-m_1)^2+\\frac{n n_0}{n+n_0}(\\bar{x}-m_0)^2\\] onde \\[\\begin{align}\nm_1&=\\frac{n}{n+n_0}\\bar{x}+\\frac{n_0}{n+n_0}m_0\n\\end{align},\\] teremos \\[\\begin{align}\n\\pi(\\mu,\\phi|\\boldsymbol{x})&\\propto \\phi^{\\frac{\\nu_1+1}{2}-1}\\exp\\left\\{-\\frac{\\phi}{2}n_1\\left[(\\mu-m_1)^2 + d_1^2\\right]\\right\\}\\end{align},\\] onde \\[\\begin{align}\n\\nu_1&=\\nu_0+n\\\\\nn_1&=n_0+n\\\\\nm_1&=\\frac{n}{n1}\\bar{x}+\\frac{n_0}{n_1}m_0\\\\\nd_1^2& = \\frac{n_0n}{n_1^2}(\\bar{x}-m_0)^2+\\frac{n}{n_1}s^2 + \\frac{n_0}{n_1}s^2_0\n\\end{align}\\] ou seja, \\(\\mu,\\phi|\\boldsymbol{x}\\sim\\hbox{NG}(m_1,n+n_0,\\nu_0+n,d_1^2)\\), o que implica em:\n\\[\\begin{align}\n\\mu|\\phi,\\boldsymbol{x}&\\sim\\hbox{Normal}\\left(m_1,\\frac{\\phi^{-1}}{n+n_0}\\right)\\\\\n\\phi|\\boldsymbol{x}&\\sim\\hbox{Gama}\\left(\\frac{n+\\nu_0}{2},\\frac{(n+n_0)d_1^2}{2}\\right)\\\\\n\\mu|\\boldsymbol{x}&\\sim t_{n}\\left(m_1,\\frac{d^2_1}{\\nu_0+n}\\right)\n\\end{align}\\]\nDisto, teremos que\n\n\n\n\n\n\n\n\nParâmetro\nEstimativa\nErro\n\n\n\n\n\\(\\mu\\)\n\\(\\frac{n}{n+n_0}\\bar{x}+\\frac{n_0}{n+n_0}m_0\\)\n\\(\\frac{d_1}{\\sqrt{n+\\nu_0-2}}\\)\n\n\n\\(\\phi\\)\n\\(\\frac{n+\\nu_0}{(n+n_0)d_1^2}\\)\n\\(\\frac{\\sqrt{2(n+\\nu_0)}}{d_1^2(n+n_0)}\\)"
  },
  {
    "objectID": "normal.html#detecção-de-outliers",
    "href": "normal.html#detecção-de-outliers",
    "title": "5  O modelo normal",
    "section": "5.6 Detecção de outliers",
    "text": "5.6 Detecção de outliers"
  },
  {
    "objectID": "poisson.html#verossimilhança-prioris-e-posterioris",
    "href": "poisson.html#verossimilhança-prioris-e-posterioris",
    "title": "6  O modelo Poisson revisitado",
    "section": "6.1 Verossimilhança, prioris e posterioris",
    "text": "6.1 Verossimilhança, prioris e posterioris\nDizemos que \\(X|\\theta\\) tem distribuição Poisson se sua função de probabilidade é dada por \\[f(x|\\theta)=\\frac{e^{-\\theta}\\theta^x}{x!},\\] onde \\(x=0,1,\\ldots\\) e \\(\\theta&gt;0\\). O parâmetro \\(\\theta\\) é denominado taxa. Para este modelo \\[E(X|\\theta)=Var(X|\\theta)=\\theta.\\]\nEsta é uma das distribuições para contagens mais importantes. A verossimilhança deste modelo, para uma amostra de vaiid, é dada por \\[L(\\theta)=\\frac{e^{-n\\theta}\\theta^{\\sum_{i=1}^{n}x_i}}{\\prod_{i=1}^{n}x_i!}.\\] O modelo Poisson pertence à família exponencial e sua conjugada é \\(\\theta\\sim\\hbox{Gama}(r,s)\\), onde \\(r\\) e \\(s\\) podem ser interpretados como o total da contagem e o tamanho da amostra .\nNeste caso, a é \\(\\hbox{Gama}(r+\\sum_{i=1}^n x_i+r, s+n)\\).\nA média da é \\[E(\\theta|\\mathbf{x})=\\frac{\\sum_{i=1}^{n}x_i+r}{n+s}=\\frac{n}{n+s}\\bar{x}+\\frac{s}{n+s}E(\\theta),\\] onde fica claro que este estimador é uma média ponderada das informações provenientes das duas fontes de informação (sendo \\(\\bar{x}\\) a estimativa de máxima verossimilhança e \\(E(\\theta)\\) a média ).\nSe \\(n\\gg s\\), então a média a posteriori dará maior peso para a informação dos dados.\nA informação de Fisher é \\[\\mathcal{I}(\\theta)=\\frac{1}{\\theta}\\]\nAssim, a priori de Jeffreys é dada por \\[f(\\theta)\\propto \\theta^{-\\frac{1}{2}},\\] sendo, portanto, uma priori imprópria. Contudo, \\[f(\\theta|\\mathbf{x})\\propto e^{-n\\theta}\\theta^{\\sum_{i=1}^{n}x_i} \\theta^{-\\frac{1}{2}},\\] logo, a posteriori é própria, tendo distribuição \\(Gama(\\sum_{i=1}^{n}x_i+1/2,n)\\).\nConsidere a posteriori \\(\\theta|\\mathbf{x}\\sim\\hbox{Gama}(r_1,s_1)\\). Podemos retirar uma amostra da preditiva do seguinte modo:\n\nGere \\(\\theta_j\\sim\\hbox{Gama}(r_1,s_1)\\)\n\n2.Gere \\(\\tilde{\\mathbf{x}}\\sim\\hbox{Poisson}(\\theta_j)\\)."
  },
  {
    "objectID": "poisson.html#o-modelo-poisson-para-taxas",
    "href": "poisson.html#o-modelo-poisson-para-taxas",
    "title": "6  O modelo Poisson revisitado",
    "section": "6.2 O modelo Poisson para taxas",
    "text": "6.2 O modelo Poisson para taxas\nA taxa é o cociente entre o número de casos de um evento em determinado intervalo de tempo e a população em risco, definida em um espaço e no mesmo intervalo de tempo (``pessoas-tempo’’). Note que, pela definição, a taxa é uma estatística.\nSeja \\(n\\) o tamanho da população no espaço/tempo e seja \\(y\\) o número de casos do evento de interesse. Então,\n\\[\\hbox{taxa} = \\frac{y}{n}\\]\nContudo, como \\(n\\) tende a ser muito maior que \\(y\\), é comum reportar a taxa vezes \\(10^k\\), para algum \\(k&gt;0\\).\n\nExemplo: Segundo o Anuário de Segurança Pública 2022, em 2021 houveram 68.885 casos de estupro. Considerando uma população de 212,7 milhões de habitantes, a taxa de estupro para aquele ano foi de \\[\\frac{68.885}{212.700.000}=3,23\\times 10^{-4}\\] casos por pessoa-ano. Como \\(n\\) tende a ser maior que \\(y\\), é comum considerar.\nMultiplicando a taxa por \\(10^5\\), temos uma taxa de 32,3 casos para cada 100.000 habitantes.\n\nAgora,considere que \\(\\theta\\) é o parâmetro taxa. Então,\n\\[\\hat{\\theta}=\\frac{y}{n}\\] é a estimativa para \\(\\theta\\). Como \\(y\\) é uma contagem, é razoável supor que \\[\\theta =\\frac{1}{n}E(Y|\\theta).\\] e um modelo possível seria \\(y|\\theta\\sim\\hbox{Poisson}(\\theta n)\\).\nAgora, considere que uma população está particionada em \\(m\\) localidades. Para um dado intervalo de tempo, sejam \\(n_i\\) e \\(y_i\\) a população da localidade \\(i\\) e seu respectivo número de casos observados. Suponha ainda que a taxa \\(\\theta\\) é comum para a pooulação e que \\(y_i\\) é condicionalmente independente de \\(y_j\\) dado \\(\\theta\\). Assumindo a distribuição Poisson, teremos\n\\[L(\\theta)=\\prod_{i=1}^m\\frac{e^{-\\theta n_i}(\\theta n_i)^{y_i}}{y_i!}\\varpropto \\theta^{\\sum_{i=1}^m y_i}e^{-\\theta \\sum_{i=1}^m n_i}=\\theta^{\\sum_{i=1}^n y_i}e^{-\\theta N},\\] onde \\(N=\\sum_{i=1}^m n_i\\) é o tamanho da população. Como a verossimilhança pertence à família exponencial, temos que o modelo Gama\\((a,b)\\) é conjugado gerando a posteriori\n\\[\\theta|\\mathbf{y}\\sim\\hbox{Gama}\\left(\\sum_{i=1}^{m}y_i+a,N+b\\right).\\]\nA prioris impróprias \\(\\pi(\\theta)\\varpropto \\theta^{-1}\\) e \\(\\pi(\\theta)\\varpropto \\theta^{-1/2}\\) geram, respectivamente, as posterioris \\(\\hbox{Gama}(\\sum_{i=1}^m y_i,N)\\) e \\(\\hbox{Gama}(\\sum_{i=1}^m y_i+1/2,N)\\)."
  },
  {
    "objectID": "poisson.html#exemplo-1-crime-de-estupro-de-vulnerável-no-interior-do-amazonas",
    "href": "poisson.html#exemplo-1-crime-de-estupro-de-vulnerável-no-interior-do-amazonas",
    "title": "6  O modelo Poisson revisitado",
    "section": "6.3 Exemplo 1: crime de estupro de vulnerável no interior do Amazonas",
    "text": "6.3 Exemplo 1: crime de estupro de vulnerável no interior do Amazonas\nOs dados a seguir foram cedidos pelo Observatório de Violência de Gênero no Amazonas e compreendem os anos entre 2010 e 2012.\n\n\n\nCidade\nvitimas\nPopulacao feminina\n\n\n\n\nAmatura\n3\n639\n\n\nAtalaia do Norte\n6\n905\n\n\nBarreirinha\n12\n1899\n\n\nBenjamin Constant\n2\n2036\n\n\nBoa Vista do Ramos\n6\n1060\n\n\nFonte Boa\n0\n1438\n\n\nJutai\n1\n1143\n\n\nMaues\n13\n3421\n\n\nNhamunda\n9\n1168\n\n\nParintins\n20\n6700\n\n\nSanto Antonio do Ica\n7\n1608\n\n\nSao Paulo de Olivenca\n5\n2033\n\n\nTabatinga\n8\n3095\n\n\nTonantins\n1\n1186\n\n\n\nConsiderando a priori \\(\\pi(\\theta)\\varpropto \\theta^{-1/2}\\) teremos:\n\n# banco de dados\ncasos &lt;- c( 3, 6, 12, 2, 6, 0, 1, 13, 9, 20, 7, 5, 8, 1 )   \n\npop &lt;- c(639, 905, 1899, 2036, 1060, 1438, 1143, 3421, 1168, 6700, 1608, 2033, 3095, 1186)\npop &lt;- pop/10^5\n\nmunicipios &lt;- c( 'Amatura', 'Atl.Norte', 'Barr', 'BC','BV Ramos', 'Fonte B', 'Jutai', 'Maues', 'Nhamunda', 'Parintins', 'StoIca', 'SP Olivenca', 'Tbt','Tonantins')\n\n\n# posteriori\na_post &lt;- sum(casos) + .5\nb_post &lt;- sum(pop)\n\ncurve(dgamma(x,a_post,b_post),230,450 ,lwd = 2, xlab = expression(theta), ylab = 'densidade a posteriori' )\n\n\n\n\nAbaixo, simulamos 50.000 amostras da preditiva a posteriori\n\nB &lt;- 50000 # número de simulações da preditiva a posteriori\nm &lt;- length(casos)\n\npred_mun &lt;- NULL\nfor(i in 1:5000){\n  theta &lt;- rgamma(1, sum(casos) + .5, sum(pop))\n  pred_mun &lt;- rbind(pred_mun, rpois(m , theta * pop))\n}\n\npred_mun &lt;- data.frame(pred_mun)\nnames(pred_mun) &lt;- municipios\nboxplot(pred_mun)\npoints(1:14,casos, pch=16,cex = 1.2, col ='tomato')\n\n\n\n\n\noo &lt;- par()\nmat &lt;- matrix(1:m,ncol=2)\nmat &lt;- rbind(mat, c(15,16))\nlayout(mat, heights = rep(1,14,.5,.5))\n\nfor(i in 1:m){\n  freq &lt;- prop.table( table(pred_mun[,i]) )\n  par(mar = c(1,5,1,1), cex = .8)\n  plot.new()\n  plot.window(xlim=c(0,46), ylim = c(0,.3))\n  points(as.numeric(names(freq)), freq, type='h', lwd = 2)\n  title(ylab=municipios[i])\n  points(casos[i],0,pch=16,col='tomato',cex= 1.2)\n  \n}\n  par(mar = c(2,5,0,1))\n  plot.new()\n  plot.window(xlim=c(0,46), ylim = c(0,.1))\n  segments(0,.05,46,.05,lwd=2)\n for(j in seq(0,45,5)){\n    segments(j,.05,j,.03)\n    text(j,.01,j)\n  }\n    par(mar = c(2,5,0,1))\n  plot.new()\n  plot.window(xlim=c(0,46), ylim = c(0,.1))\n  segments(0,.05,46,.05,lwd=2)\n  for(j in seq(0,45,5)){\n    segments(j,.05,j,.03)\n    text(j,.01,j)\n  }\n\n\n\npar(oo)\n\nWarning in par(oo): parâmetro gráfico \"cin\" não pode ser especificado\n\n\nWarning in par(oo): parâmetro gráfico \"cra\" não pode ser especificado\n\n\nWarning in par(oo): parâmetro gráfico \"csi\" não pode ser especificado\n\n\nWarning in par(oo): parâmetro gráfico \"cxy\" não pode ser especificado\n\n\nWarning in par(oo): parâmetro gráfico \"din\" não pode ser especificado\n\n\nWarning in par(oo): parâmetro gráfico \"page\" não pode ser especificado\n\n\n\np &lt;- NULL\nfor(i in 1:m){\np[i] &lt;- 2*min(mean(pred_mun[,i] &gt; casos[i]),\nmean(pred_mun[,i] &lt; casos[i]))\n}\n\ndata.frame(municipios,p)\n\n    municipios      p\n1      Amatura 0.3268\n2    Atl.Norte 0.0712\n3         Barr 0.0236\n4           BC 0.0212\n5     BV Ramos 0.1456\n6      Fonte B 0.0000\n7        Jutai 0.0464\n8        Maues 0.5104\n9     Nhamunda 0.0116\n10   Parintins 0.6524\n11      StoIca 0.3336\n12 SP Olivenca 0.4140\n13         Tbt 0.4320\n14   Tonantins 0.0344"
  },
  {
    "objectID": "negative_binomial.html#o-modelo-binomial-negativo",
    "href": "negative_binomial.html#o-modelo-binomial-negativo",
    "title": "7  Binomial negativa",
    "section": "7.1 O modelo binomial negativo",
    "text": "7.1 O modelo binomial negativo\nA distribuição Poisson é muito comum em problemas de contagem. Como sua esperança e variância são iguais, o termo sobredispersão foi cunhado na literatura como uma variância maior que a média, o que seria indício de que o modelo Poisson não é adequado (de modo análogo, há o conceito de subdispersão, mas não é um fenômeno comum).\nDizemos que \\(X|\\rho,\\phi\\sim\\hbox{Binomial Negativa}\\) se\n\\[p(x|\\rho,\\phi)=\\frac{\\Gamma(\\phi+x)}{x!\\Gamma(\\phi)}\\rho^\\phi(1-\\rho)^x,\\] onde \\(x\\in\\mathbb{N}\\), \\(\\rho\\in(0,1)\\) e \\(\\phi&gt;0\\).\nExistem diversos motivos para considerar o modelo binomial negativo uma alternativa quando o modelo Poisson não parece ser adequado. Primeiro, temos que \\(E(X|\\rho,\\phi)=\\phi(1-\\rho)/\\rho\\) e \\(Var(X|\\rho,\\phi)=E(X|\\rho,\\phi)/\\rho\\), logo, a sobredispersão está presente no modelo. Além disso, se \\(X|\\lambda\\sim\\hbox{Poisson}(\\lambda)\\) e \\(\\lambda\\sim\\hbox{Gama}(\\phi, \\rho/(1-\\rho))\\), então \\(X|\\phi,\\rho\\sim\\hbox{Binomial Negativa}(\\phi,\\rho)\\) logo, este modelo é uma mistura do modelo Poisson. Por último, fazendo \\[\\mu=\\phi\\frac{1-\\rho}{\\rho}\\Rightarrow \\rho(\\phi)=\\frac{\\phi}{\\phi+\\mu},\\] pode-de mostrar que \\[\\lim_{\\phi\\rightarrow\\infty}p(x|\\phi)=\\frac{e^{-\\mu}\\mu^x}{x!}\\] ou seja, o modelo Poisson também pode ser vist como um caso limite do binomial negativo."
  },
  {
    "objectID": "negative_binomial.html#priori-para-phi-condicionado",
    "href": "negative_binomial.html#priori-para-phi-condicionado",
    "title": "7  Binomial negativa",
    "section": "7.2 Priori para \\(\\phi\\) condicionado",
    "text": "7.2 Priori para \\(\\phi\\) condicionado\nQuando \\(\\phi\\) é conhecido, a verossimilhança do modelo se torna\n\\[L(\\rho|\\phi)\\propto \\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i},\\] logo, o modelo Beta\\((a,b)\\) é conjugado, com a posteriori dada por \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi+a,\\sum_{i=1}^n x_i+b\\right).\\]\nA priori de Jeffreys é dada por\n\\[\\pi(\\rho)\\propto \\frac{1}{\\rho(1-\\rho)^{1/2}},\\] o que implica na posteriori \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi,\\sum_{i=1}^n x_i+\\frac{1}{2}\\right).\\]"
  },
  {
    "objectID": "negative_binomial.html#priori-para-phi",
    "href": "negative_binomial.html#priori-para-phi",
    "title": "7  Binomial negativa",
    "section": "7.3 Priori para \\(\\phi\\)",
    "text": "7.3 Priori para \\(\\phi\\)\nSeja \\(\\pi(\\phi)\\pi(\\rho)\\) a priori para \\((\\phi,\\rho)\\). Então, teremos que\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}\\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i}\\pi(\\phi)\\pi(\\rho).\\]\nAssumindo qualquer uma das prioris da seção anterior, teremos\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\pi(\\rho|\\phi,\\boldsymbol{x}),\\]\nlogo,\n\\[\\pi(\\phi|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\]\nComo a posteriori de \\(\\phi\\) não é uma distribuição conhecida, precisamos construir um simulador. O algoritmo Metropolis-Hastings é uma boa escolha, uma vez que a constante de proporcionalidade da densidade é desconhecida.\n\nAlgoritmo Metropolis-Hastings\nO Metropolis-Hastings simula se utiliza de uma distribuição que sabemos simular (denominada proposta) para gerar uma cadeia de Markov cuja distribuição estacionária é a distribuição de interesse.\nNa \\(j\\)-ésima itereção, a simulação do valor proposto \\(\\phi^*\\) é baseada no valor atual da cadeia, \\(\\phi^{(j-1)}\\). Como \\(\\phi&gt;0\\), a proposta \\(\\phi^*\\sim \\hbox{Gamma}(\\tau\\phi^{(j-1)},\\tau)\\) é adequada uma vez que \\[E(\\phi^*)=\\phi^{(j-1)}\\] e \\[\\sqrt{Var(\\phi^*)}=\\frac{\\phi^{(j-1)}}{\\tau}\\] Acima, \\(\\tau\\) é denominado tunning (afinação em tradução livre) e deve ser escolhido para que a cadeia tenha o número de aceites da proposta controlado (algo em torno de 23% ).\nAbaixo, segue o algoritmo\n\nFaça \\(j=0\\) e escolha um valor para \\(\\phi^{(0)}\\) (a estimativa de máxima verossimilhança, por exemplo). Faça um contador de aceites, começando com \\(k=0\\).\nPara o passo \\(j\\):\n\n\nSimule \\(\\phi^*\\sim\\hbox{Gama}(\\tau\\phi^{j-1},\\tau)\\)\nCalcule\n\n\\[prob = \\frac{\\pi(\\phi^*|\\boldsymbol{x})}{\\pi(\\phi^{(j-1)}|\\boldsymbol{x})}\\frac{g(\\phi^{(j-1)}|\\tau\\phi^*,\\tau)}{g(\\phi^*|\\tau\\phi^{(j-1)},\\tau)},\\] onde \\(g(.|a,b)\\) é a função densidade do modelo gama. + Simule \\(u\\sim\\hbox{Uniforme}(0,1)\\). Se \\(u&lt;prob\\), faça \\(\\phi^{(j)}=\\phi^*\\) e \\(k=k+1\\) (houve um aceite). Senão, faça \\(\\phi^{(j)}=\\phi^{(j-1)}\\)."
  },
  {
    "objectID": "aproximacao_normal.html",
    "href": "aproximacao_normal.html",
    "title": "8  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "",
    "text": "Assuma que \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^q\\). Seja \\(\\ell(\\boldsymbol{\\theta})=\\log L(\\boldsymbol{\\theta})\\) a função log-verossimilhança e \\(\\hat{\\boldsymbol{\\theta}}\\) a estimativa de máxima verossimilhaça para \\(\\boldsymbol{\\theta}\\). Considere a seguinte aproximação de \\(\\ell(\\boldsymbol{\\theta})\\) em séries de Taylor\n\\[\\ell(\\boldsymbol{\\theta})\\approx  \\ell(\\hat{\\boldsymbol{\\theta}})+\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\] onde \\(\\boldsymbol{\\theta}\\) é a matriz hessiana (de derivadas segunda) aplicada em \\(\\hat{\\boldsymbol{\\theta}}\\). Deste modo, teremos que \\[\\pi(\\boldsymbol{\\theta}|\\boldsymbol{x})\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\left[-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\right](\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\right\\}\\pi(\\boldsymbol{\\theta})\\]\nUtilizando a priori imprópria \\(\\pi(\\boldsymbol{\\theta})\\), temos que \\(\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx \\hbox{Normal}(\\hat{\\boldsymbol{\\theta}},-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})^{-1})\\).\nNote que as informações necessárias para a aproximação da posteriori acima podem ser obtidas via função optim.\n\nExemplo  A amostra abaixo foi simulada do modelo Gama\\((\\alpha,\\beta)\\) (o valor dos parâmetros foram omitidos de propósito)\n\nx\n\n [1] 0.2769550 1.1902521 1.1543901 0.6836040 1.2951363 0.8468467 0.7626888\n [8] 0.3830976 0.2270072 0.2785412 0.3853067 0.4818242 0.2021683 0.8914625\n[15] 0.7718524 0.9455476 0.8702839 0.5309044 1.2858882 1.0415047\n\n\nComo \\(\\alpha,\\beta&gt;0\\), considere que \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\) (deste modo, \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^2\\)).\nA função de log-verossimilhança deste modelo é\n\nlogveross &lt;- function(theta){ sum(dgamma(x, exp(theta[1]), exp(theta[2]), log = T))\n}\n\nPodemos utilizar a função optim para obter as estimativas de máxima verossimilhança e a matriz hessiana. Contudo, primeiro devemos observar que esta função é um minimizador, logo, queremos que \\(\\boldsymbol{\\theta}\\) que minimize \\(-\\ell({\\boldsymbol{\\theta}})\\).\n\nopt &lt;- optim( c(0,0), function(q) -logveross(q), hessian = T)\nopt\n\n$par\n[1] 1.245897 1.567152\n\n$value\n[1] 7.435047\n\n$counts\nfunction gradient \n      65       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]      [,2]\n[1,]  80.46195 -69.52104\n[2,] -69.52104  69.52342\n\n\nNo objeto opt, a lista par é o vetor com as estimativas de máxima verossimilhança, enquanto que hessian é o valor de \\(-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\).\nA inversa de opt$hessian vai dar a matriz de covariância entre \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori.\n\nSigma &lt;- solve(opt$hessian)\nSigma\n\n           [,1]       [,2]\n[1,] 0.09138023 0.09137711\n[2,] 0.09137711 0.10575762\n\n\nAgora, podemos simular \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori:\n\nrequire(mvtnorm)\n\nCarregando pacotes exigidos: mvtnorm\n\ntheta_sim &lt;- rmvnorm(500, opt$par, Sigma)\n\nPor último, podemos fazer inferências sobre \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\):\n\n# intervalos de credibilidade para alfa\nquantile(exp(theta_sim[,1]), c(.025,.975))\n\n    2.5%    97.5% \n1.978850 6.350455 \n\n# intervalos de credibilidade para beta\nquantile(exp(theta_sim[,2]), c(.025,.975))\n\n    2.5%    97.5% \n2.582863 8.865732"
  },
  {
    "objectID": "aproximacao_normal.html#aproximação-da-posteriori-pela-distribuição-normal",
    "href": "aproximacao_normal.html#aproximação-da-posteriori-pela-distribuição-normal",
    "title": "8  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "8.1 Aproximação da posteriori pela distribuição normal",
    "text": "8.1 Aproximação da posteriori pela distribuição normal\nAssuma que \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^q\\). Seja \\(\\ell(\\boldsymbol{\\theta})=\\log L(\\boldsymbol{\\theta})\\) a função log-verossimilhança e \\(\\hat{\\boldsymbol{\\theta}}\\) a estimativa de máxima verossimilhaça para \\(\\boldsymbol{\\theta}\\). Considere a seguinte aproximação de \\(\\ell(\\boldsymbol{\\theta})\\) em séries de Taylor\n\\[\\ell(\\boldsymbol{\\theta})\\approx  \\ell(\\hat{\\boldsymbol{\\theta}})+\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\] onde \\(\\boldsymbol{\\theta}\\) é a matriz hessiana (de derivadas segunda) aplicada em \\(\\hat{\\boldsymbol{\\theta}}\\). Deste modo, teremos que \\[\\pi(\\boldsymbol{\\theta}|\\boldsymbol{x})\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\left[-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\right](\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\right\\}\\pi(\\boldsymbol{\\theta})\\]\nUtilizando a priori imprópria \\(\\pi(\\boldsymbol{\\theta})\\), temos que \\(\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx \\hbox{Normal}(\\hat{\\boldsymbol{\\theta}},-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})^{-1})\\).\nNote que as informações necessárias para a aproximação da posteriori acima podem ser obtidas via função optim.\n\nExemplo  A amostra abaixo foi simulada do modelo Gama\\((\\alpha,\\beta)\\) (o valor dos parâmetros foram omitidos de propósito)\n\nx\n\n [1] 0.2769550 1.1902521 1.1543901 0.6836040 1.2951363 0.8468467 0.7626888\n [8] 0.3830976 0.2270072 0.2785412 0.3853067 0.4818242 0.2021683 0.8914625\n[15] 0.7718524 0.9455476 0.8702839 0.5309044 1.2858882 1.0415047\n\n\nComo \\(\\alpha,\\beta&gt;0\\), considere que \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\) (deste modo, \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^2\\)).\nA função de log-verossimilhança deste modelo é\n\nlogveross &lt;- function(theta){ sum(dgamma(x, exp(theta[1]), exp(theta[2]), log = T))\n}\n\nPodemos utilizar a função optim para obter as estimativas de máxima verossimilhança e a matriz hessiana. Contudo, primeiro devemos observar que esta função é um minimizador, logo, queremos que \\(\\boldsymbol{\\theta}\\) que minimize \\(-\\ell({\\boldsymbol{\\theta}})\\).\n\nopt &lt;- optim( c(0,0), function(q) -logveross(q), hessian = T)\nopt\n\n$par\n[1] 1.245897 1.567152\n\n$value\n[1] 7.435047\n\n$counts\nfunction gradient \n      65       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]      [,2]\n[1,]  80.46195 -69.52104\n[2,] -69.52104  69.52342\n\n\nNo objeto opt, a lista par é o vetor com as estimativas de máxima verossimilhança, enquanto que hessian é o valor de \\(-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\).\nA inversa de opt$hessian vai dar a matriz de covariância entre \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori.\n\nSigma &lt;- solve(opt$hessian)\nSigma\n\n           [,1]       [,2]\n[1,] 0.09138023 0.09137711\n[2,] 0.09137711 0.10575762\n\n\nAgora, podemos simular \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori:\n\nrequire(mvtnorm)\n\nCarregando pacotes exigidos: mvtnorm\n\ntheta_sim &lt;- rmvnorm(500, opt$par, Sigma)\n\nPor último, podemos fazer inferências sobre \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\):\n\n# intervalos de credibilidade para alfa\nquantile(exp(theta_sim[,1]), c(.025,.975))\n\n    2.5%    97.5% \n1.978850 6.350455 \n\n# intervalos de credibilidade para beta\nquantile(exp(theta_sim[,2]), c(.025,.975))\n\n    2.5%    97.5% \n2.582863 8.865732"
  },
  {
    "objectID": "aproximacao_normal.html#metropolis-revisitado",
    "href": "aproximacao_normal.html#metropolis-revisitado",
    "title": "8  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "8.2 Metropolis revisitado",
    "text": "8.2 Metropolis revisitado\nA diferença entre o algoritmo Metropolis e o Metropolis-Hastings está na escolha da distribuição proposta. No primeiro, a proposta é simétrica, \\[g(x|y)=g(y|x).\\] Com isso, teremos que \\[\\frac{f(x)}{f(y)}\\frac{g(y|x)}{g(x|y)}=\\frac{f(x)}{f(y)}\\] e a probabilidade de aceitação da cadeia é baseada somente na distribuição alvo \\(f\\).\nNo algoritmo Metropolis, é comum escolher a distribuição proposta como sendo uma normal. Uma escolha razoável é utilizar como proposta aproximação normal vista na seção anterior.\n\nExemplo  Consideremos novamente a amostra do exemplo anterior. A função de verossimilhança é \\[L(\\theta)=\\prod_{i=1}^n \\frac{\\beta(\\theta_2)^{\\alpha(\\theta_1)}}{\\Gamma(\\alpha(\\theta_1))} x_i^{\\alpha(\\theta_1)-1}e^{-\\beta(\\theta_2)x_i}\\] onde \\(\\alpha(\\theta_1)=e^{\\theta_1}\\), \\(\\beta(\\theta_2)=e^{\\theta_2}\\). Além disso ,considere ad prioris independentes \\(\\theta_i\\sim\\hbox{Normal}(0,100)\\). Então, devemos simular do modelo\n\\[\\pi(\\theta|\\boldsymbol{x})\\propto \\left[\\frac{\\beta(\\theta_2)^{\\alpha(\\theta_1)}}{\\Gamma(\\alpha(\\theta_1))}\\right]^n \\left[\\prod_{i=1}^n x_i\\right]^{\\alpha(\\theta_1)}e^{-\\beta(\\theta_2)\\sum_{i=1}^{n}x_i}e^{-\\frac{1}{200}(\\theta_1^2 + \\theta_2^2)}\\]\nA posteriori aproximada, que encontramos no exemplo anterior é \\[\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx N \\left[ \\left(\\begin{array}{c}1,24\\\\1,56 \\end{array}\\right),\\left(\\begin{array}{cc}0,09 & 0,09\\\\0,09 &0,11\\end{array}\\right)\\right]\\]\nVamos aproveitar a estrutura de covariâncias acima para usar a proposta\n\\[\\boldsymbol{\\theta}^*|\\boldsymbol{x}\\sim N \\left[ \\boldsymbol{\\theta}^{(j-1)},\\tau\\left(\\begin{array}{cc}0,09 & 0,09\\\\0,09 &0,11\\end{array}\\right)\\right]\\] onde \\(\\boldsymbol{\\theta}^*\\) é o candidato gerado e \\(\\boldsymbol{\\theta}^{(j)}\\) é o estado atual da cadeia e \\(\\tau\\) é o tunning da cadeia.\n\nB &lt;- 10000 # número de iterações\ntheta &lt;- array(NA_real_, c(B,2))\n\ntheta[1,] &lt;- opt$par # valor inicial da cadeia é a emv\ntau &lt;- 1             # tunning\ncont &lt;- 0            # contador de aceites\n\nfor(j in 2:B){\n  #simule um candidato\n  theta_cand &lt;- rmvnorm(1, theta[j-1,], tau*Sigma)\n  \n  # calcule a probabilidade do salto\n  lnum &lt;- logveross(theta_cand) +\n    sum(dnorm(theta_cand[1,],0,10, log = T))\n  \n  lden &lt;- logveross(theta[j-1,]) +\n    sum(dnorm(theta[j-1,],0,10, log = T))\n  \n  prob &lt;- exp( lnum - lden)\n  \n  # verifique o salto\n  u &lt;- runif(1)\n  if( u &lt; prob){\n    theta[j, ] &lt;- theta_cand\n    cont &lt;- cont+1\n  } else {\n    theta[j,] &lt;- theta[j-1,]\n  }\n}\n\ncont/B\n\n[1] 0.5628"
  }
]