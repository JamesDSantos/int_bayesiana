[
  {
    "objectID": "regressao.html",
    "href": "regressao.html",
    "title": "12  O modelo de regressão linear normal",
    "section": "",
    "text": "12.1 Introdução\nDenominamos regressão o problema de determinar a média de \\(Y\\) dado o vetor \\(\\boldsymbol{x}'=(x_1,\\ldots,x_q)\\). Em particular se\n\\[E(Y|\\boldsymbol{x},\\boldsymbol{\\beta})=\\boldsymbol{x}'\\boldsymbol{\\beta}=\\sum_{j=1}^q x_j\\beta_j,\\] dizemos que a regressão é linear (em \\(\\boldsymbol{\\beta}\\)) e o objetivo passa a ser fazer inferências sobre \\(\\boldsymbol{\\beta}\\).\nNo problema de regressão, as seguintes nomenclaturas são usuais:\nOs termos input e output são usuais em aprendizagem de máquina, enquanto que variável independente e dependente são usuais na área da saúde (vale ressaltar que não há relação com a independência sob o ponto de vista da probabilidade, pois claramente \\(Y\\) e \\(\\boldsymbol{X}\\) são dependentes).\nSejam \\(Y_1,\\ldots,Y_n\\) uma amostra de variáveis aleatórias independentes. Sejam \\(\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_n\\) vetores de dimensão \\(q\\). Então, o modelo de regressão linear normal é dado por\n\\[y|\\boldsymbol{x},\\boldsymbol{\\beta}\\sim\\hbox{Normal}(\\boldsymbol{x}'\\boldsymbol{\\beta},\\sigma^2).\\]\nComo \\(Y_1,\\ldots,Y_n\\) são independentes, temos que \\(\\boldsymbol{Y}'=(Y_1,\\ldots,Y_n)\\) tem distribuição normal multivariada com média\n\\[E(\\boldsymbol{Y}|\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_n)=\\left(\\begin{array}{c}E(Y_1|\\boldsymbol{x}_1)\\\\ \\vdots \\\\ E(Y_n|\\boldsymbol{x}_n)\\end{array}\\right)=\\left(\\begin{array}{c}\\boldsymbol{x}_1'\\boldsymbol{\\beta}\\\\ \\vdots \\\\ \\boldsymbol{x}_n'\\boldsymbol{\\beta}\\end{array}\\right)=\\underbrace{\\left(\\begin{array}{c}\\boldsymbol{x}_1'\\\\ \\vdots \\\\ \\boldsymbol{x}_n'\\end{array}\\right)}_{\\boldsymbol{X}}\\boldsymbol{\\beta}=\\boldsymbol{X}\\boldsymbol{\\beta}\\]\ne como \\(Var(Y_i|\\boldsymbol{X})=Var(Y_i|\\boldsymbol{x}_i)=\\sigma^2\\) e, para \\(i\\neq j,\\) \\(Cov(Y_i,Y_j|\\boldsymbol{X})=0\\), teremos que \\[Var(\\boldsymbol{Y}|\\boldsymbol{X})=\\sigma^2\\text{I}_n\\] Portanto \\(\\boldsymbol{Y}|\\boldsymbol{X},\\boldsymbol{\\beta},\\sigma^2\\sim\\hbox{Normal}(\\boldsymbol{X}\\boldsymbol{\\beta},\\sigma^2\\text{I}_q)\\). Sua função de verossimilhança é\n\\[L(\\boldsymbol{\\beta},\\sigma^2)\\propto \\left(\\frac{1}{2\\pi\\sigma^2}\\right)^{\\frac{n}{2}}e^{-\\frac{1}{2\\sigma^2}(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})'(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})}.\\] Note que\n\\[\\begin{align}\n(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})'(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})&= \\boldsymbol{y}'\\boldsymbol{y}+\\boldsymbol{\\beta}'(\\boldsymbol{X}'\\boldsymbol{X})\\boldsymbol{\\beta}-2\\boldsymbol{\\beta}'\\boldsymbol{X}'\\boldsymbol{y}\\\\&=\n\\boldsymbol{y}'\\boldsymbol{y}+\\boldsymbol{\\beta}'(\\boldsymbol{X}'\\boldsymbol{X})\\boldsymbol{\\beta}-2\\boldsymbol{\\beta}'(\\boldsymbol{X}'\\boldsymbol{X})\\underbrace{(\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}'\\boldsymbol{y}}_{\\hat{\\boldsymbol{\\beta}}}\n\\\\&=\n\\boldsymbol{y}'\\boldsymbol{y}+\\boldsymbol{\\beta}'(\\boldsymbol{X}'\\boldsymbol{X})\\boldsymbol{\\beta}-2\\boldsymbol{\\beta}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}\\pm \\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}\\\\&=(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})+\\boldsymbol{y}'\\boldsymbol{y}-\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}\\end{align}\n\\] Observe que \\[\\begin{align}\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}&=((\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}'\\boldsymbol{y})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}'\\boldsymbol{y}\\\\\n&=((\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}'\\boldsymbol{y})'\\boldsymbol{X}'\\boldsymbol{y}\\\\&=\n\\boldsymbol{y}\\boldsymbol{X}(\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}'\\boldsymbol{y}\\end{align}\\] logo\n\\[\\begin{align}\n(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})'(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})&= (\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})+\\underbrace{\\boldsymbol{y}'(\\text{I}_n-\\boldsymbol{X}(\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}')\\boldsymbol{y}}_{SQR}\\end{align}\n\\] onde \\(SQR\\) é a sigla para soma de quadrados de resíduos. Esse termo tem esse nome porque \\[SQR=(\\boldsymbol{y}-\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{y}-\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}})\\] e \\[\\boldsymbol{r}=\\boldsymbol{y}-\\boldsymbol{X}\\hat{\\boldsymbol{\\beta}}\\] é denominado vetor de resíduos. Portanto, a função de verossimilhança pode ser reescrita como\n\\[L(\\boldsymbol{\\beta},\\sigma^2)\\propto \\left(\\frac{1}{2\\pi\\sigma^2}\\right)^{\\frac{n}{2}}e^{-\\frac{1}{2\\sigma^2}(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})}e^{-\\frac{1}{2\\sigma^2}SQR}.\\] ## Priori conjugada e suas limitações\nSeja \\(\\phi=1/\\sigma^2\\). Então, a priori normal-gama, também escrita como \\[\\begin{align}\\boldsymbol{\\beta}|\\phi,\\boldsymbol{X}&\\sim\\hbox{Normal}(\\boldsymbol{\\beta}_0,\\phi^{-1} C_0^{-1})\\\\ \\phi&\\sim\\hbox{Gama}\\left(\\frac{n_0}{2},\\frac{s_0}{2}\\right)\\end{align}\\] é conjugada para o modelo linear. A posteriori é dada por\n\\[\\begin{align}f(\\boldsymbol{\\beta},\\phi|\\text{dados})&\\propto \\phi^\\frac{n}{2}e^{-\\frac{\\phi}{2}(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})-\\frac{\\phi}{2}SQR}\\times\\\\&|\\phi\\boldsymbol{C}_0|^{1/2}e^{-\\frac{\\phi}{2}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)'\\boldsymbol{C}_0(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)]}\\phi^{\\frac{n_0}{2}-1}e^{-\\frac{s_0}{2}\\phi}\\\\&=\\phi^{\\frac{q}{2}}e^{-\\frac{\\phi}{2}[(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})+(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)'\\boldsymbol{C}_0(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)]}\\phi^{\\frac{n+n_0}{2}-1}e^{-\\frac{\\phi}{2}(SQR+s_0)}\\end{align}\\] Como \\[\\begin{align}\n&(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})+(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)'\\boldsymbol{C}_0(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)\\\\&=\\boldsymbol{\\beta}'[\\underbrace{(\\boldsymbol{X}'\\boldsymbol{X})+\\boldsymbol{C}_0}_{\\boldsymbol{C}_1}]\\boldsymbol{\\beta}-2\\boldsymbol{\\beta}'( (\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{C}_0\\boldsymbol{\\beta}_0)+\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{\\beta}_0'\\boldsymbol{C}_0\\boldsymbol{\\beta}_0\\\\\n&=\\boldsymbol{\\beta}'\\boldsymbol{C}_1\\boldsymbol{\\beta}-2\\boldsymbol{\\beta}'\\boldsymbol{C}_1[\\underbrace{\\boldsymbol{C}_1^{-1}( (\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{C}_0\\boldsymbol{\\beta}_0)}_{\\tilde{\\boldsymbol{\\beta}}}]+\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{\\beta}_0'\\boldsymbol{C}_0\\boldsymbol{\\beta}_0\\\\\n&=\\boldsymbol{\\beta}'\\boldsymbol{C}_1\\boldsymbol{\\beta}-2\\boldsymbol{\\beta}'\\boldsymbol{C}_1\\tilde{\\boldsymbol{\\beta}}\\pm\\tilde{\\boldsymbol{\\beta}}'\\boldsymbol{C}_1\\tilde{\\boldsymbol{\\beta}}+\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{\\beta}_0'\\boldsymbol{C}_0\\boldsymbol{\\beta}_0\\\\\n&=(\\boldsymbol{\\beta}-\\tilde{\\boldsymbol{\\beta}})'\\boldsymbol{C}_1(\\boldsymbol{\\beta}-\\tilde{\\boldsymbol{\\beta}})+\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{\\beta}_0'\\boldsymbol{C}_0\\boldsymbol{\\beta}_0-\\tilde{\\boldsymbol{\\beta}}'\\boldsymbol{C}_1\\tilde{\\boldsymbol{\\beta}}\n\\end{align}\\] Além disso, pode-se mostrar que \\[\\hat{\\boldsymbol{\\beta}}'(\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{\\beta}_0'\\boldsymbol{C}_0\\boldsymbol{\\beta}_0-\\tilde{\\boldsymbol{\\beta}}'\\boldsymbol{C}_1\\tilde{\\boldsymbol{\\beta}}=(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)'(\\boldsymbol{C}_0+(\\boldsymbol{X}'\\boldsymbol{X})^{-1})^{-1}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)\\] \\[\\begin{align}f(\\boldsymbol{\\beta},\\phi|\\text{dados})&\\propto\\phi^{\\frac{q}{2}}e^{-\\frac{\\phi}{2}(\\boldsymbol{\\beta}-\\tilde{\\boldsymbol{\\beta}})'\\boldsymbol{C}_1(\\boldsymbol{\\beta}-\\tilde{\\boldsymbol{\\beta}})}\\phi^{\\frac{n+n_0}{2}-1}e^{-\\frac{\\phi}{2}(SQR+s_0+(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)'(\\boldsymbol{C}_0+(\\boldsymbol{X}'\\boldsymbol{X})^{-1})^{-1}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0))}\\end{align}\\] ou seja \\[\\begin{align}\\boldsymbol{\\beta}|\\phi,\\hbox{dados}&\\sim\\hbox{Normal}(\\tilde{\\boldsymbol{\\beta}},\\phi^{-1}\\boldsymbol{C}_1^{-1})\\\\\n\\phi|\\text{dados}&\\sim\\hbox{Gama}\\left(\\frac{n_0+n}{2},\\frac{s_1}{2}\\right)\n\\end{align}\\] onde \\[s_1=SQR+s_0+(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)'(\\boldsymbol{C}_0+(\\boldsymbol{X}'\\boldsymbol{X})^{-1})^{-1}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)\\]\nO estimador de Bayes para \\(\\boldsymbol{\\beta}\\) é\n\\[\\tilde{\\boldsymbol{\\beta}}=\\boldsymbol{C}_1^{-1}[ (\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}+\\boldsymbol{C}_0\\boldsymbol{\\beta}_0]\\]\nPara elicitar corretamente a priori conjugada é necessário elicitar a matriz \\(\\boldsymbol{C}_0\\), que é um desafio. A solução mais simples é considerar que \\(\\boldsymbol{C_0}=\\lambda \\text{I}_q\\) e valores pequenos de \\(\\lambda\\) levam a uma informação a priori mais difusa. Essa solução é utilizada na inferência frequentista, conforme podemos ver abaixo.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>O modelo de regressão linear normal</span>"
    ]
  },
  {
    "objectID": "regressao.html#introdução",
    "href": "regressao.html#introdução",
    "title": "12  O modelo de regressão linear normal",
    "section": "",
    "text": "\\(Y\\): variável resposta, output, resultado, variável dependente\n\\(\\boldsymbol{x}\\): variáveis regressoras, input, variáveis independentes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA relação com a Regressão Ridge O estimador frequentista existe apenas quando \\(\\boldsymbol{X}'\\boldsymbol{X}\\) tem inversa. Essa inversa pode não existir quando \\(q&gt;n\\) ou quando as colunas de \\(\\boldsymbol{X}\\) são altamente correlacionada (esse fenômeno é denominado multicolinearidade). Uma solução é utilizar o estimador de regressão de Ridge, dado por\n\\[\\hat{\\boldsymbol{\\beta}}_{R}(\\lambda)=[\\lambda\\text{I}_q+ \\boldsymbol{X}'\\boldsymbol{X}]^{-1}\\boldsymbol{X}'\\boldsymbol{Y},\\] onde \\(\\lambda\\) é denominado shrinkage (algo como parâmetro de contração, embora também possa ser denominado parâmetro de regularização). A escolha de \\(\\lambda\\) é um problema em aberto, pois não há garantias de resultados ótimos.\nSob o ponto de vista bayesiano, fazendo \\(\\boldsymbol{\\beta}_0=\\text{0}_q\\) e \\(\\boldsymbol{C}_0=\\lambda\\text{I}_q\\), temos que\n\\[\\begin{align}\\tilde{\\boldsymbol{\\beta}}&=(\\lambda\\text{I}_q +\\boldsymbol{X}'\\boldsymbol{X})^{-1} (\\boldsymbol{X}'\\boldsymbol{X})\\hat{\\boldsymbol{\\beta}}\\\\&=\n(\\lambda\\text{I}_q +\\boldsymbol{X}'\\boldsymbol{X})^{-1} (\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\boldsymbol{X}'\\boldsymbol{Y}\\\\&=\n[\\lambda\\text{I}_q+ \\boldsymbol{X}'\\boldsymbol{X}]^{-1}\\boldsymbol{X}'\\boldsymbol{Y}=\\hat{\\beta}(\\lambda),\\end{align}\\] ou seja, o estimador de Bayes é o estimador da regressão Ridge. Neste caso, o aumento de \\(\\lambda\\) implica no aumento da crença a priori de que \\(\\boldsymbol{\\beta}\\) é zero.\n\n\nExemplo. mtcars\nO banco de dados mtcars, disponível no R, apresenta estatísticas de design e performance de 32 automóveis. Considere as seguintes variáveis:\n\nmpg: milhas/galão\ncyl: número de cilindros\ndisp: deslocamento (polegadas cúbicas)\nhp: potência bruta\nwt: peso (em libras)\n\nConsiderando mpg como variável resposta, vamos analisar sua relação com as demais.\n\nbanco  &lt;- mtcars[,c(\"mpg\",\"cyl\", \"disp\",\"hp\",\"wt\")]\npairs(banco)\n\n\n\n\n\n\n\n\nAlgumas relações, como disp - deslocamento - e hp - potência bruta, não parecem lineares. Podemos linearizar a relação aplicando a transformação logarítmica\n\nbanco2  &lt;- banco\nbanco2$disp &lt;- log ( banco$disp )\nbanco2$hp   &lt;- log ( banco$hp )\npairs(banco2)\n\n\n\n\n\n\n\n\nVamos ajustar um modelo de regressão linear com \\(\\boldsymbol{\\beta}_0=\\text{0}_5\\), \\(n_0=0,01,s_0=0,01\\), \\(\\boldsymbol{C}_0=\\lambda\\text{I}_5\\) para diferentes valores de \\(\\lambda\\). Abaixo, apresentamos as estimativas de Bayes para \\(\\boldsymbol{\\beta}\\) com diferentes valores de \\(\\lambda\\). Para verificar como as estimativas são influenciadas por \\(\\lambda\\), vamos representar as estimativas de máxima verossimilhança nas linhas tracejadas. Observe que as estimativas falham em se aproximar das estimativas de máxima verossmilhança mesmo para \\(\\lambda\\) pequeno\n\nX &lt;- as.matrix(cbind(1,banco2[,-1]))\ny =  banco2[,1]\n\nbeta_til &lt;- function(lambda) solve( diag(lambda,5) + t(X)%*%X )%*%t(X)%*%y\nbeta_emv &lt;- beta_til(0)\n\nm = 20\nlambda = seq(.001,m,.001)\nresp = NULL\nfor(l in lambda){\n  resp &lt;- rbind(resp, beta_til(l)[,1])\n}\n\nplot.new()\nplot.window(ylim=c(-5,10), xlim=c(0,m))\nlines(lambda, resp[,2],col=1,lwd=2)\nabline(h=beta_emv[2,1],col=1, lty = 2,lwd=2)\nlines(lambda, resp[,3],col=2,lwd=2)\nabline(h=beta_emv[3,1],col=2, lty = 2,lwd=2)\nlines(lambda, resp[,4],col=3,lwd=2)\nabline(h=beta_emv[4,1],col=3, lty = 2,lwd=2)\nlines(lambda, resp[,5],col=4,lwd=2)\nabline(h=beta_emv[5,1],col=4, lty = 2,lwd=2)\npoints(cbind(lambda[1],resp[1,]), pch = 16, col=1:4, cex= 1.2)\naxis(1)\naxis(2)\nlegend('topright',names(banco2)[-1],col=1:4,bty='n',lty=1)\ntitle(xlab=expression(lambda), ylab='Estimativas dos coeficientes de regressão')",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>O modelo de regressão linear normal</span>"
    ]
  },
  {
    "objectID": "regressao.html#a-priori-g-de-zellner",
    "href": "regressao.html#a-priori-g-de-zellner",
    "title": "12  O modelo de regressão linear normal",
    "section": "12.2 A priori \\(G\\) de Zellner",
    "text": "12.2 A priori \\(G\\) de Zellner\nA maior dificuldade na priori conjugada está na dificuldade em introduzir a estrutura de correlação a priori para \\(\\boldsymbol{\\beta}\\). A priori \\(G\\) de Zellner resolve essa questão. Para tanto, observe que \\[\\hat{\\boldsymbol{\\beta}}\\sim\\hbox{Normal}(\\boldsymbol{\\beta},\\phi^{-1}(\\boldsymbol{X}'\\boldsymbol{X})^{-1})\\] A ideia central é utilizar a matriz \\((\\boldsymbol{X}'\\boldsymbol{X})^{-1}\\) para construção da estrutura de covariâncias a priori para \\(\\boldsymbol{\\beta}\\).\nA priori de \\(G\\) de Zellner é dada por \\[\\begin{align}\\boldsymbol{\\beta}|\\phi&\\sim\\hbox{Normal}(\\boldsymbol{\\beta}_0,\\phi^{-1}\\lambda^{-1}(\\boldsymbol{X}'\\boldsymbol{X})^{-1})\\\\f(\\phi)&\\propto \\frac{1}{\\phi}\\end{align}\\] Deste modo ,a posteriori é dada por\n\\[\\begin{align}f(\\boldsymbol{\\beta},\\phi|\\text{dados})&\\propto \\phi^\\frac{n}{2}e^{-\\frac{\\phi}{2}(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})-\\frac{\\phi}{2}SQR}\\times\\\\&|\\phi\\boldsymbol{X}'\\boldsymbol{X}|^{1/2}e^{-\\frac{\\phi}{2}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)'\\lambda(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)]}\\frac{1}{\\phi}\\\\&=\\phi^{\\frac{q}{2}}e^{-\\frac{\\phi}{2}[(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\boldsymbol{X}'\\boldsymbol{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})+\\lambda(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)'\\boldsymbol{X}'\\boldsymbol{X}(\\boldsymbol{\\beta}-\\boldsymbol{\\beta}_0)]}\\phi^{\\frac{n}{2}-1}e^{\\frac{\\phi}{2}SQR}\\end{align}\\] Pode mostrar que o termo na primeira exponencial acima é dado por \\[(\\boldsymbol{\\beta}-\\tilde{\\boldsymbol{\\beta}})'(1+\\lambda)\\boldsymbol{X}'\\boldsymbol{X}(\\boldsymbol{\\beta}-\\tilde{\\boldsymbol{\\beta}})+(\\boldsymbol{\\beta}_0-\\tilde{\\boldsymbol{\\beta}})'\\frac{\\lambda}{1+\\lambda}\\boldsymbol{X}'\\boldsymbol{X}(\\boldsymbol{\\beta}_0-\\tilde{\\boldsymbol{\\beta}})\\] onde \\[\\tilde{\\boldsymbol{\\beta}}=\\frac{\\lambda}{1+\\lambda}\\boldsymbol{\\beta}_0+\\frac{1}{1+\\lambda}\\hat{\\boldsymbol{\\beta}}.\\] Então, \\[\\begin{align}\n\\boldsymbol{\\beta}|\\phi,\\hbox{dados}&\\sim\\hbox{Normal}(\\tilde{\\boldsymbol{\\beta}}, \\phi^{-1}(1+\\lambda)^{-1}(\\boldsymbol{X}'\\boldsymbol{X})^{-1})\\\\\n\\phi|\\text{dados}&\\sim\\hbox{Gama}\\left(\\frac{n}{2},\\frac{s_1}{2}\\right),\n\\end{align}\\] onde \\[s_1=SQR+\\frac{\\lambda}{1+\\lambda}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)'\\boldsymbol{X}'\\boldsymbol{X}^{-1}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}_0)\\]\n\nExemplo mtcars\nVamos refazer o problema anterior considerando ainda \\(\\boldsymbol{\\beta}=\\text{0}_5\\) para diferentes valores de \\(\\lambda\\). Nesse caso\n\\[\\tilde{\\boldsymbol{\\beta}}=\\frac{1}{1+\\lambda}\\hat{\\boldsymbol{\\beta}}.\\]\n\nX &lt;- as.matrix(cbind(1,banco2[,-1]))\ny =  banco2[,1]\n\nSa = solve(t(X)%*%X)\nbeta_til &lt;- function(lambda) (Sa%*%t(X)%*%y)/(1+lambda)\n\nm=5\nlambda = seq(.001,4,.01)\nresp = NULL\nfor(l in lambda){\n  resp &lt;- rbind(resp, beta_til(l)[,1])\n}\n\nplot.new()\nplot.window(ylim=c(-5,2.5), xlim=c(0,m))\nlines(lambda, resp[,2],col=1, lwd = 2)\nabline(h = beta_emv[2,1], col = 1, lwd = 2,lty=2)\nlines(lambda, resp[,3],col=2, lwd = 2)\nabline(h = beta_emv[3,1], col = 2, lwd = 2,lty=2)\nlines(lambda, resp[,4],col=3, lwd= 2)\nabline(h = beta_emv[4,1], col = 3, lwd =2,lty=2)\nlines(lambda, resp[,5],col=4, lwd= 2)\nabline(h = beta_emv[5,1], col = 4, lwd = 2,lty=2)\naxis(1)\naxis(2)\nlegend('topright',names(banco2)[-1],col=1:4,bty='n',lty=1, bg = 'white')\n\n\n\n\n\n\n\n\nPodemos perceber que a priori \\(G\\) de Zellner é menos sensível que a priori conjugada. Selecionando \\(\\lambda=0,01\\), vamos simular amostras da posteriori e analisar se 0 é um valor plausível para cada \\(\\beta\\). Abaixo apresentamos as densidades a posteriori estimadas e os respectivos intervalos de credibilidade 95%.\n\nrequire(mvtnorm)\n\nCarregando pacotes exigidos: mvtnorm\n\n# simulando phi\nX= as.matrix(cbind(1,banco2[,-1]))\ny = banco2[,1]\nSX = solve(t(X)%*%X)\nlambda = .01\nbeta_emv &lt;- SX%*%t(X)%*%y\nSQR = t((y-X%*%beta_emv))%*%(y-X%*%beta_emv)\ns1 = SQR+(t(beta_emv)%*%t(X)%*%X%*%beta_emv)*lambda/(1+lambda)\nn = length(y)\nphi = rgamma(500,n/2, .5*drop(s1))\n\nmu = beta_emv/(1+lambda)\nbeta = array(NA_real_, c(500,5))\nfor(i in 1:500)beta[i,] = rmvnorm(1, mu,SX/(phi[i]*1.01) )\n\noo = par(mfrow=c(2,2))\nplot(density(beta[,2]), main =names(banco2)[2],lwd=2)\nqq = quantile(beta[,2], c(.025,.975))\nsegments(qq[1],0,qq[2],0, lwd = 3)\nplot(density(beta[,3]), main =names(banco2)[3],lwd=2)\nqq = quantile(beta[,3], c(.025,.975))\nsegments(qq[1],0,qq[2],0, lwd = 3)\nplot(density(beta[,4]), main =names(banco2)[4],lwd=2)\nqq = quantile(beta[,4], c(.025,.975))\nsegments(qq[1],0,qq[2],0, lwd = 3)\nplot(density(beta[,5]), main =names(banco2)[5],lwd=2)\nqq = quantile(beta[,5], c(.025,.975))\nsegments(qq[1],0,qq[2],0, lwd = 3)\n\n\n\n\n\n\n\npar(oo)\n\nObserve que zero está na região de alta densidade para todos os parâmetros, o que contradiz nossa análise exploratória. É possível que o modelo esteja mal especificado, especialmente por causa do número de variáveis regressoras.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>O modelo de regressão linear normal</span>"
    ]
  },
  {
    "objectID": "regressao.html#seleção-de-regressoras",
    "href": "regressao.html#seleção-de-regressoras",
    "title": "12  O modelo de regressão linear normal",
    "section": "12.3 Seleção de regressoras",
    "text": "12.3 Seleção de regressoras\nNo exemplo da última sessão, vimos que a distribuição a posteriori do coeficiente da variável cyl possui muita massa em torno de zero, o que deve implicar que esta variável não é relevante para o problema.\nPodemos utilizar o critério de informação do desvio (DIC) para escolher entre um subgrupo de regressoras. Recordemos que os critério de informação são descritos como\n\\[-2\\log L(\\hat{\\boldsymbol{\\beta}},\\hat{\\phi})+2k,\\] onde \\(L()\\) é a função de verossimilhança, \\(\\hat{\\boldsymbol{\\beta}}\\) são estimativas para os coeficientes de regressão, \\(\\hat{\\phi}\\) é uma estimativa para \\(\\phi\\) e \\(k\\) é uma penalidade relacionada ao número de parâmetros. No DIC, temos\\(\\hat{\\boldsymbol{\\beta}}=E(\\boldsymbol{\\beta}|\\boldsymbol{y})\\), \\(\\hat{\\phi}=E(\\phi|\\boldsymbol{y})\\) e \\[k=\\frac{1}{2}Var_{\\boldsymbol{\\beta},\\phi|\\boldsymbol{y}}(\\log L(\\boldsymbol{\\beta},\\phi)).\\]\n\nAlgoritmo: Calculando o DIC via Monte Carlo\n\nSimule \\((\\boldsymbol{\\beta},\\phi)_1,\\ldots,(\\boldsymbol{\\beta},\\phi)_B\\) da distribuição a posteriori de \\((\\boldsymbol{\\beta},\\phi)\\).\nEstime \\(E(\\boldsymbol{\\beta}|\\boldsymbol{x})\\) por \\[\\hat{\\boldsymbol{\\beta}}=\\frac{1}{B}\\sum_{j=1}^B \\boldsymbol{\\beta}j\\] e \\[\\hat{\\phi}=\\frac{1}{B}\\sum_{j=1}^{^B}\\phi_j.\\]\nFaça \\(v_j=-2\\log L(\\boldsymbol{\\beta}_j,\\phi_j)\\). Estime \\(k\\) por \\[k=\\frac{1}{2B}\\sum_{j=1}^B(v_j-\\bar{v})^2\\]\nCalcule o DIC:\n\n\\[DIC=-2\\log L(\\hat{\\boldsymbol{\\beta}},\\hat{\\phi})+2k.\\]\n\n\nmtcars (cont). Vamos calcular o DIC do modelo encontrado no exemplor anterior. Primeiro, vamos implementar a função \\(\\log L\\):\n\n# criando a função log-verossimilhança\nloglik &lt;- function(theta,y,X){\n  m = length(theta)\n  beta= matrix(theta[1:(m-1)], ncol = 1)\n  phi = theta[m]\n  mu = X%*%beta\n  sum( dnorm(y,mu,1/sqrt(phi) , log = T))\n}\n\nVamos calcular o DIC para o modelo com as regressoras cyl, disp, hp, wt.\n\nrequire(mvtnorm)\n# matriz de regressoras (com o intercepto)\nX = as.matrix(cbind(1,banco2[,-1]))\ny = banco2[,1]\nlambda = .01\nn = length(y)\nB = 5000\n# simulando phi\nSa = solve(t(X)%*%X)\nbeta_emv &lt;- Sa%*%t(X)%*%y\nSQR = t((y-X%*%beta_emv))%*%(y-X%*%beta_emv)\ns1 = SQR + (t(beta_emv) %*% t(X) %*%X%*% beta_emv )*lambda/(1+lambda)\nphi = rgamma(B,n/2, .5*drop(s1))\n\n# simulando mu\nmu = beta_emv/(1+lambda)\nbeta = array(NA_real_, c(B,ncol(X)))\nfor(i in 1:B)beta[i,] = rmvnorm(1, mu,Sa/(phi[i]*(1+lambda)) )\n\n# encontrando as estimativas a posteriori\nbeta_hat = colMeans(beta)\nphi_hat  = mean(phi)\n\n# encontrando vi e estimando k\nvi = apply( cbind(beta,phi), 1, function(theta) -2*loglik(theta,y,X))\nk  = var(vi)/2\nk\n\n[1] 13.03661\n\n# calculando o DIC\n-2*loglik(c(beta_hat,phi_hat), y, X) +2*k\n\n[1] 171.5675\n\n\nEm seguida, vamos calcular o DIC removendo uma variável de cada vez, explorando se haveria melhoria em remover variáveis. Obtivemos a tabela abaixo, o que nos levou a decisão de aceitar o modelo hp e wt\n\n\n        Regressoras DIC\n1 disp, cyl, hp, wt 171\n2      disp, hp, wt 170\n3       cyl, hp, wt 171\n4       cyl, hp, wt 172\n5     cyl, disp, hp 172\n6            hp, wt 169\n7          dips, wt 171\n8          disp, hp 171\n9                wt 175\n\n\nVamos verificar o modelo com as variáveis hp e wt. Abaixo apresentamos as densidades a posteriori estimadas e os respectivos intervalos de credibilidade 95%. Temos evidências claras do efeito negativo.\n\nrequire(mvtnorm)\n# simulando phi\nX= as.matrix(cbind(1,banco2[,-1][,3:4]))\ny = banco2[,1]\nSX = solve(t(X)%*%X)\nlambda = .01\nbeta_emv &lt;- SX%*%t(X)%*%y\nSQR = t((y-X%*%beta_emv))%*%(y-X%*%beta_emv)\ns1 = SQR+(t(beta_emv)%*%t(X)%*%X%*%beta_emv)*lambda/(1+lambda)\nn = length(y)\nphi = rgamma(500,n/2, .5*drop(s1))\n\nmu = beta_emv/(1+lambda)\nbeta = array(NA_real_, c(500,ncol(X)))\nfor(i in 1:500)beta[i,] = rmvnorm(1, mu,SX/(phi[i]*1.01) )\n\noo = par(mfrow=c(1,2))\nplot(density(beta[,2]), main =names(banco2)[2],lwd=2)\nqq = quantile(beta[,2], c(.025,.975))\nsegments(qq[1],0,qq[2],0, lwd = 3)\nplot(density(beta[,3]), main =names(banco2)[3],lwd=2)\nqq = quantile(beta[,3], c(.025,.975))\nsegments(qq[1],0,qq[2],0, lwd = 3)\n\n\n\n\n\n\n\npar(oo)\n\nPara verificar a adequação deste modelo, podemos utilizar a comparação usual entre a função de distribuição empírica e a preditiva a posteriori.\n\nn &lt;- length(y)\ny_pred &lt;- array(NA_real_, c(500, n))\nfor(i in 1:500){\n  y_pred[i,] &lt;- rnorm(n, X%*%beta[i,], 1/sqrt(phi[i]))\n}\n\nFd_sim = apply(y_pred,1, function(x){\n  Fd = ecdf(x)\n  Fd(sort(y))\n})\n\nqq = apply(Fd_sim,1, function(x) quantile(x,c(.025,.977)))\n\nplot(ecdf(y), main = '')\nlines(sort(y),qq[1,], col =2)\nlines(sort(y),qq[2,], col =2)\n\n\n\n\n\n\n\n\nObserve que o ajuste não é adequado, dando evidências de que modelo escolhido não se ajsuta bem para este conjunto de dados",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>O modelo de regressão linear normal</span>"
    ]
  },
  {
    "objectID": "regressao.html#exercícios",
    "href": "regressao.html#exercícios",
    "title": "12  O modelo de regressão linear normal",
    "section": "12.4 Exercícios",
    "text": "12.4 Exercícios\n\n12.4.1 1.\nOs dados deste exemplos se referem ao número de espécies de tartarugas nas várias Ilhas Galápagos, sob o nome gala, disponíveis na biblioteca faraway. O conjunto de dados contém 30 casos (ilhas) e sete variáveis.\nAs variáveis são Species\n\nSpecies - o número de espécies de tartarugas encontradas na ilha,\nEndemics — o número de espécies endêmicas\nArea — a área da ilha (km²)\nElevation — a maior elevação da ilha (m)\nNearest — a distância da ilha mais próxima (km)\nScruz — a distância da Ilha Santa Cruz (km)\nAdjacent — a área da ilha adjacente (km²).\n\nVerifique se é possível ajustar um modelo linear para a varíavel Species utilizando as demais como regressoras.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>O modelo de regressão linear normal</span>"
    ]
  },
  {
    "objectID": "misturas.html",
    "href": "misturas.html",
    "title": "14  Misturas de distribuições",
    "section": "",
    "text": "14.1 O modelo t-Student como uma mistura normal-gama\nA função densidade do modelo t-Student é dada por \\[f(x|\\mu,\\phi,\\nu)=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})}\\sqrt{\\frac{\\phi}{\\pi\\nu}}\\left[1+\\frac{\\phi}{\\nu}\\left(x-\\mu\\right)^2\\right]^{-\\frac{\\nu+1}{2}},\\] onde \\(x,\\mu\\in\\mathbb{R}\\) e \\(\\phi,\\nu&gt;0\\). Se \\(\\nu&gt;1\\), então \\(E(X)=\\mu\\) e se \\(\\nu&gt;2\\), \\(Var(X)=\\nu/(\\phi(\\nu-2))\\).\nConsidere que \\(X|Z,\\mu,\\phi\\sim\\hbox{Normal}(\\mu,(z\\phi)^{-1})\\) e \\(Z\\sim\\hbox{Gama}(\\nu/2,\\nu/2)\\). Então\n\\[\\begin{align}\nf(x|\\mu,\\phi,\\nu)&=\\int_0^\\infty f(x|z,\\mu,\\phi)f(z|\\nu)dz=\\int_0^\\infty \\sqrt{\\frac{\\phi z}{2\\pi}}e^{-\\frac{z\\phi}{2}(x-\\mu)^2}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}z^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}z}dz\\\\\n&=\\sqrt{\\frac{\\phi}{2\\pi}}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}\\int_0^\\infty z^{\\frac{\\nu+1}{2}-1} \\exp\\left\\{-z\\frac{\\nu}{2}\\left[1+\\frac{\\phi}{\\nu}(x-\\mu)^2\\right]\\right\\}dz\\\\\n&=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})}\\sqrt{\\frac{\\phi}{\\pi\\nu}}\\left[1+\\frac{\\phi}{\\nu}\\left(x-\\mu\\right)^2\\right]^{-\\frac{\\nu+1}{2}}.\n\\end{align}\\]\nPortanto, a distribuição normal-gama é uma mistura para a \\(t\\)-Student e a verossimilhança aumentada para este modelo é\n\\[\\begin{align}L(\\mu,\\phi,\\nu)&=\\prod_{i=1}^n f(x_i|z_i,\\mu,\\phi)f(z|\\nu)= \\prod_{i=1}^n \\sqrt{\\frac{\\phi z_i}{2\\pi}}e^{-\\frac{z_i\\phi}{2}(x_i-\\mu)^2}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}z_i^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}z_i}\\\\\n\\end{align}\\]\nConsiderando que \\(\\mu|\\phi \\sim\\hbox{Normal}(m,(\\lambda\\phi)^{-1})\\), \\(\\phi\\sim\\hbox{Gama}(n_0/2,s_0/2)\\) temos a seguinte posteriori baseada no modelo aumentado:\n\\[f(\\mu,\\phi,\\nu|\\boldsymbol{x})\\propto \\left[\\prod_{i=1}^n \\sqrt{\\frac{\\phi z_i}{2\\pi}}e^{-\\frac{z_i\\phi}{2}(x_i-\\mu)^2}\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)}z_i^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}z_i}\\right]\\times \\phi^{1/2}e^{-\\frac{\\lambda}{2} \\phi(\\mu-m)^2}\\times\\phi^{\\frac{n_0}{2}-1}e^{-\\frac{s_0}{2}\\phi}\\times f(\\nu)\\] Pode-se mostrar que\n\\[\\begin{align}\\mu|\\hbox{resto}&\\sim\\hbox{Normal}\\left(\\frac{\\sum_{i=1}^n z_i x_i+\\lambda m}{\\lambda+\\sum_{i=1}^n z_i},\\left[\\phi\\left(\\lambda+\\sum_{i=1}^{n}z_i\\right)\\right]^{-1}\\right)\\\\\n\\phi|\\hbox{resto}&\\sim\\hbox{Gama}\\left(\\frac{n+n_0+1}{2},\\frac{1}{2}\\left[s_0+\\lambda(\\mu-m)^2+\\sum_{i=1}^n z_i(x_i-\\mu)^2\\right]\\right)\\\\\nz_i|\\hbox{resto}&\\sim\\hbox{Gama}\\left(\\frac{\\nu+1}{2},\\frac{\\phi(x_i-\\mu)^2+\\nu}{2}\\right)\\end{align}\\]\nA condicional completa para \\(\\nu\\) é dada por \\[f(\\nu|\\hbox{resto})\\propto \\frac{(\\nu/2)^{n\\nu/2}}{\\Gamma(\\nu/2)^n}\\left(\\prod_{i=1}^n z_i\\right)^{\\frac{\\nu}{2}-1}e^{-\\frac{\\nu}{2}\\sum_{i=1}^nz_i}f(\\nu)\\]\nObserve que a condicional completa para \\(\\nu\\) não possui um núcleo conhecido. Para facilitar a simulação, podemos considerar que o espaço paramétrico de \\(\\nu\\) é uma coleção com \\(M&lt;\\infty\\) pontos. Então, teremos que \\[f(\\nu_0|\\hbox{resto})\\approx P(\\nu=\\nu_0|\\hbox{resto})\\propto \\frac{(\\nu_0/2)^{n\\nu_0/2}}{\\Gamma(\\nu_0/2)^n}\\left(\\prod_{i=1}^n z_i\\right)^{\\frac{\\nu_0}{2}-1}e^{-\\frac{\\nu}{2}\\sum_{i=1}^nz_i}f(\\nu_0)\\] e podemos utilizar o simulador sample do R. Estudos sugerem que a priori escolhida deve favorecer valores baixos para \\(\\nu\\). Vamos utilizar a priori \\(\\nu\\sim\\hbox{Exponencial}(r_0)\\)",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#modelos-com-inflação-de-zeros",
    "href": "misturas.html#modelos-com-inflação-de-zeros",
    "title": "14  Misturas de distribuições",
    "section": "14.2 Modelos com inflação de zeros",
    "text": "14.2 Modelos com inflação de zeros\nQuando são observados mais zeros do que o esperado pelo modelo de contagem assumido para a verossimilhança, é usual considerar um modelo com inflação de zeros. Nesse tipo de modelo, assumimos que existe uma variável \\(Z|p\\sim\\hbox{Bernoulli}(\\rho)\\) tal que:\n\\[X=\\left\\{\\begin{array}{ll}0, & \\hbox{se }Z=1\\ \\\\ Y,&\\hbox{se }Z=0\\end{array}\\right.\\] onde \\(Y\\sim h(.|\\theta)\\) é o modelo de contagem. Apenas \\(X\\) é observado e, como\n\\[\\begin{align}P(X=0|\\theta,p)&=P(X=0|Z=0,\\theta)P(Z=0|\\rho)+P(X=0|Z=1,\\theta)P(Z=1|\\rho)\\\\&=(1-\\rho)h(0|\\theta)+\\rho\\end{align}\\] a probabilidade de observar um zero está entre \\(h(0|\\theta)\\) e 1, o que caracteriza a inflação.\nAgora, considere um modelo inflacionado de zeros aumentado:\n\\[f(x,z|\\theta,\\rho)=f(x|z,\\theta)f(z|\\rho)=f(x|z,\\theta)\\rho^z(1-\\rho)^{1-z}.\\] Note que\n\\[f(x|z,\\theta)=\\left\\{\n\\begin{array}{ll}\nh(x|\\theta),&\\hbox{ se }z=0,\\\\\nI(x=0),&\\hbox{ se }z=1\\\\\n\\end{array}\\right.\\] logo, a distribuição conjunta \\(f(x,z|\\theta,\\rho)\\) é dada por\n\\[\\begin{array}{c|cc}\\hline & x=0 & \\hbox{qualquer }x&gt; 0 \\\\ \\hline\nz=0 & h(0|\\theta)(1-\\rho) & h(x|\\theta)(1-\\rho) \\\\\nz=1 & \\rho & 0 \\\\ \\hline\n\\end{array}\n\\] Então,\n\\[\\begin{align}\n\\prod_{i=1}^n f(x_i,z_i|\\theta,\\rho)&=\\prod_{i=1}^n [h(0|\\theta)(1-\\rho)]^{I(x_i=0,z_i=0)}[h(x_i|\\theta)(1-\\rho)]^{I(x_i&gt;0,z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\\\\n&=\\prod_{i=1}^n [h(x_i|\\theta)(1-\\rho)]^{I(z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\\\\n&=\\prod_{i=1}^n(1-\\rho)^{I(z_i=0)}\\rho^{I(x_i=0,z_i=1)}\\prod_{i=1}^n [h(x_i|\\theta)]^{I(z_i=0)}\\end{align}\\] e, notando que \\(I(z_i=0)=1-z_i,\\)\n\\[\\begin{align}\n\\prod_{i=1}^n f(x_i,z_i|\\theta,\\rho)&=\n(1-\\rho)^{n-\\sum_{i=1}^n z_i}\\rho^{\\sum_{i=1}^n z_iI(x_i=0)}\\prod_{i=1}^n [h(x_i|\\theta)]^{1-z_i}\\end{align}\\]\nConsidere, a priori, que \\(\\theta\\) e \\(\\rho\\) são independentes. Seja \\(\\pi(\\theta)\\) a priori para \\(\\theta\\) e considere que \\(\\rho\\sim\\hbox{Beta}(a,b)\\). Então, as condicionais completas para \\(\\theta\\) e \\(\\rho\\) são\n\\[\\begin{align}\n\\pi(\\theta|\\rho,\\boldsymbol{z},\\boldsymbol{x})&\\propto \\prod_{i=1}^n h(x_i|\\theta)^{1-z_i}\\pi(\\theta),\\\\\n\\pi(\\rho|\\theta,\\boldsymbol{z},\\boldsymbol{x})&\\propto \\rho^{\\sum_{i=1}^n z_iI(x_i=0)+a-1}(1-\\rho)^{n-\\sum_{i=1}^n z_i+b-1},\\\\\n\\end{align}\\]\nPara a condicional completa de \\(z_i\\), notemos que \\[P(Z_i=1|x_i&gt;0)=\\frac{P(Z_i=1,X_i&gt;0)}{P(X_i&gt;0)}=0,\\] e que\n\\[P(Z_i=z|x_i=0)= \\left\\{\\begin{array}{ll}\\frac{P(Z_i=0,X_i=0)}{P(X_i=0)}=\\frac{h(0|\\theta)(1-\\rho)}{\\rho+(1-\\rho)h(0|\\theta)},&,z=0\\\\\n\\frac{P(Z_i=1,X_i=0)}{P(X_i=0)}=\\frac{\\rho}{\\rho+(1-\\rho)h(0|\\theta)},&z=1\\end{array}\\right.,\\] logo \\[\\pi(z_i|\\theta,\\rho,\\boldsymbol{x},\\boldsymbol{z}_{(-i)})=\\left\\{\\begin{array}{ll}\\hbox{Bernoulli}\\left( \\frac{\\rho}{\\rho+(1-\\rho)h(0|\\theta)}\\right),&\\hbox{ se }x_i=0\\\\\nI(z_i=0),&\\hbox{ se } x_i&gt;0\\\\ \\end{array}\\right.\\]\nPortanto, um amostrador de Gibbs para um modelo inflacionado de zeros é\n\nAmostrador de Gibbs para o modelo inflado de zeros\nFaça \\(j=0\\) e dê os valores iniciais \\(\\theta^{(0)}\\) e \\(\\rho^{(0)}\\).\nNo \\(j\\)-ésimo passo:\n\nPara \\(i\\in\\{1,\\ldots,n\\}\\), se \\(x_i&gt;0\\) faça \\(z_i=0\\). Senão, simule \\[z_i^{(j)}\\sim \\hbox{Bernoulli}\\left(\\frac{\\rho^{(j-1)}}{\\rho^{(j-1)}+(1-\\rho^{(j-1)})h(x_i|\\theta^{(j-1)})}\\right)\\]\nSimule \\(\\rho^{(j)}\\sim\\hbox{Beta}(a+\\sum_{i=1}^n z_i^{(j)}I(x_i=0),b+n-\\sum_{i=1}^n z_i^{(j)})\\)\nSimule \\(\\theta^{(j)}\\) de \\[\\pi(\\theta|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x})\\propto \\prod_{i=1}^n h(x_i|\\theta^{(j)})^{1-z_i^{(j)}}\\pi(\\theta^{(j)}).\\]\n\n\n\nExemplo - A Poisson inflada de zeros \nNeste exemplo, vamos considerar que a distribuição da contagem é Poisson(\\(\\theta\\)) e que \\(\\theta\\sim\\hbox{Gama}(r,s)\\). Então,\n\\[\\begin{align}\n\\pi(\\theta|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x})&\\propto \\prod_{i=1}^{n} h(x_{i} | \\theta )^{ 1-z_{i}^{(j)} }\\pi(\\theta)=\n\\prod_{i=1}^{n} \\left[\\frac{ e^{-\\theta}\\theta^{x_i} }{x_i!}\\right]^{1-z_{i}^{(j)}}\\frac{s^r}{\\Gamma(r)}\\theta^{r-1} e^{-s\\theta}\\\\&\\propto \\theta^{\\sum_{i=1}^n x_i(1-z_i^{(j)})+r-1}e^{-(n-\\sum_{i=1}^n z_i^{(j)}+s)\\theta}\n\\end{align},\\]\nou seja, \\(\\theta^{(j)}|\\rho^{(j)},\\boldsymbol{z}^{(j)},\\boldsymbol{x}\\sim\\hbox{Gama}(\\sum_{i=1}^n x_i(1-z_i^{(j)})+r,n-\\sum_{i=1}^n z_i^{(j)}+s)\\)\n\n\nOs dados abaixo representam o número anual de furacões atlânticos grandes (categoria 4 ou 5) entre 1987 e 2012, nos Estados Unidos.\n\nfur &lt;-  c(0, 0 ,1,\n0, 0, 1, 0, 0, 1, 0, 0, 2, 2,\n0, 0, 1, 1, 3, 4, 0, 0, 2, 0,\n0, 0, 0)\n\nA frequência relativa de zeros é 0,58. Considerando o modelo Poisson\\((\\theta)\\) com \\(\\pi(\\theta)\\propto \\theta^{-1}\\), temos que\n\nr1 &lt;- sum(fur)\ns1 &lt;- length(fur)\nplot(table(fur)/s1, type= 'p', xlab='No. anual de mortes pod fur', ylab = 'Probabilidade', col = 'cyan3', pch=16)\nlines(0:4,table(fur)/s1, col = 'cyan3')\npoints(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), pch=16, col = 'brown')\nlines(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), col = 'brown')\n\nlegend('bottomleft',c('Freq. relativa','Pred. post. Poisson'), fill=c('cyan3','brown'), bty='n')\n\n\n\n\n\n\n\n\n\n# hiperparâmetros para rho\na = b = 1\n\n# hiperparâmetros para theta\nr=.1\ns=.1\n\n# tamanho da amostra\nn &lt;- length(fur) \n\n# valores iniciais da cadeia\ntheta &lt;- mean(fur)\nrho &lt;- mean(fur == 0)\n\n# amostrador de Gibbs\nB &lt;- 50000\nfor(i in 1:B){\n  # simulando z\n  z &lt;- NULL\n  prob &lt;- rho[i]/ ( (1-rho[i])*dpois(0,theta[i]) + rho[i])\n  for(j in 1:n){\n    if(fur[j] &gt;0){ z[j] &lt;- 0} else{\n      z[j] &lt;- rbinom(1,1,prob)\n    }\n  }\n\n  # simulando rho\n  rho[i+1] &lt;- rbeta( 1, a + sum( z * (fur == 0)) , n- sum(z)+ b )\n  \n  # simulando theta\n  theta[i+1] &lt;- rgamma(1, sum( fur*(1-z) ) + r,  n - sum(z) + s)\n}\n\nVamos descartar a metade das simulações e usar um thinning igual a 15:\n\ntheta_sim &lt;- theta[seq(B/2,B,15)]\nrho_sim &lt;- rho[seq(B/2,B,15)]\n\noo &lt;- par(mfrow=c(2,2))\nts.plot(theta_sim, lwd = 2)\nts.plot(rho_sim, lwd = 2)\nacf(theta_sim)\nacf(rho_sim)\n\n\n\n\n\n\n\n\nVamos estimar as probabilidade de ocorrerem \\(k\\) mortes via preditiva posteriori:\n\n# tamanho do vetor simulado\nBs &lt;- length(theta_sim)\n\nx_til &lt;- array( NA_real_, c(Bs,n))\nfor(j in 1:Bs){\n  z &lt;- rbinom( n, 1, rho_sim[j])\n  x_til[j,] &lt;- (1-z)*rpois(n, theta_sim[j])\n}\n\n# probabilidades estimadas via ZIP\np_zip &lt;- prop.table(table(x_til))\n\np_zip\n\nx_til\n           0            1            2            3            4            5 \n6.081168e-01 2.006829e-01 1.149232e-01 5.103595e-02 1.765032e-02 5.698860e-03 \n           6            7            8 \n1.522772e-03 2.768677e-04 9.228923e-05 \n\n\nAbaixo mostramos as probabilidades preditas do modelo ZIP, do modelo Poisson a e frequência relativa.\n\nr1 &lt;- sum(fur)\ns1 &lt;- length(fur)\nplot(table(fur)/s1, type= 'p', xlab='No. anual de mortes pod fur', ylab = 'Probabilidade', col = 'cyan3', pch=16)\nlines(0:4,table(fur)/s1, col = 'cyan3')\npoints(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), pch=16, col = 'brown')\nlines(0:4, dnbinom(0:4, size = r1, prob = s1/(1+s1)), col = 'brown')\npoints(names(p_zip),p_zip, pch=16,col = 'magenta')\nlines(names(p_zip),p_zip,col = 'magenta')\n\nlegend('bottomleft',c('Freq. relativa','Pred. post. Poisson', 'Pred. post. ZIP'), fill=c('cyan3','brown', 'magenta'), bty='n')\n\n\n\n\n\n\n\n\n\n\n14.2.1 Exercício\n\nAbaixo, segue o número anual de tornados em Lafayette Parish, Louisiana, entre 1950 e 2012.\n\ntor &lt;- c(0, 0,0, 1, 0, 0, 0, 1, 0, 0,\n1, 0, 0, 0, 1, 1, 0, 0, 0, 2,\n0, 0, 0, 0, 1, 3, 0, 2, 1, 0,\n1, 0, 0, 1, 0, 1, 0, 0, 2, 1,\n0, 1, 2, 0, 0, 1, 0, 1, 2, 0,\n0, 0, 3, 0, 2, 0, 1, 1, 3, 0,\n1, 1, 1)\n\n\nAjuste o modelo Poisson.\nAjuste o modelo Poisson inflado de zeros.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#mistura-escalonada-de-normais",
    "href": "misturas.html#mistura-escalonada-de-normais",
    "title": "14  Misturas de distribuições",
    "section": "14.3 Mistura escalonada de normais",
    "text": "14.3 Mistura escalonada de normais",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "misturas.html#misturas-finitas-com-número",
    "href": "misturas.html#misturas-finitas-com-número",
    "title": "14  Misturas de distribuições",
    "section": "14.4 Misturas finitas com número",
    "text": "14.4 Misturas finitas com número\nDizemos que \\(X|\\boldsymbol{\\theta},\\boldsymbol{p},\\kappa\\) é um modelo de mistura finito se sua função de densidade/probabilidade é dada por\n\\[f(x| \\boldsymbol{\\theta},\\boldsymbol{p} ,\\kappa )=\\sum_{k=1}^\\kappa p_k f_k(x|\\boldsymbol{\\theta}_k).\\]\nCada função \\(f(.|\\boldsymbol{\\theta}_k)\\) é denominada componente da mistura e o número de componentes pode ser desconhecido.\nAssim como o modelo com zeros inflacionados, podemos utilizar uma variável latente \\(\\textbf{z}_i|\\kappa=(z_{i,1},\\ldots,z_{i,\\kappa})\\sim\\hbox{Multinomial}(p_1\\ldots,p_\\kappa|\\sum_{k=1}^\\kappa z_{ik}=1)\\), obtendo o seguinte modelo aumentado\n\\[f(x_i|\\boldsymbol{\\theta},\\textbf{z}_i,\\kappa)=\\prod_{k=1}^\\kappa \\left[f\\left(x_i|\\boldsymbol{\\theta}_k\\right)\\right]^{z_{i,k}}\\]\nA função de verossimilhança aumentada para este modelo é\n\\[\\prod_{i=1}^n f(x_i|\\boldsymbol{\\theta},\\textbf{z}_i,\\kappa)=\\prod_{i=1}^n\\prod_{k=1}^\\kappa \\left[f\\left(x_i|\\boldsymbol{\\theta}_k\\right)\\right]^{z_{i,k}}.\\]\nConsidere as prioris \\(\\pi(\\boldsymbol{\\theta}|\\kappa)=\\prod_{k=1}^\\kappa \\pi(\\boldsymbol{\\theta}_k)\\) e \\(\\textbf{p}|\\kappa\\sim\\hbox{Dirichlet}(a_1,\\ldots,a_\\kappa)\\), onde \\[f(\\textbf{p}|\\kappa)\\propto \\prod_{k=1}^\\kappa p_k^{a_k-1}\\] com \\(\\sum_{k=1}^\\kappa p_k=1\\). As condicionais completas para este problema são\n\n\\(\\begin{align}f(\\boldsymbol{\\theta}_k|resto)\\propto \\prod_{i:z_{i,k}=1}f(x_i|\\boldsymbol{\\theta}_k)\\pi(\\boldsymbol{\\theta}_k)\\end{align}\\)\n\\(\\begin{align}f(\\textbf{z}_i|resto)\\propto \\prod_{k=1}^\\kappa \\left[p_kf(x_i|\\boldsymbol{\\theta}_k)\\right]^{z_{i,k}}\\end{align}\\) ou seja, \\(\\textbf{z}_i|rest\\sim\\hbox{Multinomial}(\\tilde{p}_1,\\ldots,\\tilde{p}_\\kappa)\\), onde\n\n\\[\\tilde{p}_k=\\frac{p_kf(x_i|\\boldsymbol{\\theta}_k)}{\\sum_{k=1}^\\kappa p_kf(x_i|\\boldsymbol{\\theta}_k)}\\] * \\(f(\\textbf{p}|resto)\\propto \\prod_{k=1}^\\kappa p_k^{\\sum_{i=1}^n z_{i,k}+a_k-1}\\), ou seja \\(\\textbf{p}|resto\\sim\\hbox{Dirichlet}(a_1+\\sum_{i=1}^n z_{i,1},\\ldots,a_\\kappa+\\sum_{i=1}^n z_{i,\\kappa})\\)\nSe necessário, podemos atrbuir a priori \\[\\pi(\\kappa)=\\frac{1}{M},\\kappa=1,2,\\ldots,M\\] para obter a condicional completa \\[\\pi(\\kappa|resto)=\\frac{\\prod_{i=1}^n\\prod_{k=1}^\\kappa f(x_i|\\boldsymbol{\\theta}_k)^{z_{i,k}}\\pi(\\boldsymbol{\\theta}_k)\\pi(\\textbf{p}|\\kappa)\\pi(\\textbf{z}_i|\\kappa)}{\\sum_{\\kappa=1}^M \\prod_{i=1}^n\\prod_{k=1}^\\kappa f(x_i|\\boldsymbol{\\theta}_k)^{z_{i,k}}\\pi(\\boldsymbol{\\theta}_k)\\pi(\\textbf{p}|\\kappa)\\pi(\\textbf{z}_i|\\kappa)},\\kappa=1,\\ldots,M.\\]\n\n14.4.1 O velho fiel\nO banco de dados faithful mostra a duração e o tempo até a próxima erupção do geiser Velho Fiel, no parque Yellowstone. Abaixo mostramos o diagrama do tempo de espera entre erupções\n\nhist(faithful$waiting)\n\n\n\n\n\n\n\n\nÉ possível notar classes, uma com tempo e entre erupções menor que 70 com tempo maior. Temos as seguintes estimativas iniciais:\n\n## elementos na classe 1\nx &lt;- faithful$waiting\nz &lt;- x &lt; 70\n# proporção na classe 1\nmean(z)\n\n[1] 0.3786765\n\n# média e desvio padrão na classe 1\nmean( x[z])\n\n[1] 55.15534\n\nsd( x[z])\n\n[1] 6.266558\n\n\n\n## elementos na classe 2\n# proporção na classe 2\nmean(z==F)\n\n[1] 0.6213235\n\n# média e desvio padrão na classe 2\nmean( x[z==F])\n\n[1] 80.49112\n\nsd( x[z==F])\n\n[1] 5.456667\n\n\nVamos considerar que as duas componentes possuem distribuição normal. Para cada componente, teremos as seguintes prioris:\n\\[\\pi(\\mu_i,\\phi_i)=\\frac{\\phi^{1/2}_i}{\\sqrt{2\\pi C}}e^{-\\frac{\\phi_i}{2C}(\\mu_i-m_i)^2}\\frac{b^a}{\\Gamma(a)}\\phi_i^{a-1}e^{b\\phi_i},\\]\n\\[p\\sim\\hbox{Beta}(r,s)\\]\n\\[z_i\\sim\\hbox{Bernoulli}(p)\\]\nO modelo aumentado é \\[f(x_i|\\mu,\\phi,z_{i})=\\left[\\frac{\\phi_1^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_1}{2}(x_i-\\mu_1)}\\right]^{z_i}\\left[\\frac{\\phi_2^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_2}{2}(x_i-\\mu_2)}\\right]^{1-z_i}\\] As condicionais completas são:\n\\[\\begin{align}f(\\mu_1|resto) &\\propto \\exp\\left\\{-\\frac{\\phi_1}{2}\\sum_{i=1}^n z_i(x_i-\\mu_1)^2\\right\\}\\exp\\left\\{-\\frac{\\phi_1}{2C} z_i(\\mu_1-m_1)^2\\right\\}\\\\&\\propto \\exp\\left\\{-\\frac{\\phi_1}{2}\\left(\\sum_{i=1}^n z_i+C^{-1}\\right) \\left(\\mu_1-\\frac{\\sum_{i=1}^{n}x_iz_i+m_1C^{-1}}{\\sum_{i=1}^n z_i+C^{-1}}\\right)^2\\right\\}\\end{align}\\]\n\\[\\begin{align}f(\\mu_2|resto) &\\propto \\exp\\left\\{-\\frac{\\phi_2}{2}\\sum_{i=1}^n (1-z_i)(x_i-\\mu_2)^2\\right\\}\\exp\\left\\{-\\frac{\\phi_2}{2C} (1-z_i)(\\mu_2-m_2)^2\\right\\}\\\\&\\propto \\exp\\left\\{-\\frac{\\phi_2}{2}\\left(\\sum_{i=1}^n (1-z_i)+C^{-1}\\right) \\left(\\mu_2-\\frac{\\sum_{i=1}^{n}x_i(1-z_i)+m_1C^{-1}}{\\sum_{i=1}^n (1-z_i)+C^{-1}}\\right)^2\\right\\}\\end{align}\\]\n\\[\\begin{align}f(\\phi_2|resto)&\\propto \\phi_2^{-\\frac{1}{2}\\sum_{i=1}^{n}z_i}\ne^{-\\frac{\\phi_2}{2}\\sum_{i=1}^n (1-z_i)(x_i-\\mu_2)^2}\\phi^{-1/2}_2e^{-\\frac{\\phi_2}{2}(\\mu_2-m_2)^2}\\phi_2^{a/2-1}e^{-\\phi_2 b/2}\\\\ &\\propto \\phi_2^{\\frac{1}{2}(1+a+\\sum_{i=1}^{n}(1-z_i)-1}e^{-\\frac{\\phi_2}{2}[\\sum_{i=1}^n(1-z_i)(x_i-\\mu_2)^2 +(\\mu_2-m_2)^2 + b]}\\end{align}\\] \\[\\begin{align}f(\\phi_1|resto)&\\propto \\phi^{-\\frac{1}{2}\\sum_{i=1}^{n}z_i}\ne^{-\\frac{\\phi_1}{2}\\sum_{i=1}^n z_i(x_i-\\mu_1)^2}\\phi^{-1/2}e^{-\\frac{\\phi_1}{2}(\\mu_1-m_1)^2}\\phi_1^{a/2-1}e^{-\\phi_1 b/2}\\\\ &\\propto \\phi_1^{\\frac{1}{2}(1+a+\\sum_{i=1}^{n}z_i)-1}e^{-\\frac{\\phi_1}{2}[\\sum_{i=1}^nz_i(x_i-\\mu_1)^2 +(\\mu_1-m_1)^2 + b]}\\end{align}\\]\n\\[\\begin{align}f(p|resto)\\propto \\prod_{i=1}^n p^{z_i}(1-p)^{1-z_i}p^{r-1}(1-p)^{s-1}\\propto p^{r+\\sum_{i=1}^n z_i-1}(1-p)^{s+\\sum_{i=1}^n (1-z_i)-1}\\end{align}\\]\n\\[f(z_i|resto)\\propto\\left[ p\\frac{\\phi_1^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_1}{2}(x_i-\\mu_1)^2}\\right]^{z_i}\\left[ (1-p)\\frac{\\phi_2^{1/2}}{\\sqrt{2\\pi}}e^{-\\frac{\\phi_2}{2}(x_i-\\mu_2)^2}\\right]^{1-z_i}\\]\nAbaixo implementamos o amostrador de Gibbs\n\nB &lt;- 50000\n\n# hiperparmametros\nm1 &lt;- 65\nm2 &lt;- 80\nC &lt;- 1000\nr= 4; s = 6\na = 1; b = .1\n\n# valores iniciais\nz &lt;- x &lt; 70\nphi1 &lt;- 1/36\nphi2 &lt;- 1/25\nmu1 = mu2 =  p = NULL\n\nfor(i in 1:B){\n  # mu dado o resto\n  m1_post &lt;- ( sum(x*z) + m1/C) / ( sum(z) + 1/C )\n  m2_post &lt;- ( sum(x*(1-z)) + m1/C) / ( sum(1-z) + 1/C )\n  s1_post &lt;- 1 / ( ( sum(z) + 1/C )*phi1[i] )\n  s2_post &lt;- 1 / ( ( sum(1-z) + 1/C )*phi2[i] )\n  \n  mu1[i+1] &lt;- rnorm(1, m1_post, sqrt( s1_post) )\n  mu2[i+1] &lt;- rnorm(1, m2_post, sqrt( s2_post) )\n  \n  # phi dado resto\n  phi1[i+1] &lt;- rgamma(1, 1 + a + sum(z), sum( z*(x - mu1[i+1])^2 ) + (mu1[i+1]-m1)^2 + b)\n  phi2[i+1] &lt;- rgamma(1, 1 + a + sum(1-z), sum( (1-z)*(x - mu2[i+1])^2 ) + (mu2[i+1]-m2)^2 + b)\n  \n  # p dado resto\n  p[i+1] &lt;- rbeta(1, r + sum(z), s + sum(1-z) )\n  \n  # z dado resto\n  aux1 &lt;- p[i+1]*dnorm(x,mu1[i+1], 1/sqrt(phi1[i+1]))\n  aux2 &lt;- (1-p[i+1])*dnorm(x,mu2[i+1], 1/sqrt(phi2[i+1]))\n  \n  z &lt;- rbinom(length(x), 1, aux1/( aux1 + aux2))\n}\n# \n\n\nhist(mu1[seq(B/2,B,30)])\n\n\n\n\n\n\n\nhist(mu2[seq(B/2,B,30)])",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Misturas de distribuições</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html",
    "href": "negativeBinomial.html",
    "title": "13  Binomial negativa",
    "section": "",
    "text": "13.1 O modelo binomial negativo\nA distribuição Poisson é muito comum em problemas de contagem. Como sua esperança e variância são iguais, o termo sobredispersão foi cunhado na literatura como uma variância maior que a média, o que seria indício de que o modelo Poisson não é adequado (de modo análogo, há o conceito de subdispersão, mas não é um fenômeno comum).\nDizemos que \\(X|\\rho,\\phi\\sim\\hbox{Binomial Negativa}\\) se\n\\[p(x|\\rho,\\phi)=\\frac{\\Gamma(\\phi+x)}{x!\\Gamma(\\phi)}\\rho^\\phi(1-\\rho)^x,\\] onde \\(x\\in\\mathbb{N}\\), \\(\\rho\\in(0,1)\\) e \\(\\phi&gt;0\\).\nExistem diversos motivos para considerar o modelo binomial negativo uma alternativa quando o modelo Poisson não parece ser adequado. Primeiro, temos que \\(E(X|\\rho,\\phi)=\\phi(1-\\rho)/\\rho\\) e \\(Var(X|\\rho,\\phi)=E(X|\\rho,\\phi)/\\rho\\), logo, a sobredispersão está presente no modelo. Além disso, se \\(X|\\lambda\\sim\\hbox{Poisson}(\\lambda)\\) e \\(\\lambda\\sim\\hbox{Gama}(\\phi, \\rho/(1-\\rho))\\), então \\(X|\\phi,\\rho\\sim\\hbox{Binomial Negativa}(\\phi,\\rho)\\) logo, este modelo é uma mistura do modelo Poisson. Por último, fazendo \\[\\mu=\\phi\\frac{1-\\rho}{\\rho}\\Rightarrow \\rho(\\phi)=\\frac{\\phi}{\\phi+\\mu},\\] pode-de mostrar que \\[\\lim_{\\phi\\rightarrow\\infty}p(x|\\phi)=\\frac{e^{-\\mu}\\mu^x}{x!}\\] ou seja, o modelo Poisson também pode ser vist como um caso limite do binomial negativo.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html#priori-para-phi-condicionado",
    "href": "negativeBinomial.html#priori-para-phi-condicionado",
    "title": "13  Binomial negativa",
    "section": "13.2 Priori para \\(\\phi\\) condicionado",
    "text": "13.2 Priori para \\(\\phi\\) condicionado\nQuando \\(\\phi\\) é conhecido, a verossimilhança do modelo se torna\n\\[L(\\rho|\\phi)\\propto \\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i},\\] logo, o modelo Beta\\((a,b)\\) é conjugado, com a posteriori dada por \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi+a,\\sum_{i=1}^n x_i+b\\right).\\]\nA priori de Jeffreys é dada por\n\\[\\pi(\\rho)\\propto \\frac{1}{\\rho(1-\\rho)^{1/2}},\\] o que implica na posteriori \\[\\rho|\\boldsymbol{x},\\phi\\sim\\hbox{Beta}\\left(n\\phi,\\sum_{i=1}^n x_i+\\frac{1}{2}\\right).\\]",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "negativeBinomial.html#priori-para-phi",
    "href": "negativeBinomial.html#priori-para-phi",
    "title": "13  Binomial negativa",
    "section": "13.3 Priori para \\(\\phi\\)",
    "text": "13.3 Priori para \\(\\phi\\)\nSeja \\(\\pi(\\phi)\\pi(\\rho)\\) a priori para \\((\\phi,\\rho)\\). Então, teremos que\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}\\rho^{n\\phi}(1-\\rho)^{\\sum_{i=1}^n x_i}\\pi(\\phi)\\pi(\\rho).\\]\nAssumindo qualquer uma das prioris da seção anterior, teremos\n\\[\\pi(\\phi,\\rho|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\pi(\\rho|\\phi,\\boldsymbol{x}),\\]\nlogo,\n\\[\\pi(\\phi|\\boldsymbol{x})\\propto \\frac{\\prod_{i=1}^n\\Gamma(\\phi+x_i)}{\\Gamma(\\phi)^n}B\\left(a_0+n\\phi,b_0+\\sum_{i=1}^nx_i\\right)\\pi(\\phi)\\]\nComo a posteriori de \\(\\phi\\) não é uma distribuição conhecida, precisamos construir um simulador. O algoritmo Metropolis-Hastings é uma boa escolha, uma vez que a constante de proporcionalidade da densidade é desconhecida.\n\nAlgoritmo Metropolis-Hastings\nO Metropolis-Hastings simula se utiliza de uma distribuição que sabemos simular (denominada proposta) para gerar uma cadeia de Markov cuja distribuição estacionária é a distribuição de interesse.\nNa \\(j\\)-ésima itereção, a simulação do valor proposto \\(\\phi^*\\) é baseada no valor atual da cadeia, \\(\\phi^{(j-1)}\\). Como \\(\\phi&gt;0\\), a proposta \\(\\phi^*\\sim \\hbox{Gamma}(\\tau\\phi^{(j-1)},\\tau)\\) é adequada uma vez que \\[E(\\phi^*)=\\phi^{(j-1)}\\] e \\[\\sqrt{Var(\\phi^*)}=\\frac{\\phi^{(j-1)}}{\\tau}\\] Acima, \\(\\tau\\) é denominado tunning (afinação em tradução livre) e deve ser escolhido para que a cadeia tenha o número de aceites da proposta controlado (algo em torno de 23% ).\nAbaixo, segue o algoritmo\n\nFaça \\(j=0\\) e escolha um valor para \\(\\phi^{(0)}\\) (a estimativa de máxima verossimilhança, por exemplo). Faça um contador de aceites, começando com \\(k=0\\).\nPara o passo \\(j\\):\n\n\nSimule \\(\\phi^*\\sim\\hbox{Gama}(\\tau\\phi^{j-1},\\tau)\\)\nCalcule\n\n\\[prob = \\frac{\\pi(\\phi^*|\\boldsymbol{x})}{\\pi(\\phi^{(j-1)}|\\boldsymbol{x})}\\frac{g(\\phi^{(j-1)}|\\tau\\phi^*,\\tau)}{g(\\phi^*|\\tau\\phi^{(j-1)},\\tau)},\\] onde \\(g(.|a,b)\\) é a função densidade do modelo gama. + Simule \\(u\\sim\\hbox{Uniforme}(0,1)\\). Se \\(u&lt;prob\\), faça \\(\\phi^{(j)}=\\phi^*\\) e \\(k=k+1\\) (houve um aceite). Senão, faça \\(\\phi^{(j)}=\\phi^{(j-1)}\\).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Binomial negativa</span>"
    ]
  },
  {
    "objectID": "mcmc.html",
    "href": "mcmc.html",
    "title": "16  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "",
    "text": "16.1 Cadeias de Markov\nA coleção \\({\\X(t),t\\inT\\}\\) é um processo estocástico se \\(X(t)\\) é uma variável aleatória para cada \\(t\\in T\\).\nA variável \\(X(t)\\) é denominada estado. O processo é dito ser a tempo discreto se \\(T\\subseteq \\mathbb{Z}\\).\nEm um processo a tempo discreto, é usual utilizar a notação \\(X(t)\\equiv X_t\\).\nO processo estocástico \\(X_0,X_1,X_2,\\ldots\\) é uma cadeia de Markov de ordem \\(d\\) se\n\\[P(X_n\\in A|X_{n−1}=x_{n−1},…,X_0=x_0)=P(X_n\\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d}).\\]\nUma cadeia de Markov de ordem \\(d\\) é dita ser homogênea se, para qualquer \\(m&gt;0\\) natural,\n\\[P(X_n\\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d})=P(X_{n+m}\\in A|X_{n+m−1}=x_{n−1},…,X_{n+m−d}=_{xn−d}).\\]\nEstamos interessados nas cadeias homogêneas de ordem \\(d=1\\), que doravante serão denominadas simplesmente por cadeias de Markov.\nA evolução da cadeia de \\(X_n\\) até \\(X_{n+1}\\) é denominada transição em 1 passo. A densidade \\(k(.|y)\\) que satisfaz\n\\[P(X_{n+1}\\in A|X_n=y)=\\int_A k(x|y)dx\\]\né denominada núcleo de transição (ou núcleo de transição em 1 passo. Se os estados forem variáveis discretas, \\(k(.|y)\\) será uma função de probabilidade e a discussão é análoga.\nA seguir, vamos discutir em quais situações esta distribuição exsite.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "mcmc.html#cadeias-de-markov",
    "href": "mcmc.html#cadeias-de-markov",
    "title": "16  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "",
    "text": "Uma cadeia de Markov\nConsidere a seguinte cadeia de Markov:\n\\[X_n|X_{n−1}=y∼\\hbox{Uniforme}(1−y,1).\\]\nAbaixo, simulamos duas trajetórias de tamanho 200 deste processo, cada uma com um valor diferente para \\(x_0\\).\n\nset.seed(123)\n\ncadeia1 &lt;- .1\ncadeia2 &lt;- .5\n\nfor(i in 2:200){\n  cadeia1[i] &lt;- runif(1, 1 - cadeia1 [i - 1] , 1)\n  cadeia2[i] &lt;- runif(1, 1 - cadeia2 [i - 1] , 1)\n}\n\n# gráfico das duas trajetórias\nplot(cadeia1,cadeia2, type = \"l\", col =1)\npoints(cadeia1[1] , cadeia2[1] , pch=16) # ponto inicial\n\n\n\n\n\n\n\n\nPelo gráfico acima observamos que, independente de onde a cadeia começou, as duas simulações se concentraram na mesma região do gráfico após algumas iterações. A figura abaixo apresenta a função densidade estimada via método do núcleo para as duas trajetórias simuladas, excluindo os 10 primeiros pontos, de onde pode-se inferir que as distribuições são as mesmas.\n\nplot(density(cadeia1[-(1:10)]), lwd = 2, main = \"\")\nlines(density(cadeia2[-(1:10)]), lty = 2, lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n16.1.1 A distribuição estacionária\nDizemos que \\(\\pi(.)\\) é a densidade da distribuição estacionária de uma cadeia de Markov se\n\\[\\pi(y)=\\int \\pi(x)k(y|x)dx.\\] Note que isto implica que \\(X_i∼\\pi()\\), ou seja, a distribuição marginal da cadeia é a mesma.\nPortanto, ao simular uma trajetória de uma cadeia de Markov com distribuição estacionária, os valores simulados são identicamente distribuídos segundo \\(\\pi(.)\\).\nSe o valor inicial \\(x_0\\) utilizado para gerar a amostra estiver dentro da região de alta densidade de \\(\\pi(.)\\), os próximos valores que serão gerados já são da distribuição estacionária. Caso contrário, defina \\(k^{(d)}(.|y)\\) como o núcleo de transição em \\(d\\) passos. Observe que tal núcleo sempre pode ser obtido do núcleo em 1 passos pois:\n\\[k^{(2)}(x|x_0)=\\int k(x|z)k(z|x_0)dz\\]\n\\[k^{(3)}(x|x_0)=\\int k^{(2)}(x|z)k(z|x_0)dz\\] e assim por diante. Contudo, se há distribuição estacionária, então \\[\\pi(x)=\\lim_{n\\rightarrow\\infty} k^{(n)}(x|x_0).\\] Isto implica que a cadeia eventualmente vai construir uma trajetória até a região de alta densidade de \\(\\pi(.)\\).\nAs condições para existência da distribuição estacionária são:\n\nExiste \\(n&gt;0\\) tal que \\(P(X_n\\in A|X_0=x_0)\\) para quaisquer \\(A\\) e \\(x_0\\), sendo que o número médio de passos para realizar a transição é finito.\n\\(P(X_n\\in A|X_0=x_0)\\) não é uma função periódica em \\(n\\)\n\n\nSimulando de uma distribuição estacionária\nConsidere novamente a seguinte cadeia de Markov:\n\\[X_n|X_{n−1}=y∼\\hbox{Uniforme}(1−y,1).\\]\nVamos simular uma trajetória de tamanho 500 começando em \\(x_0=.5\\)\n\nset.seed(123)\nx &lt;- .5\n\nfor(i in 2:500){\n  x[i] &lt;- runif(1, 1 - x [i - 1] , 1)\n}\n\n\nts.plot(x)\nabline(h=.5,lty=2)\n\n\n\n\n\n\n\n\nAbaixo, apresentamos o histograma da distribuição estacionária simulada pela cadeia.\n\nhist(x, freq = F, main = '')\n\n\n\n\n\n\n\n\nAgora, note que \\(\\pi(y)=2y\\) é distribuição estacionária, uma vez que\n\\[2y=\\pi(y)=\\int \\pi(u)k(y|u)du=\\int 2u\\frac{I(1−u&lt;y&lt;1)}{u}du=2∫^{1}_{1−y}du=2y\\] Vamos adicionar essa densidade no histograma obtido:\n\nhist(x, freq = F, main =\"\")\nabline(0,2, lwd = 2, col =4)",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "mcmc.html#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov",
    "href": "mcmc.html#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov",
    "title": "16  Tópicos em Método de Monte Carlo via Cadeias de Markov",
    "section": "16.2 Introdução aos métodos de Monte Carlo via Cadeias de Markov",
    "text": "16.2 Introdução aos métodos de Monte Carlo via Cadeias de Markov\nOs métodos para simular a distribuição \\(f(x)\\) gerando variáveis aleatórias utilizando uma cadeia de Markov são denominados métodos de Monte Carlo via Cadeias de Markov (MCMC).\nDiferente dos outros métodos de simulação, os MCMCs exigem alguns cuidados para garantir que estamos simulando variáveis independentes e identicamente distribuídas.\nAo longo desta aula, vamos utilizar a cadeia do exemplo abaixo.\n\nUma cadeia como exemplo\nConsidere uma cadeia de Markov com o seguinte núcleo de transição,\n\\[X_t|X_{t−1}=y\\sim N(\\alpha y,1)\\] com \\(\\alpha\\in(−1,1)\\). Este núcleo tem a seguinte representação estocástica:\n\\[X_t=\\alpha X_{t−1}+e_t,\\] onde \\(e_t\\simN(0,1)\\). Note que \\[\\begin{align}X_{t+2}&=\\alpha X_{t+1}+e_{t+1}=\\alpha(\\alpha X_t+e_t)+e_{t+1}\\\\&=\\alpha^2X_t+\\alpha e_{t+1}+e_t\\end{align}\\] ou seja \\[X_{t+2}|X_t=y\\sim N(\\alpha^2y,\\alpha^2+\\alpha)\\]. É fácil induzir que \\[X_{t+n}|X_t∼N\\left(\\alpha^n y,\\sum_{j=0}^n \\alpha^j\\right).\\]\nLogo \\[\\pi(x)=\\lim_{n\\rightarrow \\infty} k^{(n)}(x|y)=\\phi\\left(x|0,\\frac{1}{1-\\alpha}\\right),\\] onde \\(\\phi(x|\\mu,\\sigma^2)\\) é a funçãon densidade da normal. Para os nossos exemplo, utilizaremos \\(\\alpha=0,7\\).\n\nO objetivo dos métodos do tipo MCMC é desenvolver uma cadeia de Markov, com certo núcleo de transição \\(k(x_i|x_{i−1})\\), que tenha como distribuição estacionária a distribuição de interesse, doravante denotada por \\(f(x)\\).\nEm um mundo ideal, a simulação da cadeia deveria começar em um ponto \\(x_0\\) com alta probabilidade sob a distribuição estacionária. Como isto em geral não é possível, só podemos garantir que existe uma iteração \\(n\\) tal que a partir dela os valores simulados são da distribuição estacionária. Para nos auxiliar na escolha deste valor \\(n\\) podemos utilizar um traceplot\n\nTraceplot O gráfico com linhas unindo os pontos \\((i,x_i)\\) é denominado traceplot. Um de seus objetivos é auxiliar a detectar em qual momento a cadeia começou a amostrar pontos de f(.) (ou equivalentemente, em que momento a cadeia entrou em equilíbrio).\n\nO traceplot de um processo estacionário com variância finita tem um comportamento típico de pontos em torno da média da distribuição estacionária. Deste modo, ele é uma ferramenta exploratória que nos auxilia a detectar se a cadeia não está em equilíbrio ao perceber um padrão fora do que se esperaria de uma distribuição estacionária.\n\nExplicando o traceplot\nAbaixo, ilustramos o traceplot de duas cadeias simuladas, sendo que a única diferença entre elas é o valor de \\(x_0\\)\nA distribuição estacionária está representada ao longo do eixo das ordenadas com as linhas tracejadas em azul representando os quantis 99,5% e 0,05%. Mostramos dois traceplots (linhas pretas) com valores distintos de x0\nNo primeiro, escolhemos \\(x_0=0\\) que é a moda da distribuição estacionária e na segunda \\(x0=−10\\), um valor extremo.\n\nset.seed(123)\n\ncadeia1 = 0\ncadeia2 = -10\n\nfor(n in 1:50){\n  cadeia1[n+1] = .7*cadeia1[n]+rnorm(1)\n  cadeia2[n+1] = .7*cadeia2[n]+rnorm(1)\n}\n\nts.plot(cadeia1, ylim=c(-10,10))\nabline(h = qnorm(.995,0,sqrt(1/.3)), lty = 2)\nabline(h = qnorm(.005,0,sqrt(1/.3)), lty = 2)\n\n\n\n\n\n\n\nts.plot(cadeia2, ylim=c(-10,10))\nabline(h = qnorm(.995,0,sqrt(1/.3)), lty = 2)\nabline(h = qnorm(.005,0,sqrt(1/.3)), lty = 2)\n\n\n\n\n\n\n\n\nCom \\(x_0=0\\), o traceplot não dá evidências contra a hipótese de equilíbrio, pois os pontos simulados condizem com o que é esperado para a distribuição estacionária. Já com \\(x_0=−10\\), temos que o traceplot dá evidências de que a convergência ocorreu após 3 ou 4 iterações.\nPodemos utilizar os dois conjuntos simulados, desde que as 4 primeiras simulações da segunda cadeia sejam descartadas. Tal descarte é denominado burn-in.\nLembremos que nosso objetivo é simular variáveis independentes e identicamente distribuídas de uma distribuição alvo. Já o objetivo de um método MCMC é gerar variáveis dependentes e identicamente distribuídas segundo a distribuição alvo.\nConsiderando as variáveis simuladas (após o burn-in) \\(x_1,x_2,\\ldots,x_n\\), a dependência (linear) das variáveis obtidas via MCMC é estimada pela função de autocorrelação.\n\\[r(h)=\\sum_{i=1}^{n−h}\\frac{(x_i−\\bar{x})(x_{i+h}−\\bar{x})}{\\sum_{i=1}^n (x_i−\\bar{x})^2}.\\]\nPara termos uma amostra de variáveis aproximadamente independentes, podemos remover o efeito da autocorrelação encontrando o valor \\(h′\\) tal que \\(r(h′)≈0\\) e ficar somente com as variáveis \\(x1,x1+h′,x1+2h′,\\ldots\\). O traceplot desta subamostra deve apresentar os pontos em torno da média mas sem um padrão.\n\nVoltemos ao Exemplo 9.2, com \\(x_0=0\\). Vamos simular uma trajetória desta cadeia de tamanho \\(n=400\\) (lembre-se que neste caso o burn-in não é necessário).\n\nset.seed(123)\nn &lt;- 400\nx &lt;- 0 \nfor(i in 2:n) x[i] &lt;- .7*x[i-1] + rnorm(1)\n\n# autocorrelações (valores e gráfico)\n(acf(x))\n\n\n\n\n\n\n\n\n\nAutocorrelations of series 'x', by lag\n\n     0      1      2      3      4      5      6      7      8      9     10 \n 1.000  0.627  0.375  0.225  0.101  0.039 -0.011  0.017  0.022  0.001 -0.027 \n    11     12     13     14     15     16     17     18     19     20     21 \n-0.057 -0.088 -0.062 -0.050 -0.046 -0.106 -0.097 -0.085 -0.058 -0.023  0.008 \n    22     23     24     25     26 \n 0.049  0.006 -0.031 -0.037 -0.054 \n\n# note o efeito indesejado da dependência, ao fazer o gráfico de dispersão entre (x_i, x_{i+1})\nplot(x[-1],x[-n])\n\n\n\n\n\n\n\n\nNote que a autocorrelação estimada em h=5 é \\(r(5)=0,039\\). Podemos então retirar a subamostra \\(x1,x6,x11,...\\) para representar a nossa amostra de variáveis independentes e identicamente distribuídas. Abaixos, mostramos que o efeito indesejado da dependência desaparece.\n\ni &lt;- seq(1, n, 5)\n\n# subamostra das variáveis iid\nx_h &lt;- x[i]\n\n# autocorrelação da subamostra\nacf(x_h)\n\n\n\n\n\n\n\n# o efeito da dependência some. Veja, por exemplo\nn_h &lt;- length( x_h )\nplot( x_h[ -1 ], x_h[ -n_h ] )",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tópicos em Método de Monte Carlo via Cadeias de Markov</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Polack, Fernando P, Stephen J Thomas, Nicholas Kitchin, Judith Absalon,\nAlejandra Gurtman, Stephen Lockhart, John L Perez, et al. 2020.\n“Safety and Efficacy of the BNT162b2 mRNA Covid-19\nVaccine.” New England Journal of Medicine 383 (27):\n2603–15.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html",
    "href": "aproximacaoNormal.html",
    "title": "11  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "",
    "text": "11.1 A priori imprópria\nConsiderando o problema de elicitar uma priori para \\(\\theta\\in\\(0,1)\\), a distribuição Uniforme(0,1) surge como uma candidato confortável, uma vez que dá probabilidades iguais para quaisquer intervalos de \\((0,1)\\) de mesmo comprimento.\nDe modo análogo, se \\(\\theta\\in(a,b)\\), a distribuição Uniforme\\((a,b)\\) é uma escolha interessante quando o objetivo é dar pouco peso para a informação a priori.\nConsidere então que \\(\\theta\\in\\mathbb{R}\\). Na prática, há um subintervalo \\((a,b)\\in\\mathbb{R}\\) que contém quasse toda a massa da posteriori. Nesse caso, podemos utilizar a priori Uniforme\\((a,b)\\), obtendo \\[f(\\theta|\\boldsymbol{x})=\\frac{L(\\theta)\\frac{1}{b-a}}{\\int_a^bL(\\theta)\\frac{1}{b-a}d\\theta}=\\frac{L(\\theta)}{\\int_a^b L(\\theta)d\\theta}.\\] Se permitirmos que \\(a=-\\infty\\) e \\(b=+\\infty\\), teremos \\[f(\\theta|\\boldsymbol{x})=\\frac{L(\\theta)\\frac{1}{b-a}}{\\int_a^bL(\\theta)\\frac{1}{b-a}d\\theta}=\\frac{L(\\theta)}{\\int_\\mathbb{R} L(\\theta)d\\theta}\\propto L(\\theta).\\] Desde que \\(\\int_{\\mathbb{R}}L(\\theta)&lt;\\infty\\), teremos que \\(f(\\theta|\\boldsymbol{x})\\) é de fato uma posteriori. A priori associada nesse caso é dada por \\[f(\\theta)=1\\] para todo \\(\\theta\\in\\mathbb{R}\\). Como essa priori não é uma função densidade, ela é denominada imprópria.\nQuando \\(\\theta\\in(0,\\infty)\\), é usual realizar a transformação \\(\\lambda = \\log(\\theta)\\in\\mathbb{R}\\). Considerando uma priori imprópria para \\(\\lambda\\), teremos \\[f(\\lambda|\\boldsymbol{x})=\\frac{L(e^{\\lambda})}{\\int_\\mathbb{R}L(e^{\\lambda})d\\lambda},\\] desde que a integral no denominador seja finita. Podemos então utilizar o método do jacobiano para obter a posteriori para \\(\\theta\\):\n\\[f(\\theta|\\boldsymbol{x})\\propto L(\\theta)\\frac{d\\lambda}{d\\theta}=L(\\theta)\\frac{1}{\\theta}.\\] Portanto, quando \\(\\theta\\in(0,1)\\), utilizamos a priori (imprópria) \\[f(\\theta)=\\frac{1}{\\theta},\\] para todo \\(\\theta&gt;0\\), considerando que \\[\\int_0^\\infty L(\\theta)\\frac{1}{\\theta}d\\theta &lt;\\infty.\\]",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html#a-priori-imprópria",
    "href": "aproximacaoNormal.html#a-priori-imprópria",
    "title": "11  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "",
    "text": "Priori imprópria para o modelo normal\nSeja \\(x_1,\\ldots,x_n\\) uma amostra observada do modelo Normal(\\(\\mu\\),1), cuja função de verossimilhança é dada por \\[L(\\mu)=\\frac{1}{(2\\pi)^{n/2}}e^{-\\frac{n}{2}(\\bar{x}-\\mu)^2-\\frac{n}{2}s^2}.\\] Considere a priori imprópria para \\(\\mu\\). Como \\[\\int_\\mathbb{R}L(\\mu)d\\mu=\\frac{1}{(2\\pi)^{n/2}}e^{-\\frac{n}{2}s^2}\\int_{\\mathbb{R}}e^{-\\frac{n}{2}(\\bar{x}-\\mu)^2}d\\mu=\\frac{1}{(2\\pi)^{n/2}}e^{-\\frac{n}{2}s^2}\\sqrt{\\frac{2\\pi}{n}}&lt;\\infty,\\] temos que \\[f(\\mu|\\boldsymbol{x})\\propto L(\\mu)\\propto e^{-\\frac{n}{2}(\\mu-\\bar{x})^2},\\] ou seja \\(\\mu|\\boldsymbol{x}\\sim\\hbox{Normal}(\\bar{x},1/n)\\).\n\n\n\n\nPriori imprópria para a Poisson Seja \\(x_1,\\ldots,x_n\\) uma amostra observada do modelo Poisson(\\(\\lambda\\)). Observe que \\[\\begin{align}\\int_0^\\infty L(\\lambda)\\frac{1}{\\lambda}d\\lambda&=\\int_0^\\infty \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n x_i}}{\\prod_{i=1^n }x_i!}\\frac{1}{\\lambda}d\\lambda=\\frac{1}{\\prod_{i=1}^nx_i!}\\int_0^\\infty\\lambda^{\\sum_{i=1}^n x_i-1}e^{-n\\lambda}d\\lambda\\\\&=\\frac{\\Gamma(\\sum_{i=1}^n x_i)}{\\prod_{i=1}^n x_i!}\\frac{1}{n^{\\sum_{i=1}^n x_i}}&lt;\\infty\\end{align}\\] portanto, a posteriori para \\(\\lambda\\) é \\[f(\\lambda|\\boldsymbol{x})\\propto L(\\lambda)\\frac{1}{\\lambda}\\propto \\lambda^{\\sum_{i=1}^n x_i-1}e^{-n\\lambda},\\] ou seja, \\(\\lambda|\\boldsymbol{x}\\sim\\hbox{Gama}(\\sum_{i=1}^n x_i,n).\\)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html#aproximação-da-posteriori-pela-distribuição-normal",
    "href": "aproximacaoNormal.html#aproximação-da-posteriori-pela-distribuição-normal",
    "title": "11  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "11.2 Aproximação da posteriori pela distribuição normal",
    "text": "11.2 Aproximação da posteriori pela distribuição normal\nAssuma que \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^q\\). Seja \\(\\ell(\\boldsymbol{\\theta})=\\log L(\\boldsymbol{\\theta})\\) a função log-verossimilhança e \\(\\hat{\\boldsymbol{\\theta}}\\) a estimativa de máxima verossimilhaça para \\(\\boldsymbol{\\theta}\\). Considere a seguinte aproximação de \\(\\ell(\\boldsymbol{\\theta})\\) em séries de Taylor\n\\[\\ell(\\boldsymbol{\\theta})\\approx  \\ell(\\hat{\\boldsymbol{\\theta}})+\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\] onde \\(\\boldsymbol{\\theta}\\) é a matriz hessiana (de derivadas segunda) aplicada em \\(\\hat{\\boldsymbol{\\theta}}\\).\nDeste modo, teremos que \\[f(\\boldsymbol{\\theta}|\\boldsymbol{x})\\propto \\exp\\left\\{-\\frac{1}{2}(\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})'\\left[-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\right](\\boldsymbol{\\theta}-\\hat{\\boldsymbol{\\theta}})\\right\\}f(\\boldsymbol{\\theta})\\]\nUtilizando a priori imprópria \\(f(\\boldsymbol{\\theta})\\propto 1\\), temos que \\(\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx \\hbox{Normal}(\\hat{\\boldsymbol{\\theta}},-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})^{-1})\\).\nSe \\(\\theta\\) for um escalar, teremos\n\\[f(\\theta| \\boldsymbol{x} )\\propto \\exp \\left\\{ -\\frac{1}{2} (\\theta-\\hat{\\theta})^2\\left[-\\left.\\frac{d^2}{d\\theta^2}\\ell(\\theta)\\right|_{\\theta=\\hat{\\theta}}\\right]\\right\\}f(\\boldsymbol{\\theta})\\] e, ao utilizar a priori imprópria novamente, teremos \\[\\theta|\\boldsymbol{x}\\sim\\hbox{Normal}\\left(\\hat{\\theta},-\\left.\\frac{d^2}{d\\theta^2}\\ell(\\theta)\\right|_{\\theta=\\hat{\\theta}}\\right).\\]\n\nImportante Para que a aproximação normal faça sentido, é necessário que a priori utilizada seja a imprópria ou uma conjugada. Para tanto, é necessário que o espaço paramétrico de \\(\\theta\\) seja a reta e alguma transformação pode ser necessária.\nSeja então \\(\\psi\\) o parâmetro original e seja \\(\\theta=g(\\psi)\\) o parâmetro transformado tal que \\(\\theta\\in(-\\infty,+\\infty)\\). Após aproximar a posteriori de \\(\\theta\\) para a normal:\n\nSimule \\(\\theta_1,\\ldots,\\theta_B\\) da normal aproximada\nCrie a amostra \\(\\psi_1=g^{-1}(\\theta_1),\\ldots,\\psi_B=g^{-1}(\\theta_B)\\)\nFaça inferências sobre \\(\\psi\\) utilizando a amostra \\(\\psi_1,\\ldots,\\psi_B\\).\n\n\nNote que as informações necessárias para a aproximação da posteriori acima podem ser obtidas via função optim.\n\nExemplo \nO USGS reune diversas informações. Entre elas, em https://earthquake.usgs.gov/earthquakes/search/, é possível obter informações sobre terremotos ocorridos no globo para um período longo de tempo. Os dados abaixo apresentam o tempo ocorrido entre terremos nos últimos 10 anos (entre maio de 2025 e maio de 2025)\n\nrequire(gsheet)\n\nCarregando pacotes exigidos: gsheet\n\nurl = 'https://docs.google.com/spreadsheets/d/1Pg0AGENj8Cf9e5yqvbXnhEZ7jgY3sBSb6ETtGUwZtpQ/edit?usp=sharing'\n\nx = gsheet2tbl(url)\nx = x$Tempo\n\nVamos supor que o modelo Gama(\\(\\alpha\\),\\(\\beta\\)) é adequado para este banco de dados. Embora o modelo Gama possua conjugada, a mesma não é trivial para propósitos de aplicação.\nVamos considerar a aproximação normal para este modelo. Como \\(\\alpha,\\beta&gt;0\\), considere as seguintes transformações para a reta:\n\n\\(\\alpha=\\exp\\{\\theta_1\\}\\)\n\\(\\beta=\\exp\\{\\theta_2\\}\\)\n\nDeste modo, \\(\\boldsymbol{\\theta}\\in\\mathbb{R}^2\\).\nA função de log-verossimilhança deste modelo é\n\nlogveross &lt;- function(theta){ sum(dgamma(x, exp(theta[1]), exp(theta[2]), log = T))\n}\n\nPodemos utilizar a função optim para obter as estimativas de máxima verossimilhança e a matriz hessiana. Contudo, primeiro devemos observar que esta função é um minimizador, logo, queremos que \\(\\boldsymbol{\\theta}\\) que minimize \\(-\\ell({\\boldsymbol{\\theta}})\\).\n\nopt &lt;- optim( c(0,0), function(q) -logveross(q), hessian = T)\nopt\n\n$par\n[1] -0.3936871 -0.1853257\n\n$value\n[1] 3295.181\n\n$counts\nfunction gradient \n      67       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]      [,2]\n[1,]  6163.371 -3038.916\n[2,] -3038.916  3038.663\n\n\nNo objeto opt, a lista par é o vetor com as estimativas de máxima verossimilhança, enquanto que hessian é o valor de \\(-\\mathcal{H}(\\hat{\\boldsymbol{\\theta}})\\).\nA inversa de opt$hessian vai dar a matriz de covariância entre \\(\\theta_1\\) e \\(\\theta_2\\) da posteriori.\n\nSigma &lt;- solve(opt$hessian)\nSigma\n\n             [,1]         [,2]\n[1,] 0.0003200819 0.0003201086\n[2,] 0.0003201086 0.0006492275\n\n\nAgora, podemos simular \\(\\theta_1\\) e \\(\\theta_2\\) a posteriori, considerando a priori imprópria:\n\nrequire(mvtnorm)\n\nCarregando pacotes exigidos: mvtnorm\n\ntheta_sim &lt;- rmvnorm(500, opt$par, Sigma)\n\nPor último, podemos fazer inferências sobre \\(\\alpha=\\exp\\{\\theta_1\\}\\) e \\(\\beta=\\exp\\{\\theta_2\\}\\):\n\nalpha = exp(theta_sim[,1])\nbeta = exp(theta_sim[,2])\n# intervalos de credibilidade para alfa\nquantile(alpha, c(.025,.975))\n\n     2.5%     97.5% \n0.6503395 0.6946834 \n\n# intervalos de credibilidade para beta\nquantile(beta, c(.025,.975))\n\n     2.5%     97.5% \n0.7933308 0.8745656 \n\n\nCom a amostra a posteriori simulada, podemos simular amostras da preditiva a posteriori.\n\nn &lt;- length(x)\ny_pred &lt;- array(NA_real_, c(500, n))\nfor(i in 1:500){\n  y_pred[i,] &lt;- rgamma(n, alpha[i], beta[i])\n}\n\nPodemos então construir um intervalo de predição para a função de distribuição empírica da preditiva a posteriori e compará-lo com a distribuição empírica dos dados.\n\nFd_sim = apply(y_pred,1, function(y){\n  Fd = ecdf(y)\n  Fd(sort(x))\n})\n\nqq = apply(Fd_sim,1, function(x) quantile(x,c(.025,.977)))\n\nplot(ecdf(x), main = '')\nlines(sort(x),qq[1,], col =2)\nlines(sort(x),qq[2,], col =2)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html#o-algoritmo-metropolis-em-conjunto-com-a-aproximação-normal",
    "href": "aproximacaoNormal.html#o-algoritmo-metropolis-em-conjunto-com-a-aproximação-normal",
    "title": "11  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "11.3 O algoritmo Metropolis em conjunto com a aproximação normal",
    "text": "11.3 O algoritmo Metropolis em conjunto com a aproximação normal\nConsidere que desejamos simular da posteriori \\(f(\\theta|\\boldsymbol{x})\\), onde \\(\\theta\\in\\mathbb{R}^d\\). Para tanto, podemos utilizar o método de Monte Carlo via Cadeias de Markov conhecido como Metropolis.\n\nMetropolis\nComece com um valo inicial \\(\\theta^{(0)}\\). Para a \\(i\\)-ésima iteração:\n\nSimule \\(\\theta^*\\sim\\hbox{Normal}(\\theta^{(i-1)},S)\\)\nCalcule a razão\n\n\\[\\rho=\\frac{f(\\theta^*|\\boldsymbol{x})}{f(\\theta^{(i-1)}|\\boldsymbol{x})}\\] 3. Simule \\(u\\sim\\hbox{Uniforme}(0,1)\\). Se \\(u&lt;\\rho\\), faça \\(\\theta^{(i)}=\\theta^*\\). Senão, faça \\(\\theta^{(i)}=\\theta^{(i-1)}\\).\n\nA distribuição dada no passo 1 do algoritmo acima é denominada proposta e uma escolha razoável para ela é a aproximação normal da posteriori.\nPortanto, podemos utilizar a aproximação normal como distribuição proposta para obter amostras da posteriori original.\n\nExemplo  Consideremos novamente a amostra do exemplo anterior. A função de verossimilhança, com os parâmetros transformados é dada por \\[L(\\theta)=\\prod_{i=1}^n \\frac{(e^{\\theta_2} )^{e ^{\\theta_1}}}{\\Gamma(e^{\\theta_1})} x_i^{e^{\\theta_1}-1}e^{-e^{\\theta_2}x_i}\\] Além disso ,considere ad prioris independentes \\(\\theta_i\\sim\\hbox{Normal}(0,100)\\), onde a variância alta foi escolhida para que a priori fosse pouco informativa. Então, devemos simular do modelo\n\\[f(\\theta|\\boldsymbol{x})\\propto L(\\theta )e^{-\\frac{1}{200}(\\theta_1^2 + \\theta_2^2)}\\]\nA posteriori aproximada, que encontramos no exemplo anterior é \\[\\boldsymbol{\\theta}|\\boldsymbol{x}\\approx N \\left[ \\left(\\begin{array}{c}-0,3936\\\\-0,1853 \\end{array}\\right),\\left(\\begin{array}{cc}0,0003 & 0,0003\\\\0,0003 &0,0006\\end{array}\\right)\\right]\\]\nVamos aproveitar a estrutura de covariâncias acima para usar a proposta\n\\[\\boldsymbol{\\theta}^*|\\boldsymbol{x}\\sim N \\left[ \\boldsymbol{\\theta}^{(j-1)},\\tau\\left(\\begin{array}{cc}0,0003 & 0,0003\\\\0,0003 &0,0006\\end{array}\\right)\\right]\\] onde \\(\\boldsymbol{\\theta}^*\\) é o candidato gerado e \\(\\boldsymbol{\\theta}^{(j)}\\) é o estado atual da cadeia e \\(\\tau\\) é o tunning da cadeia (em geral, escolhido entre .1, 1 e 10). Além disso, vamos aproveitar a estimativa de máxima verossimilhança como valor inicial para a simulação.\n\nB &lt;- 10000 # número de iterações\ntheta &lt;- array(NA_real_, c(B,2))\n\ntheta[1,] &lt;- opt$par # valor inicial da cadeia é a emv\ntau &lt;- 1             # tunning\ncont &lt;- 0            # contador de aceites\n\nfor(j in 2:B){\n  #simule um candidato\n  theta_cand &lt;- rmvnorm(1, theta[j-1,], tau*Sigma)\n  \n  # calcule a probabilidade do salto\n  lnum &lt;- logveross(theta_cand) +\n    sum(dnorm(theta_cand[1,],0,10, log = T))\n  \n  lden &lt;- logveross(theta[j-1,]) +\n    sum(dnorm(theta[j-1,],0,10, log = T))\n  \n  prob &lt;- exp( lnum - lden)\n  \n  # verifique o salto\n  u &lt;- runif(1)\n  if( u &lt; prob){\n    theta[j, ] &lt;- theta_cand\n    cont &lt;- cont+1\n  } else {\n    theta[j,] &lt;- theta[j-1,]\n  }\n}\n\ntheta_sim &lt;- theta[ seq(B/2, B, 15),]\nts.plot(theta_sim[,1])\n\n\n\n\n\n\n\nacf(theta_sim[,1])\n\n\n\n\n\n\n\n\nPor fim, as estimativas intervalares para \\((\\alpha,\\beta)\\) são\n\nquantile(exp(theta_sim[,1]), c(.025,.975))\n\n     2.5%     97.5% \n0.6515394 0.6966456 \n\n# intervalos de credibilidade para beta\nquantile(exp(theta_sim[,2]), c(.025,.975))\n\n     2.5%     97.5% \n0.7889977 0.8664740",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "aproximacaoNormal.html#exercícios",
    "href": "aproximacaoNormal.html#exercícios",
    "title": "11  Aproximação normal e seu uso com o Metropolis-Hastings",
    "section": "11.4 Exercícios",
    "text": "11.4 Exercícios\n\n11.4.1 Máximas do Rio Negro\nA tabela abaixo mostra os níveis máximos do Rio Negro regis trados no Porto de Manaus entre 2004 e 2014.\n\n# Criar os vetores de anos e valores máximos\nanos &lt;- c(1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n          2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014)\n\nmaximas &lt;- c(25.42, 28.76, 29.05, 27.16, 28.54, 28.96, 27.58, 29.30, 28.62, 28.21,\n             28.91, 28.27, 27.13, 28.10, 28.84, 28.18, 28.62, 29.77, 27.96, 28.62,\n             29.97, 29.33, 29.50)\n\n# Combinar os vetores em um data frame\ndados_anuais &lt;- data.frame(\n  Ano = anos,\n  Maxima = maximas\n)\n\n# Visualizar a tabela criada\nprint(dados_anuais)\n\n    Ano Maxima\n1  1992  25.42\n2  1993  28.76\n3  1994  29.05\n4  1995  27.16\n5  1996  28.54\n6  1997  28.96\n7  1998  27.58\n8  1999  29.30\n9  2000  28.62\n10 2001  28.21\n11 2002  28.91\n12 2003  28.27\n13 2004  27.13\n14 2005  28.10\n15 2006  28.84\n16 2007  28.18\n17 2008  28.62\n18 2009  29.77\n19 2010  27.96\n20 2011  28.62\n21 2012  29.97\n22 2013  29.33\n23 2014  29.50\n\n\nO Teorema de Fisher-Tippett diz que uma sequência de máximos de variáveis aleatórias independentes e identicamente distribuídas converge em distribuição para um membro da família de distribuições de valores extremos que pode ser dividida nas famílias Gumbel, Fréchet e Weibull.\n\nUtilize a aproximação Normal para verificar que a distribuição Weibull se ajusta a esses dados\nsimule amostras da posteriori para o modelo Weibull utilizando o algoritmo Metropolis. Dê intervalos de credibilidade para os parâmetros e verifique o ajuste analisando a preditiva a posteriori.\n\n\n\n11.4.2 Tempo entre chegadas utilizando da distribuição Lindley\nOs dados abaixo representam o tempo que 100 clientes esperaram para serem atendidos em um banco e foram retirados de aqui\n\ndados &lt;- c(0.8, 0.8, 1.3, 1.5, 1.8, 1.9, 1.9, 2.1, 2.6, 2.7, 2.9, 3.1, 3.2, 3.3, 3.5, 3.6, 4.0, 4.1, 4.2, 4.2, 4.3, 4.3, 4.4, 4.4, 4.6, 4.7, 4.7, 4.8, 4.9, 4.9, 5.0, 5.3, 5.5, 5.7, 5.7, 6.1, 6.2, 6.2, 6.2, 6.3,6.7, 6.9, 7.1, 7.1, 7.1, 7.1, 7.4, 7.6, 7.7, 8.0, 8.2, 8.6, 8.6, 8.6, 8.8, 8.8, 8.9, 8.9, 9.5, 9.6, 9.7, 9.8, 10.7, 10.9, 11.0, 11.0, 11.1, 11.2, 11.2, 11.5, 11.9, 12.4, 12.5, 12.9, 13.0, 13.1, 13.3, 13.6, 13.7, 13.9,14.1, 15.4, 15.4, 17.3, 17.3, 18.1, 18.2, 18.4, 18.9, 19.0,           19.9, 20.6, 21.3, 21.4, 21.9, 23.0, 27.0, 31.6, 33.1, 38.5)\n\n\nEmbora a distribuição exponencial seja a primeira escolha, no trabalho original os autores discutem que esta distribuição não oferece um bom ajuste para estes dados. Utilizando a distribuição preditiva a posteriori obtida a partir da priori conjugada da exponencial, obtenha evidências sobre a afirmação dos pesquisadores.\nComo alternativa, os pesquisadores sugeriram a utilização da distribuição Lindley, cuja função densidade é dada por\n\n\\[f(x|\\theta)=\\frac{\\theta^2}{\\theta+1}(1+x) e^{-\\theta x},\\] onde \\(x,\\theta&gt;0\\). Faça \\(\\lambda=\\log(\\theta)\\). Utilizando uma priori imprópria para \\(\\lambda\\) e a aproximação normal, verifique a afirmação dos pesquisadores de que a distribuição Lindley é apropriada para este conjunto de dados.\n\nRefaça o item anterior utilizando a posteriori \\[f(\\lambda|\\boldsymbol{x})\\propto \\prod_{i=1}^nf(x_i|e^{\\lambda})f(\\lambda),\\] onde \\(f(\\lambda)\\) é uma priori própria. Para tanto, utilize o algoritmo Metropolis para obter simulações da posteriori e considere a aproximação normal obtida no item anterior para construir a proposta deste simulador.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Aproximação normal e seu uso com o Metropolis-Hastings</span>"
    ]
  }
]